{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfc76fc6",
   "metadata": {},
   "source": [
    "# Supervised Classification using TabNet\n",
    "\n",
    "In this notebook, we will see how to use the TabNet layers from this repository to build a supervised learning classifier in TF Keras. As an example, we will analyze the [Adult Census Income dataset](https://archive.ics.uci.edu/ml/datasets/adult). The goal here is to predict the income bracket (earns <=\\$50K or >50K) of an individual based on some descriptive features (e.g., age, sex, race, marital status, occupation, capital gain/loss, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75e43afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minkoo/.conda/envs/tf/lib/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/home/minkoo/.conda/envs/tf/lib/python3.9/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.10.0 and strictly below 2.13.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.8.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append(\"../\")\n",
    "\n",
    "# import torch\n",
    "# import pandas as pd\n",
    "import plotly.express as px\n",
    "# import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "from utils.load_data import get_datasets_np\n",
    "# from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "# from category_encoders.woe import WOEEncoder\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "from tensorflow.keras import metrics\n",
    "\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "from tensorflow_addons.activations import sparsemax\n",
    "from scipy.special import softmax\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700a5873",
   "metadata": {},
   "source": [
    "## Loading and preparing data\n",
    "We load the Adult Census Income dataset from the UCI data repository. We impute the missing values with the mode value. We encode the labels into binary. Finally, we convert the data into [TF Dataset format](https://www.tensorflow.org/api_docs/python/tf/data/Dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "701bff3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(995318, 6, 30)\n",
      "(254005, 6, 30)\n",
      "(114869, 6, 30)\n",
      "(13710, 6, 30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 10:15:00.700037: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-14 10:15:01.123105: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-14 10:15:01.123461: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-14 10:15:01.124855: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-14 10:15:01.125282: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-14 10:15:01.125595: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-14 10:15:01.125912: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-14 10:15:01.838639: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-14 10:15:01.839038: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-14 10:15:01.839322: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-14 10:15:01.839590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6642 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "x,y, class_weights = get_datasets_np()\n",
    "\n",
    "\n",
    "#'time', 'age', 'gender_f', 'gender_m'\n",
    "time = ['time']\n",
    "vital = ['rr','hr','spo2','sbp','dbp','temp']\n",
    "CBC = ['hct','hb','platelets','wbc','rbc','mch','mchc','mcv']\n",
    "ABGA = ['ph','hco3', 'po2','pco2','sao2','fio2','pfratio']\n",
    "time_series = time+vital+CBC+ABGA\n",
    "info = ['age', 'gender_f', 'gender_m']\n",
    "scores = ['Rox', 'MEWS', 'NEWS', 'Sofa', 'QSofa']\n",
    "name = time_series+info+scores\n",
    "\n",
    "def flatten_name(name, N):\n",
    "    return [name[i] + '_' + str(j) for i in range(len(name)) for j in range(1, N+1)]\n",
    "\n",
    "def flatten_ts(X):\n",
    "    X_ts  =X[:,:,:-8]\n",
    "    X_static = X[:,0,-8:-6] #exclude gender_m\n",
    "    X_score = X[:,:,-5:]\n",
    "    flat_x_ts = np.transpose(X_ts, (0, 2, 1)).reshape(X_ts.shape[0], -1)\n",
    "    datasets_score = np.transpose(X_score, (0, 2, 1)).reshape(X_score.shape[0], -1)\n",
    "    flatten_x = np.concatenate((flat_x_ts, X_static, datasets_score), axis=1)\n",
    "    return flatten_x    \n",
    "\n",
    "flat_names = flatten_name(time_series,6) + ['age', 'gender'] + flatten_name(scores,6)\n",
    "\n",
    "flat_x = []\n",
    "df = []\n",
    "for i in range(4):\n",
    "    flat_x.append(flatten_ts(x[i]))\n",
    "    df.append(pd.DataFrame(flat_x[i], columns=flat_names))\n",
    "\n",
    "dataset_names = ['train','valid','test_icu','test_covid']\n",
    "\n",
    "datasets = []\n",
    "for i in range(4):\n",
    "    # y[i] = tf.one_hot(y[i].astype(int), 2)\n",
    "    tfdata = tf.data.Dataset.from_tensor_slices((flat_x[i],y[i]))\n",
    "    # tfdata = tf.data.Dataset.from_tensor_slices(datasets[i],y[i])\n",
    "    tfdata = tfdata.batch(1024).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    datasets.append(tfdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42e19981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def glu(x, n_units=None):\n",
    "    \"\"\"Generalized linear unit nonlinear activation.\"\"\"\n",
    "    return x[:, :n_units] * tf.nn.sigmoid(x[:, n_units:])\n",
    "class FeatureBlock(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Implementation of a FL->BN->GLU block\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature_dim,\n",
    "        apply_glu = True,\n",
    "        bn_momentum = 0.9,\n",
    "        fc = None,\n",
    "        epsilon = 1e-5,\n",
    "    ):\n",
    "        super(FeatureBlock, self).__init__()\n",
    "        self.apply_gpu = apply_glu\n",
    "        self.feature_dim = feature_dim\n",
    "        units = feature_dim * 2 if apply_glu else feature_dim # desired dimension gets multiplied by 2\n",
    "                                                              # because GLU activation halves it\n",
    "\n",
    "        self.fc = tf.keras.layers.Dense(units, use_bias=False) if fc is None else fc # shared layers can get re-used\n",
    "        self.bn = tf.keras.layers.BatchNormalization(momentum=bn_momentum, epsilon=epsilon)\n",
    "\n",
    "    def call(self, x, training = None):\n",
    "        x = self.fc(x) # inputs passes through the FC layer\n",
    "        x = self.bn(x, training=training) # FC layer output gets passed through the BN\n",
    "        if self.apply_gpu: \n",
    "            return glu(x, self.feature_dim) # GLU activation applied to BN output\n",
    "        return x\n",
    "\n",
    "    \n",
    "class FeatureTransformer(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature_dim,\n",
    "        fcs = [],\n",
    "        n_total = 4,\n",
    "        n_shared = 2,\n",
    "        bn_momentum = 0.9,\n",
    "    ):\n",
    "        super(FeatureTransformer, self).__init__()\n",
    "        self.n_total, self.n_shared = n_total, n_shared\n",
    "\n",
    "        kwrgs = {\n",
    "            \"feature_dim\": feature_dim,\n",
    "            \"bn_momentum\": bn_momentum,\n",
    "        }\n",
    "\n",
    "        # build blocks\n",
    "        self.blocks = []\n",
    "        for n in range(n_total):\n",
    "            # some shared blocks\n",
    "            if fcs and n < len(fcs):\n",
    "                self.blocks.append(FeatureBlock(**kwrgs, fc=fcs[n])) # Building shared blocks by providing FC layers\n",
    "            # build new blocks\n",
    "            else:\n",
    "                self.blocks.append(FeatureBlock(**kwrgs)) # Step dependent blocks without the shared FC layers\n",
    "\n",
    "    def call(self, x, training = None):\n",
    "        # input passes through the first block\n",
    "        x = self.blocks[0](x, training=training) \n",
    "        # for the remaining blocks\n",
    "        for n in range(1, self.n_total):\n",
    "            # output from previous block gets multiplied by sqrt(0.5) and output of this block gets added\n",
    "            x = x * tf.sqrt(0.5) + self.blocks[n](x, training=training) \n",
    "        return x\n",
    "\n",
    "    @property\n",
    "    def shared_fcs(self):\n",
    "        return [self.blocks[i].fc for i in range(self.n_shared)]\n",
    "    \n",
    "class AttentiveTransformer(tf.keras.Model):\n",
    "    def __init__(self, feature_dim):\n",
    "        super(AttentiveTransformer, self).__init__()\n",
    "        self.block = FeatureBlock(\n",
    "            feature_dim,\n",
    "            apply_glu=False,\n",
    "        )\n",
    "\n",
    "    def call(self, x, prior_scales, training=None):\n",
    "        x = self.block(x, training=training)\n",
    "        return sparsemax(x * prior_scales)\n",
    "    \n",
    "class TabNet(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_features,\n",
    "        feature_dim,\n",
    "        output_dim,\n",
    "        n_step = 2,\n",
    "        n_total = 4,\n",
    "        n_shared = 2,\n",
    "        relaxation_factor = 1.5,\n",
    "        bn_epsilon = 1e-5,\n",
    "        bn_momentum = 0.7,\n",
    "        sparsity_coefficient = 1e-5\n",
    "    ):\n",
    "        super(TabNet, self).__init__()\n",
    "        self.output_dim, self.num_features = output_dim, num_features\n",
    "        self.n_step, self.relaxation_factor = n_step, relaxation_factor\n",
    "        self.sparsity_coefficient = sparsity_coefficient\n",
    "\n",
    "        self.bn = tf.keras.layers.BatchNormalization(\n",
    "            momentum=bn_momentum, epsilon=bn_epsilon\n",
    "        )\n",
    "\n",
    "        kargs = {\n",
    "            \"feature_dim\": feature_dim + output_dim,\n",
    "            \"n_total\": n_total,\n",
    "            \"n_shared\": n_shared,\n",
    "            \"bn_momentum\": bn_momentum\n",
    "        }\n",
    "\n",
    "        # first feature transformer block is built first to get the shared blocks\n",
    "        self.feature_transforms = [FeatureTransformer(**kargs)]\n",
    "        self.attentive_transforms = []\n",
    "            \n",
    "        # each step consists out of FT and AT\n",
    "        for i in range(n_step):\n",
    "            self.feature_transforms.append(\n",
    "                FeatureTransformer(**kargs, fcs=self.feature_transforms[0].shared_fcs)\n",
    "            )\n",
    "            self.attentive_transforms.append(\n",
    "                AttentiveTransformer(num_features)\n",
    "            )\n",
    "        \n",
    "        # Final output layer\n",
    "        self.head = tf.keras.layers.Dense(1, activation=\"sigmoid\", use_bias=False)\n",
    "\n",
    "    def call(self, features, training = None):\n",
    "\n",
    "        bs = tf.shape(features)[0] # get batch shape\n",
    "        out_agg = tf.zeros((bs, self.output_dim)) # empty array with outputs to fill\n",
    "        prior_scales = tf.ones((bs, self.num_features)) # prior scales initialised as 1s\n",
    "        importance = tf.zeros([bs, self.num_features]) # importances\n",
    "        masks = []\n",
    "\n",
    "        features = self.bn(features, training=training) # Batch Normalisation\n",
    "        masked_features = features\n",
    "\n",
    "        total_entropy = 0.0\n",
    "\n",
    "        for step_i in range(self.n_step + 1):\n",
    "            # (masked) features go through the FT\n",
    "            x = self.feature_transforms[step_i](\n",
    "                masked_features, training=training\n",
    "            )\n",
    "            \n",
    "            # first FT is not used to generate output\n",
    "            if step_i > 0:\n",
    "                # first half of the FT output goes towards the decision \n",
    "                out = tf.keras.activations.relu(x[:, : self.output_dim])\n",
    "                out_agg += out\n",
    "                scale_agg = tf.reduce_sum(out, axis=1, keepdims=True) / (self.n_step - 1)\n",
    "                importance += mask_values * scale_agg\n",
    "                \n",
    "\n",
    "            # no need to build the features mask for the last step\n",
    "            if step_i < self.n_step:\n",
    "                # second half of the FT output goes as input to the AT\n",
    "                x_for_mask = x[:, self.output_dim :]\n",
    "                \n",
    "                # apply AT with prior scales\n",
    "                mask_values = self.attentive_transforms[step_i](\n",
    "                    x_for_mask, prior_scales, training=training\n",
    "                )\n",
    "\n",
    "                # recalculate the prior scales\n",
    "                prior_scales *= self.relaxation_factor - mask_values\n",
    "                \n",
    "                # multiply the second half of the FT output by the attention mask to enforce sparsity\n",
    "                masked_features = tf.multiply(mask_values, features)\n",
    "\n",
    "                # entropy is used to penalize the amount of sparsity in feature selection\n",
    "                total_entropy += tf.reduce_mean(\n",
    "                    tf.reduce_sum(\n",
    "                        tf.multiply(-mask_values, tf.math.log(mask_values + 1e-15)),\n",
    "                        axis=1,\n",
    "                    )\n",
    "                )\n",
    "                \n",
    "                # append mask values for later explainability\n",
    "                masks.append(tf.expand_dims(tf.expand_dims(mask_values, 0), 3))\n",
    "                \n",
    "        #Per step selection masks        \n",
    "        self.selection_masks = masks\n",
    "        \n",
    "        # Final output\n",
    "        final_output = self.head(out)\n",
    "        \n",
    "        # Add sparsity loss\n",
    "        loss = total_entropy / (self.n_step-1)\n",
    "        self.add_loss(self.sparsity_coefficient * loss)\n",
    "        \n",
    "        return final_output, importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0f3871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiValidationCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, val_datasets):\n",
    "        super().__init__()\n",
    "        self.val_datasets = val_datasets\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        metrics = [[] for _ in range(3)]\n",
    "        sum_auc = 0\n",
    "        for i, val_dataset in enumerate(self.val_datasets):\n",
    "            val_preds, val_imps = self.model.predict(val_dataset)\n",
    "            # val_loss, val_auc, val_ap = self.model.evaluate(val_dataset,verbose=0)\n",
    "            # logs[f'val{i+2}_loss'] = val_loss\n",
    "            logs[f'val{i+2}_auc'] = np.round(roc_auc_score(y[i+1], val_preds), 4)\n",
    "            logs[f'val{i+2}_ap'] = np.round(average_precision_score(y[i+1], val_preds), 4)\n",
    "            sum_auc = sum_auc + logs[f'val{i+2}_auc']\n",
    "        logs[f'sum_auc'] = sum_auc\n",
    "        \n",
    "        formatted_items = [f'{key}: {value:.3f}' for key, value in logs.items() if key == 'loss' or key.endswith('auc')]\n",
    "        print(f\"Epoch{epoch}\\t\", end='')\n",
    "        print(formatted_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e32f024f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopByAUCSUM(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, dataset, mode = 'max', patience = 0,verbose = 1):\n",
    "        super(tf.keras.callbacks.Callback, self).__init__()\n",
    "        self.val_datasets = dataset\n",
    "        self.mode = mode\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.best_weights = None\n",
    "        self.hist = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        sum_auc = 0\n",
    "        for i, val_dataset in enumerate(self.val_datasets):\n",
    "            val_preds, val_imps = self.model.predict(val_dataset)\n",
    "            logs[f'val{i+2}_auc'] = np.round(roc_auc_score(y[i+1], val_preds), 4)\n",
    "            logs[f'val{i+2}_ap'] = np.round(average_precision_score(y[i+1], val_preds), 4)\n",
    "            sum_auc = sum_auc + logs[f'val{i+2}_auc']\n",
    "        logs[f'sum_auc'] = sum_auc\n",
    "        score = sum_auc\n",
    "        \n",
    "        formatted_items = [f'{key}: {value:.3f}' for key, value in logs.items() if key == 'loss' or key.endswith('auc')]\n",
    "        print(f\"Epoch{epoch}\\t\", end='')\n",
    "        print(formatted_items)\n",
    "\n",
    "        self.hist.append(score)\n",
    "\n",
    "        if self.mode == 'max':\n",
    "            if max(self.hist) > score:\n",
    "                if len(self.hist) <= self.patience:\n",
    "                    pass\n",
    "                else:\n",
    "                    if self.verbose >0:\n",
    "                        print(\"Epoch %d: early stopping Threshold\" % epoch)\n",
    "                    self.model.stop_training = True\n",
    "                    self.model.set_weights(self.best_weights)\n",
    "            else:\n",
    "                self.hist = self.hist[-1:]\n",
    "                self.best_weights = self.model.get_weights()\n",
    "\n",
    "        else:\n",
    "            if min(self.hist) < score:\n",
    "                if len(self.hist) <= self.patience:\n",
    "                    pass\n",
    "                else:\n",
    "                    if self.verbose >0:\n",
    "                        print(\"Epoch %d: early stopping Threshold\" % epoch)\n",
    "                    self.model.stop_training = True\n",
    "                    self.model.set_weights(self.best_weights)\n",
    "            else:\n",
    "                self.hist = self.hist[-1:]\n",
    "                self.best_weights = self.model.get_weights()\n",
    "            \n",
    "        if len(self.hist) > self.patience:\n",
    "            self.hist.pop(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7ab2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params after 1 hour of tuning\n",
    "tabnet = TabNet(num_features = flat_x[0].shape[1],\n",
    "                output_dim = 128,\n",
    "                feature_dim = 128,\n",
    "                n_step = 2, \n",
    "                relaxation_factor= 2.2,\n",
    "                sparsity_coefficient=2.37e-07,\n",
    "                n_shared = 2,\n",
    "                bn_momentum = 0.9245)\n",
    "\n",
    "\n",
    "# Early stopping based on validation loss    \n",
    "cbs = [\n",
    "    # tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=30, restore_best_weights=False)\n",
    "        EarlyStopByAUCSUM(dataset= [datasets[1],datasets[2], datasets[3]], patience=5)\n",
    "        # ,  MultiValidationCallback([datasets[1],datasets[2], datasets[3]])\n",
    "        ]\n",
    "\n",
    "# Optimiser \n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, clipnorm=10)\n",
    "\n",
    "# Second loss in None because we also output the importances\n",
    "loss = [tf.keras.losses.BinaryCrossentropy()]\n",
    "\n",
    "# Compile the model\n",
    "tabnet.compile(optimizer,\n",
    "               loss=loss\n",
    "            #    metrics = metrics.AUC(name='auc', curve='ROC')\n",
    "            #    ,metrics=[metrics.AUC(name='auc', curve='ROC'), metrics.AUC(name='ap', curve='PR')]\n",
    "               )\n",
    "\n",
    "# Train the model\n",
    "tabnet.fit(datasets[2], \n",
    "           epochs=10, \n",
    "           validation_data=datasets[3],\n",
    "           callbacks=cbs,\n",
    "           verbose=0,\n",
    "          class_weight={\n",
    "              0:1,\n",
    "              1: 10\n",
    "          })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982242eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "val_preds, val_imps = tabnet.predict(datasets[1])\n",
    "\n",
    "\n",
    "print('Test ROC AUC', np.round(roc_auc_score(y[1], val_preds), 4))\n",
    "print('Test PR AUC', np.round(average_precision_score(y[1], val_preds), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37110e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-14 10:15:34,536] A new study created in memory with name: TabNet optimization\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003567934036254883,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 30,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 100,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1bc7a0b06f142b09e37f9628f1382fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch0\t['loss: 0.178', 'val2_auc: 0.646', 'val3_auc: 0.624', 'val4_auc: 0.639', 'sum_auc: 1.909']\n",
      "Epoch1\t['loss: 0.166', 'val2_auc: 0.692', 'val3_auc: 0.657', 'val4_auc: 0.695', 'sum_auc: 2.044']\n",
      "Epoch2\t['loss: 0.163', 'val2_auc: 0.707', 'val3_auc: 0.652', 'val4_auc: 0.653', 'sum_auc: 2.012']\n",
      "Epoch3\t['loss: 0.159', 'val2_auc: 0.731', 'val3_auc: 0.672', 'val4_auc: 0.635', 'sum_auc: 2.038']\n",
      "Epoch4\t['loss: 0.157', 'val2_auc: 0.732', 'val3_auc: 0.679', 'val4_auc: 0.705', 'sum_auc: 2.116']\n",
      "Epoch5\t['loss: 0.156', 'val2_auc: 0.737', 'val3_auc: 0.661', 'val4_auc: 0.663', 'sum_auc: 2.062']\n",
      "Epoch6\t['loss: 0.154', 'val2_auc: 0.749', 'val3_auc: 0.660', 'val4_auc: 0.670', 'sum_auc: 2.079']\n",
      "Epoch7\t['loss: 0.153', 'val2_auc: 0.738', 'val3_auc: 0.674', 'val4_auc: 0.665', 'sum_auc: 2.076']\n",
      "Epoch8\t['loss: 0.153', 'val2_auc: 0.742', 'val3_auc: 0.672', 'val4_auc: 0.717', 'sum_auc: 2.132']\n",
      "Epoch9\t['loss: 0.151', 'val2_auc: 0.753', 'val3_auc: 0.678', 'val4_auc: 0.685', 'sum_auc: 2.116']\n",
      "[I 2023-07-14 10:25:14,845] Trial 0 finished with value: 2.1157 and parameters: {'feature_dim': 128, 'n_step': 7, 'n_shared': 1, 'relaxation_factor': 1.6, 'sparsity_coefficient': 0.0020194847589782936, 'bn_momentum': 0.9520714004434059}. Best is trial 0 with value: 2.1157.\n",
      "Epoch0\t['loss: 0.219', 'val2_auc: 0.713', 'val3_auc: 0.679', 'val4_auc: 0.704', 'sum_auc: 2.097']\n",
      "Epoch1\t['loss: 0.156', 'val2_auc: 0.761', 'val3_auc: 0.720', 'val4_auc: 0.736', 'sum_auc: 2.217']\n",
      "Epoch2\t['loss: 0.145', 'val2_auc: 0.776', 'val3_auc: 0.696', 'val4_auc: 0.628', 'sum_auc: 2.100']\n",
      "Epoch3\t['loss: 0.141', 'val2_auc: 0.778', 'val3_auc: 0.683', 'val4_auc: 0.628', 'sum_auc: 2.089']\n",
      "Epoch4\t['loss: 0.140', 'val2_auc: 0.789', 'val3_auc: 0.714', 'val4_auc: 0.583', 'sum_auc: 2.086']\n",
      "Epoch5\t['loss: 0.138', 'val2_auc: 0.787', 'val3_auc: 0.702', 'val4_auc: 0.593', 'sum_auc: 2.082']\n",
      "Epoch6\t['loss: 0.138', 'val2_auc: 0.793', 'val3_auc: 0.720', 'val4_auc: 0.645', 'sum_auc: 2.158']\n",
      "Epoch 6: early stopping Threshold\n",
      "[I 2023-07-14 10:27:38,006] Trial 1 finished with value: 2.2173 and parameters: {'feature_dim': 16, 'n_step': 2, 'n_shared': 3, 'relaxation_factor': 1.4, 'sparsity_coefficient': 5.904039938701995e-06, 'bn_momentum': 0.9542147218085345}. Best is trial 1 with value: 2.2173.\n",
      "Epoch0\t['loss: 0.185', 'val2_auc: 0.719', 'val3_auc: 0.639', 'val4_auc: 0.841', 'sum_auc: 2.199']\n",
      "Epoch1\t['loss: 0.165', 'val2_auc: 0.720', 'val3_auc: 0.687', 'val4_auc: 0.723', 'sum_auc: 2.130']\n",
      "Epoch2\t['loss: 0.159', 'val2_auc: 0.715', 'val3_auc: 0.693', 'val4_auc: 0.720', 'sum_auc: 2.128']\n",
      "Epoch3\t['loss: 0.156', 'val2_auc: 0.723', 'val3_auc: 0.663', 'val4_auc: 0.676', 'sum_auc: 2.063']\n",
      "Epoch4\t['loss: 0.153', 'val2_auc: 0.728', 'val3_auc: 0.688', 'val4_auc: 0.635', 'sum_auc: 2.051']\n",
      "Epoch5\t['loss: 0.152', 'val2_auc: 0.743', 'val3_auc: 0.675', 'val4_auc: 0.683', 'sum_auc: 2.101']\n",
      "Epoch 5: early stopping Threshold\n",
      "[I 2023-07-14 10:31:22,161] Trial 2 finished with value: 2.1988 and parameters: {'feature_dim': 128, 'n_step': 4, 'n_shared': 3, 'relaxation_factor': 1.4, 'sparsity_coefficient': 1.2329846259398628e-05, 'bn_momentum': 0.9976585295726172}. Best is trial 1 with value: 2.2173.\n",
      "Epoch0\t['loss: 0.178', 'val2_auc: 0.663', 'val3_auc: 0.633', 'val4_auc: 0.654', 'sum_auc: 1.951']\n",
      "Epoch1\t['loss: 0.163', 'val2_auc: 0.708', 'val3_auc: 0.661', 'val4_auc: 0.685', 'sum_auc: 2.054']\n",
      "Epoch2\t['loss: 0.158', 'val2_auc: 0.729', 'val3_auc: 0.670', 'val4_auc: 0.746', 'sum_auc: 2.145']\n",
      "Epoch3\t['loss: 0.155', 'val2_auc: 0.728', 'val3_auc: 0.657', 'val4_auc: 0.748', 'sum_auc: 2.133']\n",
      "Epoch4\t['loss: 0.154', 'val2_auc: 0.741', 'val3_auc: 0.674', 'val4_auc: 0.766', 'sum_auc: 2.181']\n",
      "Epoch5\t['loss: 0.153', 'val2_auc: 0.731', 'val3_auc: 0.647', 'val4_auc: 0.716', 'sum_auc: 2.094']\n",
      "Epoch6\t['loss: 0.152', 'val2_auc: 0.741', 'val3_auc: 0.662', 'val4_auc: 0.703', 'sum_auc: 2.106']\n",
      "Epoch7\t['loss: 0.151', 'val2_auc: 0.740', 'val3_auc: 0.664', 'val4_auc: 0.658', 'sum_auc: 2.062']\n",
      "Epoch8\t['loss: 0.150', 'val2_auc: 0.746', 'val3_auc: 0.667', 'val4_auc: 0.682', 'sum_auc: 2.095']\n",
      "Epoch9\t['loss: 0.150', 'val2_auc: 0.747', 'val3_auc: 0.666', 'val4_auc: 0.692', 'sum_auc: 2.105']\n",
      "Epoch 9: early stopping Threshold\n",
      "[I 2023-07-14 10:40:50,101] Trial 3 finished with value: 2.1813 and parameters: {'feature_dim': 64, 'n_step': 7, 'n_shared': 1, 'relaxation_factor': 1.3, 'sparsity_coefficient': 4.37369060770961e-06, 'bn_momentum': 0.9635614958395747}. Best is trial 1 with value: 2.2173.\n",
      "Epoch0\t['loss: 0.191', 'val2_auc: 0.605', 'val3_auc: 0.585', 'val4_auc: 0.596', 'sum_auc: 1.786']\n",
      "Epoch1\t['loss: 0.166', 'val2_auc: 0.678', 'val3_auc: 0.663', 'val4_auc: 0.646', 'sum_auc: 1.987']\n",
      "Epoch2\t['loss: 0.161', 'val2_auc: 0.710', 'val3_auc: 0.639', 'val4_auc: 0.654', 'sum_auc: 2.004']\n",
      "Epoch3\t['loss: 0.159', 'val2_auc: 0.712', 'val3_auc: 0.656', 'val4_auc: 0.641', 'sum_auc: 2.009']\n",
      "Epoch4\t['loss: 0.157', 'val2_auc: 0.724', 'val3_auc: 0.646', 'val4_auc: 0.631', 'sum_auc: 2.001']\n",
      "Epoch5\t['loss: 0.155', 'val2_auc: 0.735', 'val3_auc: 0.657', 'val4_auc: 0.709', 'sum_auc: 2.100']\n",
      "Epoch6\t['loss: 0.154', 'val2_auc: 0.736', 'val3_auc: 0.688', 'val4_auc: 0.721', 'sum_auc: 2.144']\n",
      "Epoch7\t['loss: 0.153', 'val2_auc: 0.739', 'val3_auc: 0.699', 'val4_auc: 0.673', 'sum_auc: 2.110']\n",
      "Epoch8\t['loss: 0.153', 'val2_auc: 0.731', 'val3_auc: 0.676', 'val4_auc: 0.736', 'sum_auc: 2.143']\n",
      "Epoch9\t['loss: 0.153', 'val2_auc: 0.729', 'val3_auc: 0.671', 'val4_auc: 0.762', 'sum_auc: 2.162']\n",
      "[I 2023-07-14 10:46:44,044] Trial 4 finished with value: 2.1619 and parameters: {'feature_dim': 32, 'n_step': 4, 'n_shared': 1, 'relaxation_factor': 2.7, 'sparsity_coefficient': 4.2045769477471956e-06, 'bn_momentum': 0.9744805336008834}. Best is trial 1 with value: 2.2173.\n",
      "Epoch0\t['loss: 0.188', 'val2_auc: 0.554', 'val3_auc: 0.557', 'val4_auc: 0.574', 'sum_auc: 1.684']\n",
      "Epoch1\t['loss: 0.170', 'val2_auc: 0.593', 'val3_auc: 0.588', 'val4_auc: 0.610', 'sum_auc: 1.791']\n",
      "Epoch2\t['loss: 0.170', 'val2_auc: 0.593', 'val3_auc: 0.565', 'val4_auc: 0.533', 'sum_auc: 1.691']\n",
      "Epoch3\t['loss: 0.169', 'val2_auc: 0.562', 'val3_auc: 0.576', 'val4_auc: 0.600', 'sum_auc: 1.739']\n",
      "Epoch4\t['loss: 0.170', 'val2_auc: 0.571', 'val3_auc: 0.588', 'val4_auc: 0.551', 'sum_auc: 1.710']\n",
      "Epoch5\t['loss: 0.169', 'val2_auc: 0.562', 'val3_auc: 0.564', 'val4_auc: 0.599', 'sum_auc: 1.726']\n",
      "Epoch6\t['loss: 0.169', 'val2_auc: 0.578', 'val3_auc: 0.559', 'val4_auc: 0.575', 'sum_auc: 1.711']\n",
      "Epoch 6: early stopping Threshold\n",
      "[I 2023-07-14 10:54:23,938] Trial 5 finished with value: 1.7912 and parameters: {'feature_dim': 64, 'n_step': 8, 'n_shared': 1, 'relaxation_factor': 2.9000000000000004, 'sparsity_coefficient': 0.0014113645392198222, 'bn_momentum': 0.9005550334444576}. Best is trial 1 with value: 2.2173.\n",
      "Epoch0\t['loss: 0.184', 'val2_auc: 0.654', 'val3_auc: 0.628', 'val4_auc: 0.680', 'sum_auc: 1.962']\n",
      "Epoch1\t['loss: 0.165', 'val2_auc: 0.712', 'val3_auc: 0.666', 'val4_auc: 0.670', 'sum_auc: 2.048']\n",
      "Epoch2\t['loss: 0.160', 'val2_auc: 0.727', 'val3_auc: 0.676', 'val4_auc: 0.655', 'sum_auc: 2.058']\n",
      "Epoch3\t['loss: 0.156', 'val2_auc: 0.730', 'val3_auc: 0.668', 'val4_auc: 0.582', 'sum_auc: 1.981']\n",
      "Epoch4\t['loss: 0.155', 'val2_auc: 0.738', 'val3_auc: 0.683', 'val4_auc: 0.679', 'sum_auc: 2.101']\n",
      "Epoch5\t['loss: 0.153', 'val2_auc: 0.753', 'val3_auc: 0.681', 'val4_auc: 0.751', 'sum_auc: 2.185']\n",
      "Epoch6\t['loss: 0.151', 'val2_auc: 0.749', 'val3_auc: 0.664', 'val4_auc: 0.633', 'sum_auc: 2.046']\n",
      "Epoch7\t['loss: 0.149', 'val2_auc: 0.739', 'val3_auc: 0.673', 'val4_auc: 0.631', 'sum_auc: 2.042']\n",
      "Epoch8\t['loss: 0.149', 'val2_auc: 0.755', 'val3_auc: 0.670', 'val4_auc: 0.680', 'sum_auc: 2.105']\n",
      "Epoch9\t['loss: 0.148', 'val2_auc: 0.751', 'val3_auc: 0.668', 'val4_auc: 0.602', 'sum_auc: 2.022']\n",
      "[I 2023-07-14 11:04:58,597] Trial 6 finished with value: 2.0218 and parameters: {'feature_dim': 256, 'n_step': 6, 'n_shared': 4, 'relaxation_factor': 1.2, 'sparsity_coefficient': 1.774451271100977e-06, 'bn_momentum': 0.9387788237552044}. Best is trial 1 with value: 2.2173.\n",
      "Epoch0\t['loss: 0.194', 'val2_auc: 0.596', 'val3_auc: 0.595', 'val4_auc: 0.611', 'sum_auc: 1.801']\n",
      "Epoch1\t['loss: 0.168', 'val2_auc: 0.621', 'val3_auc: 0.616', 'val4_auc: 0.646', 'sum_auc: 1.883']\n",
      "Epoch2\t['loss: 0.164', 'val2_auc: 0.697', 'val3_auc: 0.659', 'val4_auc: 0.654', 'sum_auc: 2.011']\n",
      "Epoch3\t['loss: 0.160', 'val2_auc: 0.690', 'val3_auc: 0.660', 'val4_auc: 0.664', 'sum_auc: 2.014']\n",
      "Epoch4\t['loss: 0.158', 'val2_auc: 0.715', 'val3_auc: 0.669', 'val4_auc: 0.688', 'sum_auc: 2.071']\n",
      "Epoch5\t['loss: 0.156', 'val2_auc: 0.726', 'val3_auc: 0.653', 'val4_auc: 0.685', 'sum_auc: 2.063']\n",
      "Epoch6\t['loss: 0.154', 'val2_auc: 0.735', 'val3_auc: 0.680', 'val4_auc: 0.700', 'sum_auc: 2.114']\n",
      "Epoch7\t['loss: 0.154', 'val2_auc: 0.747', 'val3_auc: 0.671', 'val4_auc: 0.723', 'sum_auc: 2.141']\n",
      "Epoch8\t['loss: 0.152', 'val2_auc: 0.750', 'val3_auc: 0.672', 'val4_auc: 0.754', 'sum_auc: 2.176']\n",
      "Epoch9\t['loss: 0.151', 'val2_auc: 0.740', 'val3_auc: 0.671', 'val4_auc: 0.679', 'sum_auc: 2.091']\n",
      "[I 2023-07-14 11:15:24,279] Trial 7 finished with value: 2.0906 and parameters: {'feature_dim': 64, 'n_step': 8, 'n_shared': 1, 'relaxation_factor': 1.7000000000000002, 'sparsity_coefficient': 4.889798676382166e-08, 'bn_momentum': 0.9886773581865012}. Best is trial 1 with value: 2.2173.\n",
      "Epoch0\t['loss: 0.180', 'val2_auc: 0.661', 'val3_auc: 0.645', 'val4_auc: 0.643', 'sum_auc: 1.950']\n",
      "Epoch1\t['loss: 0.164', 'val2_auc: 0.713', 'val3_auc: 0.676', 'val4_auc: 0.681', 'sum_auc: 2.069']\n",
      "Epoch2\t['loss: 0.159', 'val2_auc: 0.725', 'val3_auc: 0.688', 'val4_auc: 0.719', 'sum_auc: 2.132']\n",
      "Epoch3\t['loss: 0.155', 'val2_auc: 0.742', 'val3_auc: 0.669', 'val4_auc: 0.739', 'sum_auc: 2.151']\n",
      "Epoch4\t['loss: 0.153', 'val2_auc: 0.738', 'val3_auc: 0.674', 'val4_auc: 0.677', 'sum_auc: 2.089']\n",
      "Epoch5\t['loss: 0.152', 'val2_auc: 0.743', 'val3_auc: 0.681', 'val4_auc: 0.692', 'sum_auc: 2.116']\n",
      "Epoch6\t['loss: 0.152', 'val2_auc: 0.743', 'val3_auc: 0.669', 'val4_auc: 0.747', 'sum_auc: 2.160']\n",
      "Epoch7\t['loss: 0.152', 'val2_auc: 0.741', 'val3_auc: 0.675', 'val4_auc: 0.694', 'sum_auc: 2.111']\n",
      "Epoch8\t['loss: 0.151', 'val2_auc: 0.742', 'val3_auc: 0.678', 'val4_auc: 0.607', 'sum_auc: 2.028']\n",
      "Epoch9\t['loss: 0.150', 'val2_auc: 0.745', 'val3_auc: 0.673', 'val4_auc: 0.633', 'sum_auc: 2.051']\n",
      "[I 2023-07-14 11:30:36,749] Trial 8 finished with value: 2.0514 and parameters: {'feature_dim': 256, 'n_step': 9, 'n_shared': 2, 'relaxation_factor': 1.2, 'sparsity_coefficient': 0.0003594992955419046, 'bn_momentum': 0.9557556295156283}. Best is trial 1 with value: 2.2173.\n",
      "Epoch0\t['loss: 0.269', 'val2_auc: 0.541', 'val3_auc: 0.528', 'val4_auc: 0.553', 'sum_auc: 1.621']\n",
      "Epoch1\t['loss: 0.173', 'val2_auc: 0.552', 'val3_auc: 0.545', 'val4_auc: 0.539', 'sum_auc: 1.636']\n",
      "Epoch2\t['loss: 0.172', 'val2_auc: 0.591', 'val3_auc: 0.600', 'val4_auc: 0.561', 'sum_auc: 1.752']\n",
      "Epoch3\t['loss: 0.171', 'val2_auc: 0.610', 'val3_auc: 0.571', 'val4_auc: 0.582', 'sum_auc: 1.763']\n",
      "Epoch4\t['loss: 0.169', 'val2_auc: 0.630', 'val3_auc: 0.621', 'val4_auc: 0.636', 'sum_auc: 1.887']\n",
      "Epoch5\t['loss: 0.166', 'val2_auc: 0.681', 'val3_auc: 0.650', 'val4_auc: 0.666', 'sum_auc: 1.997']\n",
      "Epoch6\t['loss: 0.162', 'val2_auc: 0.706', 'val3_auc: 0.648', 'val4_auc: 0.653', 'sum_auc: 2.007']\n",
      "Epoch7\t['loss: 0.161', 'val2_auc: 0.718', 'val3_auc: 0.673', 'val4_auc: 0.687', 'sum_auc: 2.077']\n",
      "Epoch8\t['loss: 0.159', 'val2_auc: 0.718', 'val3_auc: 0.681', 'val4_auc: 0.702', 'sum_auc: 2.101']\n",
      "Epoch9\t['loss: 0.159', 'val2_auc: 0.714', 'val3_auc: 0.677', 'val4_auc: 0.709', 'sum_auc: 2.100']\n",
      "[I 2023-07-14 11:38:41,372] Trial 9 finished with value: 2.0996 and parameters: {'feature_dim': 16, 'n_step': 6, 'n_shared': 4, 'relaxation_factor': 2.0, 'sparsity_coefficient': 0.0018785579676899528, 'bn_momentum': 0.9282056496721794}. Best is trial 1 with value: 2.2173.\n",
      "Epoch0\t['loss: 0.263', 'val2_auc: 0.568', 'val3_auc: 0.600', 'val4_auc: 0.561', 'sum_auc: 1.729']\n",
      "Epoch1\t['loss: 0.193', 'val2_auc: 0.594', 'val3_auc: 0.609', 'val4_auc: 0.596', 'sum_auc: 1.799']\n",
      "Epoch2\t['loss: 0.176', 'val2_auc: 0.636', 'val3_auc: 0.664', 'val4_auc: 0.670', 'sum_auc: 1.970']\n",
      "Epoch3\t['loss: 0.169', 'val2_auc: 0.649', 'val3_auc: 0.656', 'val4_auc: 0.645', 'sum_auc: 1.950']\n",
      "Epoch4\t['loss: 0.166', 'val2_auc: 0.667', 'val3_auc: 0.645', 'val4_auc: 0.604', 'sum_auc: 1.917']\n",
      "Epoch5\t['loss: 0.164', 'val2_auc: 0.685', 'val3_auc: 0.654', 'val4_auc: 0.610', 'sum_auc: 1.949']\n",
      "Epoch6\t['loss: 0.163', 'val2_auc: 0.670', 'val3_auc: 0.629', 'val4_auc: 0.683', 'sum_auc: 1.983']\n",
      "Epoch7\t['loss: 0.163', 'val2_auc: 0.675', 'val3_auc: 0.654', 'val4_auc: 0.614', 'sum_auc: 1.943']\n",
      "Epoch8\t['loss: 0.161', 'val2_auc: 0.687', 'val3_auc: 0.664', 'val4_auc: 0.658', 'sum_auc: 2.009']\n",
      "Epoch9\t['loss: 0.158', 'val2_auc: 0.697', 'val3_auc: 0.657', 'val4_auc: 0.643', 'sum_auc: 1.997']\n",
      "[I 2023-07-14 11:41:59,017] Trial 10 finished with value: 1.9967 and parameters: {'feature_dim': 16, 'n_step': 2, 'n_shared': 3, 'relaxation_factor': 2.3, 'sparsity_coefficient': 0.030137822426069164, 'bn_momentum': 0.9748275727744757}. Best is trial 1 with value: 2.2173.\n",
      "Epoch0\t['loss: 0.170', 'val2_auc: 0.725', 'val3_auc: 0.619', 'val4_auc: 0.761', 'sum_auc: 2.105']\n",
      "Epoch1\t['loss: 0.149', 'val2_auc: 0.768', 'val3_auc: 0.717', 'val4_auc: 0.791', 'sum_auc: 2.276']\n",
      "Epoch2\t['loss: 0.143', 'val2_auc: 0.786', 'val3_auc: 0.727', 'val4_auc: 0.817', 'sum_auc: 2.330']\n",
      "Epoch3\t['loss: 0.139', 'val2_auc: 0.782', 'val3_auc: 0.735', 'val4_auc: 0.816', 'sum_auc: 2.333']\n",
      "Epoch4\t['loss: 0.137', 'val2_auc: 0.774', 'val3_auc: 0.725', 'val4_auc: 0.819', 'sum_auc: 2.318']\n",
      "Epoch5\t['loss: 0.136', 'val2_auc: 0.777', 'val3_auc: 0.727', 'val4_auc: 0.844', 'sum_auc: 2.348']\n",
      "Epoch6\t['loss: 0.134', 'val2_auc: 0.781', 'val3_auc: 0.731', 'val4_auc: 0.833', 'sum_auc: 2.345']\n",
      "Epoch7\t['loss: 0.134', 'val2_auc: 0.782', 'val3_auc: 0.711', 'val4_auc: 0.836', 'sum_auc: 2.329']\n",
      "Epoch8\t['loss: 0.132', 'val2_auc: 0.782', 'val3_auc: 0.735', 'val4_auc: 0.844', 'sum_auc: 2.361']\n",
      "Epoch9\t['loss: 0.131', 'val2_auc: 0.777', 'val3_auc: 0.705', 'val4_auc: 0.827', 'sum_auc: 2.309']\n",
      "[I 2023-07-14 11:45:26,280] Trial 11 finished with value: 2.309 and parameters: {'feature_dim': 128, 'n_step': 2, 'n_shared': 3, 'relaxation_factor': 1.0, 'sparsity_coefficient': 2.9183306658478137e-05, 'bn_momentum': 0.9998409451668533}. Best is trial 11 with value: 2.309.\n",
      "Epoch0\t['loss: 0.259', 'val2_auc: 0.635', 'val3_auc: 0.556', 'val4_auc: 0.717', 'sum_auc: 1.909']\n",
      "Epoch1\t['loss: 0.160', 'val2_auc: 0.717', 'val3_auc: 0.679', 'val4_auc: 0.799', 'sum_auc: 2.194']\n",
      "Epoch2\t['loss: 0.154', 'val2_auc: 0.752', 'val3_auc: 0.705', 'val4_auc: 0.763', 'sum_auc: 2.221']\n",
      "Epoch3\t['loss: 0.149', 'val2_auc: 0.766', 'val3_auc: 0.721', 'val4_auc: 0.791', 'sum_auc: 2.279']\n",
      "Epoch4\t['loss: 0.145', 'val2_auc: 0.771', 'val3_auc: 0.729', 'val4_auc: 0.755', 'sum_auc: 2.255']\n",
      "Epoch5\t['loss: 0.143', 'val2_auc: 0.778', 'val3_auc: 0.719', 'val4_auc: 0.726', 'sum_auc: 2.223']\n",
      "Epoch6\t['loss: 0.142', 'val2_auc: 0.780', 'val3_auc: 0.728', 'val4_auc: 0.698', 'sum_auc: 2.206']\n",
      "Epoch7\t['loss: 0.141', 'val2_auc: 0.780', 'val3_auc: 0.742', 'val4_auc: 0.701', 'sum_auc: 2.223']\n",
      "Epoch8\t['loss: 0.141', 'val2_auc: 0.781', 'val3_auc: 0.743', 'val4_auc: 0.714', 'sum_auc: 2.239']\n",
      "Epoch 8: early stopping Threshold\n",
      "[I 2023-07-14 11:48:28,266] Trial 12 finished with value: 2.279 and parameters: {'feature_dim': 8, 'n_step': 2, 'n_shared': 3, 'relaxation_factor': 1.0, 'sparsity_coefficient': 5.784176242558977e-05, 'bn_momentum': 0.9983799951856832}. Best is trial 11 with value: 2.309.\n",
      "Epoch0\t['loss: 0.213', 'val2_auc: 0.587', 'val3_auc: 0.623', 'val4_auc: 0.690', 'sum_auc: 1.900']\n",
      "Epoch1\t['loss: 0.167', 'val2_auc: 0.663', 'val3_auc: 0.629', 'val4_auc: 0.789', 'sum_auc: 2.082']\n",
      "Epoch2\t['loss: 0.162', 'val2_auc: 0.737', 'val3_auc: 0.685', 'val4_auc: 0.827', 'sum_auc: 2.248']\n",
      "Epoch3\t['loss: 0.155', 'val2_auc: 0.756', 'val3_auc: 0.697', 'val4_auc: 0.789', 'sum_auc: 2.242']\n",
      "Epoch4\t['loss: 0.150', 'val2_auc: 0.762', 'val3_auc: 0.707', 'val4_auc: 0.762', 'sum_auc: 2.230']\n",
      "Epoch5\t['loss: 0.147', 'val2_auc: 0.764', 'val3_auc: 0.699', 'val4_auc: 0.769', 'sum_auc: 2.232']\n",
      "Epoch6\t['loss: 0.146', 'val2_auc: 0.766', 'val3_auc: 0.686', 'val4_auc: 0.723', 'sum_auc: 2.175']\n",
      "Epoch7\t['loss: 0.144', 'val2_auc: 0.774', 'val3_auc: 0.688', 'val4_auc: 0.707', 'sum_auc: 2.170']\n",
      "Epoch 7: early stopping Threshold\n",
      "[I 2023-07-14 11:52:20,739] Trial 13 finished with value: 2.2484 and parameters: {'feature_dim': 8, 'n_step': 3, 'n_shared': 2, 'relaxation_factor': 1.0, 'sparsity_coefficient': 7.2052398817338e-05, 'bn_momentum': 0.9989749758972103}. Best is trial 11 with value: 2.309.\n",
      "Epoch0\t['loss: 0.253', 'val2_auc: 0.649', 'val3_auc: 0.652', 'val4_auc: 0.685', 'sum_auc: 1.985']\n",
      "Epoch1\t['loss: 0.164', 'val2_auc: 0.719', 'val3_auc: 0.679', 'val4_auc: 0.697', 'sum_auc: 2.095']\n",
      "Epoch2\t['loss: 0.157', 'val2_auc: 0.743', 'val3_auc: 0.670', 'val4_auc: 0.731', 'sum_auc: 2.144']\n",
      "Epoch3\t['loss: 0.153', 'val2_auc: 0.752', 'val3_auc: 0.682', 'val4_auc: 0.704', 'sum_auc: 2.138']\n",
      "Epoch4\t['loss: 0.151', 'val2_auc: 0.758', 'val3_auc: 0.678', 'val4_auc: 0.699', 'sum_auc: 2.135']\n",
      "Epoch5\t['loss: 0.149', 'val2_auc: 0.762', 'val3_auc: 0.687', 'val4_auc: 0.684', 'sum_auc: 2.133']\n",
      "Epoch6\t['loss: 0.147', 'val2_auc: 0.763', 'val3_auc: 0.698', 'val4_auc: 0.694', 'sum_auc: 2.155']\n",
      "Epoch7\t['loss: 0.146', 'val2_auc: 0.768', 'val3_auc: 0.692', 'val4_auc: 0.653', 'sum_auc: 2.114']\n",
      "Epoch8\t['loss: 0.145', 'val2_auc: 0.775', 'val3_auc: 0.694', 'val4_auc: 0.695', 'sum_auc: 2.163']\n",
      "Epoch9\t['loss: 0.144', 'val2_auc: 0.774', 'val3_auc: 0.684', 'val4_auc: 0.689', 'sum_auc: 2.147']\n",
      "[I 2023-07-14 11:58:23,964] Trial 14 finished with value: 2.1474 and parameters: {'feature_dim': 8, 'n_step': 4, 'n_shared': 3, 'relaxation_factor': 1.0, 'sparsity_coefficient': 9.079916451453343e-05, 'bn_momentum': 0.984941258006484}. Best is trial 11 with value: 2.309.\n",
      "Epoch0\t['loss: 0.223', 'val2_auc: 0.689', 'val3_auc: 0.663', 'val4_auc: 0.710', 'sum_auc: 2.062']\n",
      "Epoch1\t['loss: 0.159', 'val2_auc: 0.717', 'val3_auc: 0.675', 'val4_auc: 0.717', 'sum_auc: 2.109']\n",
      "Epoch2\t['loss: 0.156', 'val2_auc: 0.733', 'val3_auc: 0.680', 'val4_auc: 0.705', 'sum_auc: 2.118']\n",
      "Epoch3\t['loss: 0.154', 'val2_auc: 0.736', 'val3_auc: 0.660', 'val4_auc: 0.706', 'sum_auc: 2.101']\n",
      "Epoch4\t['loss: 0.154', 'val2_auc: 0.747', 'val3_auc: 0.653', 'val4_auc: 0.677', 'sum_auc: 2.077']\n",
      "Epoch5\t['loss: 0.150', 'val2_auc: 0.769', 'val3_auc: 0.682', 'val4_auc: 0.606', 'sum_auc: 2.057']\n",
      "Epoch6\t['loss: 0.146', 'val2_auc: 0.776', 'val3_auc: 0.707', 'val4_auc: 0.666', 'sum_auc: 2.150']\n",
      "Epoch7\t['loss: 0.145', 'val2_auc: 0.783', 'val3_auc: 0.691', 'val4_auc: 0.702', 'sum_auc: 2.175']\n",
      "Epoch8\t['loss: 0.144', 'val2_auc: 0.786', 'val3_auc: 0.704', 'val4_auc: 0.573', 'sum_auc: 2.063']\n",
      "Epoch9\t['loss: 0.144', 'val2_auc: 0.778', 'val3_auc: 0.699', 'val4_auc: 0.629', 'sum_auc: 2.106']\n",
      "[I 2023-07-14 12:03:18,491] Trial 15 finished with value: 2.1054 and parameters: {'feature_dim': 8, 'n_step': 3, 'n_shared': 0, 'relaxation_factor': 1.9, 'sparsity_coefficient': 3.299157134450287e-07, 'bn_momentum': 0.9854733986797156}. Best is trial 11 with value: 2.309.\n",
      "Epoch0\t['loss: 0.177', 'val2_auc: 0.758', 'val3_auc: 0.687', 'val4_auc: 0.807', 'sum_auc: 2.252']\n",
      "Epoch1\t['loss: 0.154', 'val2_auc: 0.766', 'val3_auc: 0.693', 'val4_auc: 0.753', 'sum_auc: 2.212']\n",
      "Epoch2\t['loss: 0.147', 'val2_auc: 0.785', 'val3_auc: 0.701', 'val4_auc: 0.678', 'sum_auc: 2.164']\n",
      "Epoch3\t['loss: 0.144', 'val2_auc: 0.792', 'val3_auc: 0.704', 'val4_auc: 0.631', 'sum_auc: 2.126']\n",
      "Epoch4\t['loss: 0.142', 'val2_auc: 0.800', 'val3_auc: 0.692', 'val4_auc: 0.630', 'sum_auc: 2.122']\n",
      "Epoch5\t['loss: 0.140', 'val2_auc: 0.803', 'val3_auc: 0.687', 'val4_auc: 0.686', 'sum_auc: 2.177']\n",
      "Epoch 5: early stopping Threshold\n",
      "[I 2023-07-14 12:05:29,633] Trial 16 finished with value: 2.2524 and parameters: {'feature_dim': 128, 'n_step': 2, 'n_shared': 4, 'relaxation_factor': 2.2, 'sparsity_coefficient': 3.4397490101172444e-05, 'bn_momentum': 0.9978565842017746}. Best is trial 11 with value: 2.309.\n",
      "Epoch0\t['loss: 0.201', 'val2_auc: 0.665', 'val3_auc: 0.660', 'val4_auc: 0.638', 'sum_auc: 1.963']\n",
      "Epoch1\t['loss: 0.163', 'val2_auc: 0.706', 'val3_auc: 0.668', 'val4_auc: 0.703', 'sum_auc: 2.078']\n",
      "Epoch2\t['loss: 0.159', 'val2_auc: 0.720', 'val3_auc: 0.695', 'val4_auc: 0.680', 'sum_auc: 2.096']\n",
      "Epoch3\t['loss: 0.155', 'val2_auc: 0.740', 'val3_auc: 0.687', 'val4_auc: 0.783', 'sum_auc: 2.210']\n",
      "Epoch4\t['loss: 0.152', 'val2_auc: 0.739', 'val3_auc: 0.686', 'val4_auc: 0.693', 'sum_auc: 2.118']\n",
      "Epoch5\t['loss: 0.150', 'val2_auc: 0.740', 'val3_auc: 0.655', 'val4_auc: 0.639', 'sum_auc: 2.035']\n",
      "Epoch6\t['loss: 0.149', 'val2_auc: 0.749', 'val3_auc: 0.670', 'val4_auc: 0.616', 'sum_auc: 2.035']\n",
      "Epoch7\t['loss: 0.148', 'val2_auc: 0.749', 'val3_auc: 0.693', 'val4_auc: 0.600', 'sum_auc: 2.042']\n",
      "Epoch8\t['loss: 0.146', 'val2_auc: 0.769', 'val3_auc: 0.673', 'val4_auc: 0.681', 'sum_auc: 2.123']\n",
      "Epoch 8: early stopping Threshold\n",
      "[I 2023-07-14 12:09:52,371] Trial 17 finished with value: 2.2099 and parameters: {'feature_dim': 32, 'n_step': 3, 'n_shared': 2, 'relaxation_factor': 1.6, 'sparsity_coefficient': 3.035389476366229e-07, 'bn_momentum': 0.9720779704365353}. Best is trial 11 with value: 2.309.\n",
      "Epoch0\t['loss: 0.209', 'val2_auc: 0.610', 'val3_auc: 0.612', 'val4_auc: 0.616', 'sum_auc: 1.837']\n",
      "Epoch1\t['loss: 0.168', 'val2_auc: 0.688', 'val3_auc: 0.679', 'val4_auc: 0.754', 'sum_auc: 2.121']\n",
      "Epoch2\t['loss: 0.161', 'val2_auc: 0.720', 'val3_auc: 0.687', 'val4_auc: 0.743', 'sum_auc: 2.149']\n",
      "Epoch3\t['loss: 0.157', 'val2_auc: 0.737', 'val3_auc: 0.683', 'val4_auc: 0.695', 'sum_auc: 2.114']\n",
      "Epoch4\t['loss: 0.154', 'val2_auc: 0.742', 'val3_auc: 0.693', 'val4_auc: 0.751', 'sum_auc: 2.186']\n",
      "Epoch7\t['loss: 0.150', 'val2_auc: 0.755', 'val3_auc: 0.673', 'val4_auc: 0.746', 'sum_auc: 2.175']\n",
      "Epoch8\t['loss: 0.150', 'val2_auc: 0.756', 'val3_auc: 0.680', 'val4_auc: 0.749', 'sum_auc: 2.185']\n",
      "Epoch9\t['loss: 0.149', 'val2_auc: 0.757', 'val3_auc: 0.688', 'val4_auc: 0.707', 'sum_auc: 2.153']\n",
      "Epoch 9: early stopping Threshold\n",
      "[I 2023-07-14 12:17:05,488] Trial 18 finished with value: 2.1856 and parameters: {'feature_dim': 8, 'n_step': 5, 'n_shared': 3, 'relaxation_factor': 1.0, 'sparsity_coefficient': 0.00017986076956381768, 'bn_momentum': 0.9865259063582231}. Best is trial 11 with value: 2.309.\n",
      "Epoch0\t['loss: 0.195', 'val2_auc: 0.553', 'val3_auc: 0.568', 'val4_auc: 0.545', 'sum_auc: 1.666']\n",
      "Epoch1\t['loss: 0.172', 'val2_auc: 0.598', 'val3_auc: 0.588', 'val4_auc: 0.579', 'sum_auc: 1.765']\n",
      "Epoch2\t['loss: 0.169', 'val2_auc: 0.618', 'val3_auc: 0.618', 'val4_auc: 0.634', 'sum_auc: 1.870']\n",
      "Epoch3\t['loss: 0.167', 'val2_auc: 0.661', 'val3_auc: 0.633', 'val4_auc: 0.644', 'sum_auc: 1.938']\n",
      "Epoch4\t['loss: 0.166', 'val2_auc: 0.670', 'val3_auc: 0.649', 'val4_auc: 0.735', 'sum_auc: 2.054']\n",
      "Epoch5\t['loss: 0.164', 'val2_auc: 0.688', 'val3_auc: 0.658', 'val4_auc: 0.702', 'sum_auc: 2.048']\n",
      "Epoch6\t['loss: 0.160', 'val2_auc: 0.701', 'val3_auc: 0.648', 'val4_auc: 0.642', 'sum_auc: 1.990']\n",
      "Epoch7\t['loss: 0.159', 'val2_auc: 0.704', 'val3_auc: 0.633', 'val4_auc: 0.637', 'sum_auc: 1.974']\n",
      "Epoch8\t['loss: 0.157', 'val2_auc: 0.719', 'val3_auc: 0.663', 'val4_auc: 0.629', 'sum_auc: 2.011']\n",
      "Epoch9\t['loss: 0.155', 'val2_auc: 0.717', 'val3_auc: 0.662', 'val4_auc: 0.757', 'sum_auc: 2.136']\n",
      "[I 2023-07-14 12:24:15,747] Trial 19 finished with value: 2.1358 and parameters: {'feature_dim': 128, 'n_step': 5, 'n_shared': 4, 'relaxation_factor': 2.5, 'sparsity_coefficient': 3.5352191023539376e-05, 'bn_momentum': 0.9649376516617404}. Best is trial 11 with value: 2.309.\n",
      "Epoch0\t['loss: 0.216', 'val2_auc: 0.657', 'val3_auc: 0.631', 'val4_auc: 0.658', 'sum_auc: 1.947']\n",
      "Epoch1\t['loss: 0.164', 'val2_auc: 0.704', 'val3_auc: 0.671', 'val4_auc: 0.701', 'sum_auc: 2.075']\n",
      "Epoch2\t['loss: 0.160', 'val2_auc: 0.716', 'val3_auc: 0.667', 'val4_auc: 0.731', 'sum_auc: 2.114']\n",
      "Epoch3\t['loss: 0.158', 'val2_auc: 0.718', 'val3_auc: 0.670', 'val4_auc: 0.715', 'sum_auc: 2.104']\n",
      "Epoch4\t['loss: 0.157', 'val2_auc: 0.731', 'val3_auc: 0.683', 'val4_auc: 0.785', 'sum_auc: 2.199']\n",
      "Epoch5\t['loss: 0.155', 'val2_auc: 0.735', 'val3_auc: 0.685', 'val4_auc: 0.802', 'sum_auc: 2.221']\n",
      "Epoch6\t['loss: 0.154', 'val2_auc: 0.730', 'val3_auc: 0.673', 'val4_auc: 0.718', 'sum_auc: 2.121']\n",
      "Epoch7\t['loss: 0.153', 'val2_auc: 0.734', 'val3_auc: 0.664', 'val4_auc: 0.745', 'sum_auc: 2.143']\n",
      "Epoch8\t['loss: 0.152', 'val2_auc: 0.742', 'val3_auc: 0.676', 'val4_auc: 0.736', 'sum_auc: 2.155']\n",
      "Epoch9\t['loss: 0.152', 'val2_auc: 0.741', 'val3_auc: 0.663', 'val4_auc: 0.650', 'sum_auc: 2.054']\n",
      "[I 2023-07-14 12:29:05,825] Trial 20 finished with value: 2.0535 and parameters: {'feature_dim': 8, 'n_step': 3, 'n_shared': 2, 'relaxation_factor': 1.8, 'sparsity_coefficient': 1.4284358049601092e-08, 'bn_momentum': 0.9898273393543359}. Best is trial 11 with value: 2.309.\n",
      "Epoch0\t['loss: 0.177', 'val2_auc: 0.746', 'val3_auc: 0.677', 'val4_auc: 0.792', 'sum_auc: 2.215']\n",
      "Epoch1\t['loss: 0.154', 'val2_auc: 0.763', 'val3_auc: 0.664', 'val4_auc: 0.728', 'sum_auc: 2.155']\n",
      "Epoch2\t['loss: 0.149', 'val2_auc: 0.778', 'val3_auc: 0.715', 'val4_auc: 0.679', 'sum_auc: 2.173']\n",
      "Epoch3\t['loss: 0.143', 'val2_auc: 0.788', 'val3_auc: 0.731', 'val4_auc: 0.713', 'sum_auc: 2.231']\n",
      "Epoch4\t['loss: 0.141', 'val2_auc: 0.787', 'val3_auc: 0.719', 'val4_auc: 0.685', 'sum_auc: 2.192']\n",
      "Epoch5\t['loss: 0.140', 'val2_auc: 0.789', 'val3_auc: 0.731', 'val4_auc: 0.670', 'sum_auc: 2.191']\n",
      "Epoch6\t['loss: 0.138', 'val2_auc: 0.785', 'val3_auc: 0.732', 'val4_auc: 0.690', 'sum_auc: 2.208']\n",
      "Epoch7\t['loss: 0.138', 'val2_auc: 0.800', 'val3_auc: 0.719', 'val4_auc: 0.728', 'sum_auc: 2.246']\n",
      "Epoch8\t['loss: 0.136', 'val2_auc: 0.805', 'val3_auc: 0.722', 'val4_auc: 0.684', 'sum_auc: 2.211']\n",
      "Epoch9\t['loss: 0.135', 'val2_auc: 0.806', 'val3_auc: 0.722', 'val4_auc: 0.715', 'sum_auc: 2.243']\n",
      "[I 2023-07-14 12:32:40,688] Trial 21 finished with value: 2.2428 and parameters: {'feature_dim': 128, 'n_step': 2, 'n_shared': 4, 'relaxation_factor': 2.2, 'sparsity_coefficient': 2.7019851188421078e-05, 'bn_momentum': 0.9982357452152011}. Best is trial 11 with value: 2.309.\n",
      "Epoch0\t['loss: 0.176', 'val2_auc: 0.753', 'val3_auc: 0.687', 'val4_auc: 0.852', 'sum_auc: 2.292']\n",
      "Epoch1\t['loss: 0.155', 'val2_auc: 0.757', 'val3_auc: 0.670', 'val4_auc: 0.833', 'sum_auc: 2.260']\n",
      "Epoch2\t['loss: 0.150', 'val2_auc: 0.771', 'val3_auc: 0.680', 'val4_auc: 0.768', 'sum_auc: 2.219']\n",
      "Epoch3\t['loss: 0.144', 'val2_auc: 0.779', 'val3_auc: 0.700', 'val4_auc: 0.699', 'sum_auc: 2.178']\n",
      "Epoch4\t['loss: 0.143', 'val2_auc: 0.780', 'val3_auc: 0.677', 'val4_auc: 0.748', 'sum_auc: 2.205']\n",
      "Epoch5\t['loss: 0.141', 'val2_auc: 0.799', 'val3_auc: 0.718', 'val4_auc: 0.668', 'sum_auc: 2.185']\n",
      "Epoch 5: early stopping Threshold\n",
      "[I 2023-07-14 12:34:49,889] Trial 22 finished with value: 2.2915 and parameters: {'feature_dim': 128, 'n_step': 2, 'n_shared': 4, 'relaxation_factor': 2.2, 'sparsity_coefficient': 1.6003201090865092e-05, 'bn_momentum': 0.9993450840488735}. Best is trial 11 with value: 2.309.\n",
      "Epoch0\t['loss: 0.178', 'val2_auc: 0.699', 'val3_auc: 0.668', 'val4_auc: 0.761', 'sum_auc: 2.127']\n",
      "Epoch1\t['loss: 0.159', 'val2_auc: 0.707', 'val3_auc: 0.706', 'val4_auc: 0.723', 'sum_auc: 2.135']\n",
      "Epoch2\t['loss: 0.154', 'val2_auc: 0.770', 'val3_auc: 0.685', 'val4_auc: 0.664', 'sum_auc: 2.119']\n",
      "Epoch3\t['loss: 0.150', 'val2_auc: 0.769', 'val3_auc: 0.680', 'val4_auc: 0.652', 'sum_auc: 2.102']\n",
      "Epoch4\t['loss: 0.147', 'val2_auc: 0.770', 'val3_auc: 0.685', 'val4_auc: 0.625', 'sum_auc: 2.080']\n",
      "Epoch5\t['loss: 0.145', 'val2_auc: 0.788', 'val3_auc: 0.703', 'val4_auc: 0.583', 'sum_auc: 2.074']\n",
      "Epoch6\t['loss: 0.144', 'val2_auc: 0.792', 'val3_auc: 0.706', 'val4_auc: 0.552', 'sum_auc: 2.050']\n",
      "Epoch 6: early stopping Threshold\n",
      "[I 2023-07-14 12:37:18,876] Trial 23 finished with value: 2.1353 and parameters: {'feature_dim': 128, 'n_step': 2, 'n_shared': 3, 'relaxation_factor': 2.5, 'sparsity_coefficient': 0.00022722049152320005, 'bn_momentum': 0.9810702699153386}. Best is trial 11 with value: 2.309.\n",
      "Epoch0\t['loss: 0.184', 'val2_auc: 0.633', 'val3_auc: 0.609', 'val4_auc: 0.647', 'sum_auc: 1.889']\n",
      "Epoch1\t['loss: 0.164', 'val2_auc: 0.700', 'val3_auc: 0.689', 'val4_auc: 0.754', 'sum_auc: 2.143']\n",
      "Epoch2\t['loss: 0.157', 'val2_auc: 0.743', 'val3_auc: 0.675', 'val4_auc: 0.581', 'sum_auc: 2.000']\n",
      "Epoch3\t['loss: 0.154', 'val2_auc: 0.750', 'val3_auc: 0.670', 'val4_auc: 0.636', 'sum_auc: 2.056']\n",
      "Epoch4\t['loss: 0.151', 'val2_auc: 0.748', 'val3_auc: 0.690', 'val4_auc: 0.624', 'sum_auc: 2.062']\n",
      "Epoch5\t['loss: 0.150', 'val2_auc: 0.757', 'val3_auc: 0.691', 'val4_auc: 0.652', 'sum_auc: 2.099']\n",
      "Epoch6\t['loss: 0.148', 'val2_auc: 0.758', 'val3_auc: 0.684', 'val4_auc: 0.588', 'sum_auc: 2.030']\n",
      "Epoch 6: early stopping Threshold\n",
      "[I 2023-07-14 12:40:48,334] Trial 24 finished with value: 2.1433 and parameters: {'feature_dim': 128, 'n_step': 3, 'n_shared': 4, 'relaxation_factor': 2.0, 'sparsity_coefficient': 1.4932931214607998e-05, 'bn_momentum': 0.9920816393617481}. Best is trial 11 with value: 2.309.\n",
      "Epoch0\t['loss: 0.188', 'val2_auc: 0.611', 'val3_auc: 0.590', 'val4_auc: 0.611', 'sum_auc: 1.811']\n",
      "Epoch1\t['loss: 0.166', 'val2_auc: 0.698', 'val3_auc: 0.642', 'val4_auc: 0.638', 'sum_auc: 1.978']\n",
      "Epoch2\t['loss: 0.159', 'val2_auc: 0.721', 'val3_auc: 0.663', 'val4_auc: 0.675', 'sum_auc: 2.059']\n",
      "Epoch3\t['loss: 0.156', 'val2_auc: 0.743', 'val3_auc: 0.679', 'val4_auc: 0.641', 'sum_auc: 2.063']\n",
      "Epoch4\t['loss: 0.153', 'val2_auc: 0.734', 'val3_auc: 0.675', 'val4_auc: 0.629', 'sum_auc: 2.038']\n",
      "Epoch5\t['loss: 0.151', 'val2_auc: 0.743', 'val3_auc: 0.687', 'val4_auc: 0.629', 'sum_auc: 2.059']\n",
      "Epoch9\t['loss: 0.149', 'val2_auc: 0.753', 'val3_auc: 0.672', 'val4_auc: 0.739', 'sum_auc: 2.164']\n",
      "[I 2023-07-14 12:47:03,349] Trial 25 finished with value: 2.1641 and parameters: {'feature_dim': 128, 'n_step': 4, 'n_shared': 3, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1.3562069543509214e-06, 'bn_momentum': 0.9788171689771782}. Best is trial 11 with value: 2.309.\n",
      "Epoch0\t['loss: 0.192', 'val2_auc: 0.713', 'val3_auc: 0.667', 'val4_auc: 0.709', 'sum_auc: 2.088']\n",
      "Epoch1\t['loss: 0.156', 'val2_auc: 0.759', 'val3_auc: 0.704', 'val4_auc: 0.723', 'sum_auc: 2.186']\n",
      "Epoch2\t['loss: 0.148', 'val2_auc: 0.771', 'val3_auc: 0.717', 'val4_auc: 0.689', 'sum_auc: 2.177']\n",
      "Epoch3\t['loss: 0.143', 'val2_auc: 0.790', 'val3_auc: 0.701', 'val4_auc: 0.706', 'sum_auc: 2.197']\n",
      "Epoch4\t['loss: 0.141', 'val2_auc: 0.798', 'val3_auc: 0.713', 'val4_auc: 0.778', 'sum_auc: 2.290']\n",
      "Epoch5\t['loss: 0.139', 'val2_auc: 0.805', 'val3_auc: 0.709', 'val4_auc: 0.675', 'sum_auc: 2.189']\n",
      "Epoch6\t['loss: 0.138', 'val2_auc: 0.806', 'val3_auc: 0.727', 'val4_auc: 0.701', 'sum_auc: 2.234']\n",
      "Epoch7\t['loss: 0.136', 'val2_auc: 0.811', 'val3_auc: 0.717', 'val4_auc: 0.732', 'sum_auc: 2.260']\n",
      "Epoch8\t['loss: 0.135', 'val2_auc: 0.810', 'val3_auc: 0.702', 'val4_auc: 0.573', 'sum_auc: 2.085']\n",
      "Epoch9\t['loss: 0.134', 'val2_auc: 0.814', 'val3_auc: 0.710', 'val4_auc: 0.596', 'sum_auc: 2.119']\n",
      "Epoch 9: early stopping Threshold\n",
      "[I 2023-07-14 12:50:19,552] Trial 26 finished with value: 2.2903 and parameters: {'feature_dim': 32, 'n_step': 2, 'n_shared': 3, 'relaxation_factor': 1.2, 'sparsity_coefficient': 0.0004717656366560386, 'bn_momentum': 0.9919221494004509}. Best is trial 11 with value: 2.309.\n",
      "Epoch0\t['loss: 0.213', 'val2_auc: 0.597', 'val3_auc: 0.590', 'val4_auc: 0.620', 'sum_auc: 1.808']\n",
      "Epoch1\t['loss: 0.166', 'val2_auc: 0.699', 'val3_auc: 0.667', 'val4_auc: 0.626', 'sum_auc: 1.992']\n",
      "Epoch2\t['loss: 0.162', 'val2_auc: 0.708', 'val3_auc: 0.647', 'val4_auc: 0.648', 'sum_auc: 2.003']\n",
      "Epoch3\t['loss: 0.159', 'val2_auc: 0.718', 'val3_auc: 0.679', 'val4_auc: 0.627', 'sum_auc: 2.025']\n",
      "Epoch4\t['loss: 0.158', 'val2_auc: 0.723', 'val3_auc: 0.673', 'val4_auc: 0.607', 'sum_auc: 2.003']\n",
      "Epoch5\t['loss: 0.155', 'val2_auc: 0.722', 'val3_auc: 0.662', 'val4_auc: 0.701', 'sum_auc: 2.085']\n",
      "Epoch6\t['loss: 0.154', 'val2_auc: 0.727', 'val3_auc: 0.664', 'val4_auc: 0.615', 'sum_auc: 2.005']\n",
      "Epoch7\t['loss: 0.154', 'val2_auc: 0.742', 'val3_auc: 0.666', 'val4_auc: 0.674', 'sum_auc: 2.081']\n",
      "Epoch8\t['loss: 0.153', 'val2_auc: 0.744', 'val3_auc: 0.676', 'val4_auc: 0.828', 'sum_auc: 2.247']\n",
      "Epoch9\t['loss: 0.152', 'val2_auc: 0.738', 'val3_auc: 0.664', 'val4_auc: 0.654', 'sum_auc: 2.056']\n",
      "[I 2023-07-14 12:55:03,220] Trial 27 finished with value: 2.0562 and parameters: {'feature_dim': 32, 'n_step': 3, 'n_shared': 4, 'relaxation_factor': 2.5, 'sparsity_coefficient': 0.0006743250059567324, 'bn_momentum': 0.9914689867277048}. Best is trial 11 with value: 2.309.\n",
      "Epoch0\t['loss: 0.209', 'val2_auc: 0.683', 'val3_auc: 0.668', 'val4_auc: 0.721', 'sum_auc: 2.072']\n",
      "Epoch1\t['loss: 0.159', 'val2_auc: 0.754', 'val3_auc: 0.707', 'val4_auc: 0.747', 'sum_auc: 2.208']\n",
      "Epoch2\t['loss: 0.149', 'val2_auc: 0.777', 'val3_auc: 0.686', 'val4_auc: 0.650', 'sum_auc: 2.113']\n",
      "Epoch3\t['loss: 0.144', 'val2_auc: 0.784', 'val3_auc: 0.665', 'val4_auc: 0.621', 'sum_auc: 2.071']\n",
      "Epoch4\t['loss: 0.143', 'val2_auc: 0.796', 'val3_auc: 0.675', 'val4_auc: 0.603', 'sum_auc: 2.074']\n",
      "Epoch5\t['loss: 0.141', 'val2_auc: 0.800', 'val3_auc: 0.686', 'val4_auc: 0.604', 'sum_auc: 2.090']\n",
      "Epoch6\t['loss: 0.139', 'val2_auc: 0.804', 'val3_auc: 0.678', 'val4_auc: 0.628', 'sum_auc: 2.110']\n",
      "Epoch 6: early stopping Threshold\n",
      "[I 2023-07-14 12:57:31,975] Trial 28 finished with value: 2.2074 and parameters: {'feature_dim': 32, 'n_step': 2, 'n_shared': 2, 'relaxation_factor': 2.3, 'sparsity_coefficient': 0.00010496706438819807, 'bn_momentum': 0.981105562952832}. Best is trial 11 with value: 2.309.\n",
      "Epoch0\t['loss: 0.203', 'val2_auc: 0.709', 'val3_auc: 0.666', 'val4_auc: 0.720', 'sum_auc: 2.094']\n",
      "Epoch1\t['loss: 0.172', 'val2_auc: 0.737', 'val3_auc: 0.680', 'val4_auc: 0.713', 'sum_auc: 2.130']\n",
      "Epoch2\t['loss: 0.167', 'val2_auc: 0.740', 'val3_auc: 0.677', 'val4_auc: 0.743', 'sum_auc: 2.159']\n",
      "Epoch3\t['loss: 0.165', 'val2_auc: 0.748', 'val3_auc: 0.667', 'val4_auc: 0.735', 'sum_auc: 2.149']\n",
      "Epoch4\t['loss: 0.162', 'val2_auc: 0.741', 'val3_auc: 0.683', 'val4_auc: 0.744', 'sum_auc: 2.169']\n",
      "Epoch5\t['loss: 0.161', 'val2_auc: 0.740', 'val3_auc: 0.653', 'val4_auc: 0.725', 'sum_auc: 2.117']\n",
      "Epoch6\t['loss: 0.160', 'val2_auc: 0.743', 'val3_auc: 0.661', 'val4_auc: 0.768', 'sum_auc: 2.173']\n",
      "Epoch7\t['loss: 0.159', 'val2_auc: 0.747', 'val3_auc: 0.661', 'val4_auc: 0.737', 'sum_auc: 2.145']\n",
      "Epoch8\t['loss: 0.158', 'val2_auc: 0.748', 'val3_auc: 0.658', 'val4_auc: 0.734', 'sum_auc: 2.139']\n",
      "Epoch9\t['loss: 0.157', 'val2_auc: 0.747', 'val3_auc: 0.663', 'val4_auc: 0.725', 'sum_auc: 2.135']\n",
      "[I 2023-07-14 13:05:03,220] Trial 29 finished with value: 2.1351 and parameters: {'feature_dim': 32, 'n_step': 5, 'n_shared': 0, 'relaxation_factor': 1.2, 'sparsity_coefficient': 0.010531296310885264, 'bn_momentum': 0.9927324912612053}. Best is trial 11 with value: 2.309.\n",
      "Epoch0\t['loss: 0.196', 'val2_auc: 0.652', 'val3_auc: 0.610', 'val4_auc: 0.624', 'sum_auc: 1.886']\n",
      "Epoch1\t['loss: 0.171', 'val2_auc: 0.689', 'val3_auc: 0.679', 'val4_auc: 0.630', 'sum_auc: 1.998']\n",
      "Epoch2\t['loss: 0.166', 'val2_auc: 0.716', 'val3_auc: 0.667', 'val4_auc: 0.673', 'sum_auc: 2.056']\n",
      "Epoch3\t['loss: 0.163', 'val2_auc: 0.724', 'val3_auc: 0.668', 'val4_auc: 0.710', 'sum_auc: 2.102']\n",
      "Epoch4\t['loss: 0.160', 'val2_auc: 0.746', 'val3_auc: 0.689', 'val4_auc: 0.702', 'sum_auc: 2.137']\n",
      "Epoch5\t['loss: 0.157', 'val2_auc: 0.735', 'val3_auc: 0.681', 'val4_auc: 0.691', 'sum_auc: 2.106']\n",
      "Epoch6\t['loss: 0.156', 'val2_auc: 0.746', 'val3_auc: 0.670', 'val4_auc: 0.716', 'sum_auc: 2.132']\n",
      "Epoch7\t['loss: 0.155', 'val2_auc: 0.746', 'val3_auc: 0.675', 'val4_auc: 0.622', 'sum_auc: 2.043']\n",
      "Epoch8\t['loss: 0.154', 'val2_auc: 0.754', 'val3_auc: 0.690', 'val4_auc: 0.634', 'sum_auc: 2.078']\n",
      "Epoch9\t['loss: 0.153', 'val2_auc: 0.744', 'val3_auc: 0.685', 'val4_auc: 0.665', 'sum_auc: 2.095']\n",
      "Epoch 9: early stopping Threshold\n",
      "[I 2023-07-14 13:11:14,774] Trial 30 finished with value: 2.1369 and parameters: {'feature_dim': 128, 'n_step': 4, 'n_shared': 3, 'relaxation_factor': 1.6, 'sparsity_coefficient': 0.00684467252844028, 'bn_momentum': 0.981983894339528}. Best is trial 11 with value: 2.309.\n",
      "Epoch0\t['loss: 0.174', 'val2_auc: 0.754', 'val3_auc: 0.699', 'val4_auc: 0.862', 'sum_auc: 2.314']\n",
      "Epoch1\t['loss: 0.152', 'val2_auc: 0.755', 'val3_auc: 0.664', 'val4_auc: 0.848', 'sum_auc: 2.268']\n",
      "Epoch2\t['loss: 0.147', 'val2_auc: 0.759', 'val3_auc: 0.674', 'val4_auc: 0.726', 'sum_auc: 2.159']\n",
      "Epoch3\t['loss: 0.143', 'val2_auc: 0.763', 'val3_auc: 0.714', 'val4_auc: 0.732', 'sum_auc: 2.209']\n",
      "Epoch4\t['loss: 0.141', 'val2_auc: 0.765', 'val3_auc: 0.721', 'val4_auc: 0.697', 'sum_auc: 2.182']\n",
      "Epoch5\t['loss: 0.139', 'val2_auc: 0.778', 'val3_auc: 0.699', 'val4_auc: 0.612', 'sum_auc: 2.089']\n",
      "Epoch 5: early stopping Threshold\n",
      "[I 2023-07-14 13:14:07,928] Trial 31 finished with value: 2.3143 and parameters: {'feature_dim': 256, 'n_step': 2, 'n_shared': 3, 'relaxation_factor': 1.1, 'sparsity_coefficient': 0.0002987212968111641, 'bn_momentum': 0.9995243335086753}. Best is trial 31 with value: 2.3143.\n",
      "Epoch0\t['loss: 0.173', 'val2_auc: 0.765', 'val3_auc: 0.701', 'val4_auc: 0.713', 'sum_auc: 2.179']\n",
      "Epoch1\t['loss: 0.151', 'val2_auc: 0.790', 'val3_auc: 0.713', 'val4_auc: 0.654', 'sum_auc: 2.157']\n",
      "Epoch2\t['loss: 0.144', 'val2_auc: 0.791', 'val3_auc: 0.720', 'val4_auc: 0.598', 'sum_auc: 2.109']\n",
      "Epoch3\t['loss: 0.142', 'val2_auc: 0.799', 'val3_auc: 0.716', 'val4_auc: 0.565', 'sum_auc: 2.080']\n",
      "Epoch4\t['loss: 0.141', 'val2_auc: 0.808', 'val3_auc: 0.720', 'val4_auc: 0.545', 'sum_auc: 2.074']\n",
      "Epoch5\t['loss: 0.138', 'val2_auc: 0.809', 'val3_auc: 0.728', 'val4_auc: 0.578', 'sum_auc: 2.115']\n",
      "Epoch 5: early stopping Threshold\n",
      "[I 2023-07-14 13:17:00,575] Trial 32 finished with value: 2.179 and parameters: {'feature_dim': 256, 'n_step': 2, 'n_shared': 3, 'relaxation_factor': 1.2, 'sparsity_coefficient': 0.0006256281995705974, 'bn_momentum': 0.9926137405058187}. Best is trial 31 with value: 2.3143.\n",
      "Epoch3\t['loss: 0.146', 'val2_auc: 0.764', 'val3_auc: 0.678', 'val4_auc: 0.613', 'sum_auc: 2.055']\n",
      "Epoch4\t['loss: 0.144', 'val2_auc: 0.773', 'val3_auc: 0.703', 'val4_auc: 0.713', 'sum_auc: 2.190']\n",
      "Epoch5\t['loss: 0.141', 'val2_auc: 0.791', 'val3_auc: 0.720', 'val4_auc: 0.784', 'sum_auc: 2.295']\n",
      "Epoch 5: early stopping Threshold\n",
      "[I 2023-07-14 13:20:54,070] Trial 33 finished with value: 2.2974 and parameters: {'feature_dim': 256, 'n_step': 3, 'n_shared': 2, 'relaxation_factor': 1.4, 'sparsity_coefficient': 0.0002169622618612959, 'bn_momentum': 0.9991337437435457}. Best is trial 31 with value: 2.3143.\n",
      "Epoch0\t['loss: 0.177', 'val2_auc: 0.703', 'val3_auc: 0.668', 'val4_auc: 0.563', 'sum_auc: 1.934']\n",
      "Epoch1\t['loss: 0.156', 'val2_auc: 0.760', 'val3_auc: 0.727', 'val4_auc: 0.771', 'sum_auc: 2.259']\n",
      "Epoch2\t['loss: 0.150', 'val2_auc: 0.756', 'val3_auc: 0.713', 'val4_auc: 0.795', 'sum_auc: 2.264']\n",
      "Epoch3\t['loss: 0.144', 'val2_auc: 0.740', 'val3_auc: 0.660', 'val4_auc: 0.763', 'sum_auc: 2.163']\n",
      "Epoch4\t['loss: 0.140', 'val2_auc: 0.748', 'val3_auc: 0.676', 'val4_auc: 0.745', 'sum_auc: 2.169']\n",
      "Epoch5\t['loss: 0.140', 'val2_auc: 0.734', 'val3_auc: 0.655', 'val4_auc: 0.633', 'sum_auc: 2.021']\n",
      "Epoch6\t['loss: 0.139', 'val2_auc: 0.730', 'val3_auc: 0.661', 'val4_auc: 0.577', 'sum_auc: 1.967']\n",
      "Epoch7\t['loss: 0.138', 'val2_auc: 0.733', 'val3_auc: 0.657', 'val4_auc: 0.526', 'sum_auc: 1.916']\n",
      "Epoch 7: early stopping Threshold\n",
      "[I 2023-07-14 13:26:01,954] Trial 34 finished with value: 2.2643 and parameters: {'feature_dim': 256, 'n_step': 3, 'n_shared': 2, 'relaxation_factor': 1.3, 'sparsity_coefficient': 1.429998432322495e-05, 'bn_momentum': 0.9998382183112261}. Best is trial 31 with value: 2.3143.\n",
      "Epoch0\t['loss: 0.173', 'val2_auc: 0.723', 'val3_auc: 0.693', 'val4_auc: 0.772', 'sum_auc: 2.189']\n",
      "Epoch1\t['loss: 0.158', 'val2_auc: 0.754', 'val3_auc: 0.695', 'val4_auc: 0.721', 'sum_auc: 2.169']\n",
      "Epoch2\t['loss: 0.153', 'val2_auc: 0.750', 'val3_auc: 0.697', 'val4_auc: 0.743', 'sum_auc: 2.189']\n",
      "Epoch3\t['loss: 0.151', 'val2_auc: 0.762', 'val3_auc: 0.698', 'val4_auc: 0.620', 'sum_auc: 2.081']\n",
      "Epoch4\t['loss: 0.149', 'val2_auc: 0.768', 'val3_auc: 0.687', 'val4_auc: 0.639', 'sum_auc: 2.094']\n",
      "Epoch5\t['loss: 0.147', 'val2_auc: 0.755', 'val3_auc: 0.679', 'val4_auc: 0.670', 'sum_auc: 2.104']\n",
      "Epoch6\t['loss: 0.147', 'val2_auc: 0.775', 'val3_auc: 0.695', 'val4_auc: 0.627', 'sum_auc: 2.096']\n",
      "Epoch7\t['loss: 0.146', 'val2_auc: 0.761', 'val3_auc: 0.695', 'val4_auc: 0.529', 'sum_auc: 1.986']\n",
      "Epoch 7: early stopping Threshold\n",
      "[I 2023-07-14 13:31:09,188] Trial 35 finished with value: 2.1892 and parameters: {'feature_dim': 256, 'n_step': 3, 'n_shared': 2, 'relaxation_factor': 1.5, 'sparsity_coefficient': 0.0001671296188593092, 'bn_momentum': 0.9944829351017186}. Best is trial 31 with value: 2.3143.\n",
      "Epoch0\t['loss: 0.171', 'val2_auc: 0.745', 'val3_auc: 0.665', 'val4_auc: 0.681', 'sum_auc: 2.092']\n",
      "Epoch1\t['loss: 0.152', 'val2_auc: 0.750', 'val3_auc: 0.692', 'val4_auc: 0.656', 'sum_auc: 2.098']\n",
      "Epoch2\t['loss: 0.147', 'val2_auc: 0.770', 'val3_auc: 0.698', 'val4_auc: 0.610', 'sum_auc: 2.078']\n",
      "Epoch3\t['loss: 0.143', 'val2_auc: 0.778', 'val3_auc: 0.708', 'val4_auc: 0.582', 'sum_auc: 2.068']\n",
      "Epoch4\t['loss: 0.141', 'val2_auc: 0.778', 'val3_auc: 0.725', 'val4_auc: 0.625', 'sum_auc: 2.127']\n",
      "Epoch5\t['loss: 0.140', 'val2_auc: 0.792', 'val3_auc: 0.729', 'val4_auc: 0.639', 'sum_auc: 2.160']\n",
      "Epoch6\t['loss: 0.137', 'val2_auc: 0.790', 'val3_auc: 0.746', 'val4_auc: 0.622', 'sum_auc: 2.158']\n",
      "Epoch7\t['loss: 0.137', 'val2_auc: 0.791', 'val3_auc: 0.738', 'val4_auc: 0.639', 'sum_auc: 2.169']\n",
      "Epoch8\t['loss: 0.136', 'val2_auc: 0.796', 'val3_auc: 0.725', 'val4_auc: 0.668', 'sum_auc: 2.189']\n",
      "Epoch9\t['loss: 0.136', 'val2_auc: 0.797', 'val3_auc: 0.735', 'val4_auc: 0.684', 'sum_auc: 2.216']\n",
      "[I 2023-07-14 13:35:51,638] Trial 36 finished with value: 2.2156 and parameters: {'feature_dim': 256, 'n_step': 2, 'n_shared': 2, 'relaxation_factor': 1.4, 'sparsity_coefficient': 9.427920712155374e-06, 'bn_momentum': 0.9882766390299126}. Best is trial 31 with value: 2.3143.\n",
      "Epoch0\t['loss: 0.187', 'val2_auc: 0.720', 'val3_auc: 0.660', 'val4_auc: 0.684', 'sum_auc: 2.065']\n",
      "Epoch1\t['loss: 0.164', 'val2_auc: 0.726', 'val3_auc: 0.676', 'val4_auc: 0.702', 'sum_auc: 2.104']\n",
      "Epoch2\t['loss: 0.157', 'val2_auc: 0.719', 'val3_auc: 0.670', 'val4_auc: 0.631', 'sum_auc: 2.020']\n",
      "Epoch3\t['loss: 0.154', 'val2_auc: 0.751', 'val3_auc: 0.681', 'val4_auc: 0.620', 'sum_auc: 2.053']\n",
      "Epoch4\t['loss: 0.151', 'val2_auc: 0.748', 'val3_auc: 0.694', 'val4_auc: 0.659', 'sum_auc: 2.101']\n",
      "Epoch5\t['loss: 0.150', 'val2_auc: 0.746', 'val3_auc: 0.686', 'val4_auc: 0.661', 'sum_auc: 2.092']\n",
      "Epoch6\t['loss: 0.148', 'val2_auc: 0.754', 'val3_auc: 0.674', 'val4_auc: 0.643', 'sum_auc: 2.071']\n",
      "Epoch 6: early stopping Threshold\n",
      "[I 2023-07-14 13:41:22,391] Trial 37 finished with value: 2.1043 and parameters: {'feature_dim': 256, 'n_step': 4, 'n_shared': 4, 'relaxation_factor': 1.3, 'sparsity_coefficient': 0.0009708550065316644, 'bn_momentum': 0.9946966544179248}. Best is trial 31 with value: 2.3143.\n",
      "Epoch0\t['loss: 0.179', 'val2_auc: 0.734', 'val3_auc: 0.696', 'val4_auc: 0.703', 'sum_auc: 2.133']\n",
      "Epoch1\t['loss: 0.156', 'val2_auc: 0.763', 'val3_auc: 0.685', 'val4_auc: 0.619', 'sum_auc: 2.067']\n",
      "Epoch2\t['loss: 0.152', 'val2_auc: 0.771', 'val3_auc: 0.692', 'val4_auc: 0.631', 'sum_auc: 2.094']\n",
      "Epoch3\t['loss: 0.149', 'val2_auc: 0.770', 'val3_auc: 0.676', 'val4_auc: 0.642', 'sum_auc: 2.088']\n",
      "Epoch4\t['loss: 0.148', 'val2_auc: 0.768', 'val3_auc: 0.667', 'val4_auc: 0.504', 'sum_auc: 1.940']\n",
      "Epoch5\t['loss: 0.147', 'val2_auc: 0.772', 'val3_auc: 0.687', 'val4_auc: 0.552', 'sum_auc: 2.012']\n",
      "Epoch 5: early stopping Threshold\n",
      "[I 2023-07-14 13:45:16,629] Trial 38 finished with value: 2.1329 and parameters: {'feature_dim': 256, 'n_step': 3, 'n_shared': 1, 'relaxation_factor': 1.1, 'sparsity_coefficient': 0.003056533565083659, 'bn_momentum': 0.9851880468602848}. Best is trial 31 with value: 2.3143.\n",
      "Epoch0\t['loss: 0.187', 'val2_auc: 0.725', 'val3_auc: 0.649', 'val4_auc: 0.672', 'sum_auc: 2.047']\n",
      "Epoch1\t['loss: 0.158', 'val2_auc: 0.755', 'val3_auc: 0.666', 'val4_auc: 0.740', 'sum_auc: 2.161']\n",
      "Epoch2\t['loss: 0.152', 'val2_auc: 0.767', 'val3_auc: 0.690', 'val4_auc: 0.573', 'sum_auc: 2.030']\n",
      "Epoch3\t['loss: 0.150', 'val2_auc: 0.777', 'val3_auc: 0.694', 'val4_auc: 0.642', 'sum_auc: 2.112']\n",
      "Epoch4\t['loss: 0.148', 'val2_auc: 0.785', 'val3_auc: 0.648', 'val4_auc: 0.623', 'sum_auc: 2.056']\n",
      "Epoch5\t['loss: 0.145', 'val2_auc: 0.798', 'val3_auc: 0.690', 'val4_auc: 0.586', 'sum_auc: 2.074']\n",
      "Epoch6\t['loss: 0.144', 'val2_auc: 0.801', 'val3_auc: 0.687', 'val4_auc: 0.632', 'sum_auc: 2.119']\n",
      "Epoch 6: early stopping Threshold\n",
      "[I 2023-07-14 13:47:40,937] Trial 39 finished with value: 2.161 and parameters: {'feature_dim': 64, 'n_step': 2, 'n_shared': 3, 'relaxation_factor': 3.0, 'sparsity_coefficient': 0.0003363631102367697, 'bn_momentum': 0.9772956343894748}. Best is trial 31 with value: 2.3143.\n",
      "Epoch0\t['loss: 0.189', 'val2_auc: 0.554', 'val3_auc: 0.575', 'val4_auc: 0.549', 'sum_auc: 1.678']\n",
      "Epoch3\t['loss: 0.164', 'val2_auc: 0.699', 'val3_auc: 0.662', 'val4_auc: 0.638', 'sum_auc: 1.999']\n",
      "Epoch4\t['loss: 0.158', 'val2_auc: 0.730', 'val3_auc: 0.664', 'val4_auc: 0.746', 'sum_auc: 2.140']\n",
      "Epoch5\t['loss: 0.157', 'val2_auc: 0.720', 'val3_auc: 0.655', 'val4_auc: 0.636', 'sum_auc: 2.012']\n",
      "Epoch6\t['loss: 0.155', 'val2_auc: 0.728', 'val3_auc: 0.674', 'val4_auc: 0.671', 'sum_auc: 2.073']\n",
      "Epoch7\t['loss: 0.154', 'val2_auc: 0.721', 'val3_auc: 0.659', 'val4_auc: 0.602', 'sum_auc: 1.982']\n",
      "Epoch8\t['loss: 0.153', 'val2_auc: 0.732', 'val3_auc: 0.663', 'val4_auc: 0.680', 'sum_auc: 2.074']\n",
      "Epoch9\t['loss: 0.153', 'val2_auc: 0.730', 'val3_auc: 0.671', 'val4_auc: 0.601', 'sum_auc: 2.002']\n",
      "Epoch 9: early stopping Threshold\n",
      "[I 2023-07-14 13:57:11,151] Trial 40 finished with value: 2.1404 and parameters: {'feature_dim': 128, 'n_step': 7, 'n_shared': 4, 'relaxation_factor': 1.4, 'sparsity_coefficient': 0.0001235807816948344, 'bn_momentum': 0.9695217340778627}. Best is trial 31 with value: 2.3143.\n",
      "Epoch0\t['loss: 0.212', 'val2_auc: 0.707', 'val3_auc: 0.732', 'val4_auc: 0.848', 'sum_auc: 2.286']\n",
      "Epoch1\t['loss: 0.158', 'val2_auc: 0.721', 'val3_auc: 0.733', 'val4_auc: 0.814', 'sum_auc: 2.268']\n",
      "Epoch2\t['loss: 0.151', 'val2_auc: 0.727', 'val3_auc: 0.735', 'val4_auc: 0.820', 'sum_auc: 2.281']\n",
      "Epoch3\t['loss: 0.147', 'val2_auc: 0.751', 'val3_auc: 0.721', 'val4_auc: 0.774', 'sum_auc: 2.246']\n",
      "Epoch4\t['loss: 0.144', 'val2_auc: 0.752', 'val3_auc: 0.713', 'val4_auc: 0.728', 'sum_auc: 2.194']\n",
      "Epoch5\t['loss: 0.142', 'val2_auc: 0.779', 'val3_auc: 0.725', 'val4_auc: 0.730', 'sum_auc: 2.233']\n",
      "Epoch 5: early stopping Threshold\n",
      "[I 2023-07-14 13:59:16,971] Trial 41 finished with value: 2.2863 and parameters: {'feature_dim': 32, 'n_step': 2, 'n_shared': 3, 'relaxation_factor': 1.1, 'sparsity_coefficient': 0.00044633882846035176, 'bn_momentum': 0.9994951437446402}. Best is trial 31 with value: 2.3143.\n",
      "Epoch0\t['loss: 0.214', 'val2_auc: 0.715', 'val3_auc: 0.700', 'val4_auc: 0.723', 'sum_auc: 2.138']\n",
      "Epoch1\t['loss: 0.156', 'val2_auc: 0.751', 'val3_auc: 0.695', 'val4_auc: 0.693', 'sum_auc: 2.138']\n",
      "Epoch2\t['loss: 0.148', 'val2_auc: 0.767', 'val3_auc: 0.685', 'val4_auc: 0.699', 'sum_auc: 2.151']\n",
      "Epoch3\t['loss: 0.145', 'val2_auc: 0.779', 'val3_auc: 0.693', 'val4_auc: 0.693', 'sum_auc: 2.165']\n",
      "Epoch4\t['loss: 0.143', 'val2_auc: 0.790', 'val3_auc: 0.693', 'val4_auc: 0.718', 'sum_auc: 2.202']\n",
      "Epoch5\t['loss: 0.141', 'val2_auc: 0.800', 'val3_auc: 0.713', 'val4_auc: 0.607', 'sum_auc: 2.120']\n",
      "Epoch6\t['loss: 0.139', 'val2_auc: 0.807', 'val3_auc: 0.715', 'val4_auc: 0.652', 'sum_auc: 2.175']\n",
      "Epoch7\t['loss: 0.138', 'val2_auc: 0.803', 'val3_auc: 0.739', 'val4_auc: 0.732', 'sum_auc: 2.274']\n",
      "Epoch8\t['loss: 0.138', 'val2_auc: 0.806', 'val3_auc: 0.711', 'val4_auc: 0.707', 'sum_auc: 2.224']\n",
      "Epoch9\t['loss: 0.137', 'val2_auc: 0.808', 'val3_auc: 0.727', 'val4_auc: 0.671', 'sum_auc: 2.205']\n",
      "[I 2023-07-14 14:02:43,890] Trial 42 finished with value: 2.2055 and parameters: {'feature_dim': 16, 'n_step': 2, 'n_shared': 3, 'relaxation_factor': 1.1, 'sparsity_coefficient': 0.00028066778246969013, 'bn_momentum': 0.994463239688736}. Best is trial 31 with value: 2.3143.\n",
      "Epoch0\t['loss: 0.175', 'val2_auc: 0.747', 'val3_auc: 0.667', 'val4_auc: 0.711', 'sum_auc: 2.125']\n",
      "Epoch1\t['loss: 0.153', 'val2_auc: 0.769', 'val3_auc: 0.664', 'val4_auc: 0.654', 'sum_auc: 2.087']\n",
      "Epoch2\t['loss: 0.148', 'val2_auc: 0.798', 'val3_auc: 0.684', 'val4_auc: 0.670', 'sum_auc: 2.152']\n",
      "Epoch3\t['loss: 0.146', 'val2_auc: 0.799', 'val3_auc: 0.685', 'val4_auc: 0.644', 'sum_auc: 2.127']\n",
      "Epoch4\t['loss: 0.144', 'val2_auc: 0.796', 'val3_auc: 0.703', 'val4_auc: 0.601', 'sum_auc: 2.100']\n",
      "Epoch5\t['loss: 0.142', 'val2_auc: 0.809', 'val3_auc: 0.708', 'val4_auc: 0.686', 'sum_auc: 2.202']\n",
      "Epoch6\t['loss: 0.139', 'val2_auc: 0.807', 'val3_auc: 0.703', 'val4_auc: 0.709', 'sum_auc: 2.219']\n",
      "Epoch7\t['loss: 0.140', 'val2_auc: 0.804', 'val3_auc: 0.682', 'val4_auc: 0.607', 'sum_auc: 2.093']\n",
      "Epoch8\t['loss: 0.137', 'val2_auc: 0.814', 'val3_auc: 0.711', 'val4_auc: 0.667', 'sum_auc: 2.191']\n",
      "Epoch9\t['loss: 0.137', 'val2_auc: 0.805', 'val3_auc: 0.677', 'val4_auc: 0.581', 'sum_auc: 2.063']\n",
      "[I 2023-07-14 14:07:24,422] Trial 43 finished with value: 2.0631 and parameters: {'feature_dim': 256, 'n_step': 2, 'n_shared': 3, 'relaxation_factor': 1.3, 'sparsity_coefficient': 0.00113689615138572, 'bn_momentum': 0.9885672230911862}. Best is trial 31 with value: 2.3143.\n",
      "Epoch0\t['loss: 0.181', 'val2_auc: 0.726', 'val3_auc: 0.691', 'val4_auc: 0.701', 'sum_auc: 2.118']\n",
      "Epoch5\t['loss: 0.142', 'val2_auc: 0.769', 'val3_auc: 0.680', 'val4_auc: 0.705', 'sum_auc: 2.153']\n",
      "Epoch6\t['loss: 0.141', 'val2_auc: 0.776', 'val3_auc: 0.691', 'val4_auc: 0.676', 'sum_auc: 2.143']\n",
      "Epoch7\t['loss: 0.139', 'val2_auc: 0.773', 'val3_auc: 0.676', 'val4_auc: 0.599', 'sum_auc: 2.048']\n",
      "Epoch8\t['loss: 0.139', 'val2_auc: 0.780', 'val3_auc: 0.697', 'val4_auc: 0.647', 'sum_auc: 2.124']\n",
      "Epoch9\t['loss: 0.138', 'val2_auc: 0.785', 'val3_auc: 0.676', 'val4_auc: 0.742', 'sum_auc: 2.202']\n",
      "[I 2023-07-14 14:12:08,248] Trial 44 finished with value: 2.2022 and parameters: {'feature_dim': 64, 'n_step': 3, 'n_shared': 2, 'relaxation_factor': 1.1, 'sparsity_coefficient': 5.645416307207666e-05, 'bn_momentum': 0.9943768270061402}. Best is trial 31 with value: 2.3143.\n",
      "Epoch0\t['loss: 0.171', 'val2_auc: 0.740', 'val3_auc: 0.686', 'val4_auc: 0.825', 'sum_auc: 2.250']\n",
      "Epoch1\t['loss: 0.151', 'val2_auc: 0.748', 'val3_auc: 0.680', 'val4_auc: 0.851', 'sum_auc: 2.279']\n",
      "Epoch2\t['loss: 0.145', 'val2_auc: 0.754', 'val3_auc: 0.670', 'val4_auc: 0.856', 'sum_auc: 2.281']\n",
      "Epoch3\t['loss: 0.140', 'val2_auc: 0.760', 'val3_auc: 0.685', 'val4_auc: 0.832', 'sum_auc: 2.277']\n",
      "Epoch4\t['loss: 0.139', 'val2_auc: 0.762', 'val3_auc: 0.683', 'val4_auc: 0.743', 'sum_auc: 2.188']\n",
      "Epoch5\t['loss: 0.137', 'val2_auc: 0.761', 'val3_auc: 0.685', 'val4_auc: 0.734', 'sum_auc: 2.180']\n",
      "Epoch6\t['loss: 0.136', 'val2_auc: 0.767', 'val3_auc: 0.670', 'val4_auc: 0.730', 'sum_auc: 2.168']\n",
      "Epoch7\t['loss: 0.136', 'val2_auc: 0.754', 'val3_auc: 0.662', 'val4_auc: 0.689', 'sum_auc: 2.105']\n",
      "Epoch 7: early stopping Threshold\n",
      "[I 2023-07-14 14:15:56,459] Trial 45 finished with value: 2.2809 and parameters: {'feature_dim': 256, 'n_step': 2, 'n_shared': 3, 'relaxation_factor': 1.8, 'sparsity_coefficient': 7.256409248329749e-06, 'bn_momentum': 0.999767835243791}. Best is trial 31 with value: 2.3143.\n",
      "Epoch0\t['loss: 0.213', 'val2_auc: 0.598', 'val3_auc: 0.599', 'val4_auc: 0.602', 'sum_auc: 1.798']\n",
      "Epoch1\t['loss: 0.167', 'val2_auc: 0.665', 'val3_auc: 0.639', 'val4_auc: 0.673', 'sum_auc: 1.978']\n",
      "Epoch2\t['loss: 0.162', 'val2_auc: 0.700', 'val3_auc: 0.666', 'val4_auc: 0.693', 'sum_auc: 2.060']\n",
      "Epoch3\t['loss: 0.158', 'val2_auc: 0.733', 'val3_auc: 0.672', 'val4_auc: 0.712', 'sum_auc: 2.117']\n",
      "Epoch4\t['loss: 0.156', 'val2_auc: 0.730', 'val3_auc: 0.682', 'val4_auc: 0.765', 'sum_auc: 2.177']\n",
      "Epoch5\t['loss: 0.154', 'val2_auc: 0.735', 'val3_auc: 0.671', 'val4_auc: 0.766', 'sum_auc: 2.172']\n",
      "Epoch6\t['loss: 0.152', 'val2_auc: 0.739', 'val3_auc: 0.659', 'val4_auc: 0.765', 'sum_auc: 2.163']\n",
      "Epoch7\t['loss: 0.151', 'val2_auc: 0.745', 'val3_auc: 0.683', 'val4_auc: 0.748', 'sum_auc: 2.176']\n",
      "Epoch8\t['loss: 0.151', 'val2_auc: 0.750', 'val3_auc: 0.666', 'val4_auc: 0.796', 'sum_auc: 2.213']\n",
      "Epoch9\t['loss: 0.150', 'val2_auc: 0.743', 'val3_auc: 0.677', 'val4_auc: 0.666', 'sum_auc: 2.086']\n",
      "[I 2023-07-14 14:22:05,513] Trial 46 finished with value: 2.0862 and parameters: {'feature_dim': 16, 'n_step': 4, 'n_shared': 1, 'relaxation_factor': 2.1, 'sparsity_coefficient': 2.393555306506817e-05, 'bn_momentum': 0.9833135939404118}. Best is trial 31 with value: 2.3143.\n",
      "Epoch0\t['loss: 0.185', 'val2_auc: 0.554', 'val3_auc: 0.497', 'val4_auc: 0.567', 'sum_auc: 1.618']\n",
      "Epoch1\t['loss: 0.170', 'val2_auc: 0.621', 'val3_auc: 0.567', 'val4_auc: 0.604', 'sum_auc: 1.792']\n",
      "Epoch2\t['loss: 0.165', 'val2_auc: 0.685', 'val3_auc: 0.657', 'val4_auc: 0.672', 'sum_auc: 2.014']\n",
      "Epoch3\t['loss: 0.161', 'val2_auc: 0.710', 'val3_auc: 0.660', 'val4_auc: 0.642', 'sum_auc: 2.012']\n",
      "Epoch4\t['loss: 0.158', 'val2_auc: 0.727', 'val3_auc: 0.654', 'val4_auc: 0.709', 'sum_auc: 2.089']\n",
      "Epoch5\t['loss: 0.156', 'val2_auc: 0.725', 'val3_auc: 0.648', 'val4_auc: 0.676', 'sum_auc: 2.048']\n",
      "Epoch6\t['loss: 0.155', 'val2_auc: 0.731', 'val3_auc: 0.681', 'val4_auc: 0.653', 'sum_auc: 2.065']\n",
      "Epoch7\t['loss: 0.154', 'val2_auc: 0.738', 'val3_auc: 0.657', 'val4_auc: 0.685', 'sum_auc: 2.079']\n",
      "Epoch8\t['loss: 0.153', 'val2_auc: 0.735', 'val3_auc: 0.689', 'val4_auc: 0.633', 'sum_auc: 2.058']\n",
      "Epoch9\t['loss: 0.152', 'val2_auc: 0.737', 'val3_auc: 0.670', 'val4_auc: 0.698', 'sum_auc: 2.104']\n",
      "[I 2023-07-14 14:34:06,783] Trial 47 finished with value: 2.1041 and parameters: {'feature_dim': 128, 'n_step': 9, 'n_shared': 2, 'relaxation_factor': 1.5, 'sparsity_coefficient': 6.014281237159105e-05, 'bn_momentum': 0.9900504776682657}. Best is trial 31 with value: 2.3143.\n",
      "Epoch0\t['loss: 0.210', 'val2_auc: 0.642', 'val3_auc: 0.623', 'val4_auc: 0.644', 'sum_auc: 1.909']\n",
      "Epoch1\t['loss: 0.169', 'val2_auc: 0.667', 'val3_auc: 0.669', 'val4_auc: 0.667', 'sum_auc: 2.003']\n",
      "Epoch2\t['loss: 0.166', 'val2_auc: 0.693', 'val3_auc: 0.701', 'val4_auc: 0.712', 'sum_auc: 2.106']\n",
      "Epoch3\t['loss: 0.160', 'val2_auc: 0.734', 'val3_auc: 0.696', 'val4_auc: 0.684', 'sum_auc: 2.114']\n",
      "Epoch4\t['loss: 0.155', 'val2_auc: 0.755', 'val3_auc: 0.708', 'val4_auc: 0.742', 'sum_auc: 2.204']\n",
      "Epoch5\t['loss: 0.151', 'val2_auc: 0.766', 'val3_auc: 0.709', 'val4_auc: 0.800', 'sum_auc: 2.275']\n",
      "Epoch6\t['loss: 0.149', 'val2_auc: 0.772', 'val3_auc: 0.698', 'val4_auc: 0.782', 'sum_auc: 2.252']\n",
      "Epoch7\t['loss: 0.147', 'val2_auc: 0.779', 'val3_auc: 0.699', 'val4_auc: 0.818', 'sum_auc: 2.296']\n",
      "Epoch8\t['loss: 0.147', 'val2_auc: 0.780', 'val3_auc: 0.734', 'val4_auc: 0.802', 'sum_auc: 2.317']\n",
      "Epoch9\t['loss: 0.146', 'val2_auc: 0.783', 'val3_auc: 0.729', 'val4_auc: 0.785', 'sum_auc: 2.297']\n",
      "[I 2023-07-14 14:38:48,930] Trial 48 finished with value: 2.2969 and parameters: {'feature_dim': 32, 'n_step': 3, 'n_shared': 4, 'relaxation_factor': 1.2, 'sparsity_coefficient': 0.0003990515986971999, 'bn_momentum': 0.9953676697967752}. Best is trial 31 with value: 2.3143.\n",
      "Epoch0\t['loss: 0.177', 'val2_auc: 0.757', 'val3_auc: 0.715', 'val4_auc: 0.742', 'sum_auc: 2.214']\n",
      "Epoch1\t['loss: 0.152', 'val2_auc: 0.762', 'val3_auc: 0.677', 'val4_auc: 0.673', 'sum_auc: 2.112']\n",
      "Epoch2\t['loss: 0.147', 'val2_auc: 0.773', 'val3_auc: 0.710', 'val4_auc: 0.666', 'sum_auc: 2.149']\n",
      "Epoch3\t['loss: 0.146', 'val2_auc: 0.775', 'val3_auc: 0.704', 'val4_auc: 0.601', 'sum_auc: 2.080']\n",
      "Epoch4\t['loss: 0.143', 'val2_auc: 0.779', 'val3_auc: 0.730', 'val4_auc: 0.635', 'sum_auc: 2.144']\n",
      "Epoch5\t['loss: 0.142', 'val2_auc: 0.788', 'val3_auc: 0.744', 'val4_auc: 0.714', 'sum_auc: 2.245']\n",
      "Epoch6\t['loss: 0.140', 'val2_auc: 0.795', 'val3_auc: 0.712', 'val4_auc: 0.618', 'sum_auc: 2.124']\n",
      "Epoch7\t['loss: 0.139', 'val2_auc: 0.799', 'val3_auc: 0.738', 'val4_auc: 0.735', 'sum_auc: 2.272']\n",
      "Epoch8\t['loss: 0.137', 'val2_auc: 0.804', 'val3_auc: 0.746', 'val4_auc: 0.711', 'sum_auc: 2.261']\n",
      "Epoch9\t['loss: 0.136', 'val2_auc: 0.806', 'val3_auc: 0.750', 'val4_auc: 0.763', 'sum_auc: 2.319']\n",
      "[I 2023-07-14 14:45:07,265] Trial 49 finished with value: 2.3189 and parameters: {'feature_dim': 256, 'n_step': 3, 'n_shared': 4, 'relaxation_factor': 1.0, 'sparsity_coefficient': 0.00013133458634616966, 'bn_momentum': 0.995789181142114}. Best is trial 49 with value: 2.3189.\n",
      "Epoch0\t['loss: 0.177', 'val2_auc: 0.754', 'val3_auc: 0.694', 'val4_auc: 0.703', 'sum_auc: 2.152']\n",
      "Epoch1\t['loss: 0.155', 'val2_auc: 0.736', 'val3_auc: 0.673', 'val4_auc: 0.616', 'sum_auc: 2.026']\n",
      "Epoch2\t['loss: 0.149', 'val2_auc: 0.762', 'val3_auc: 0.685', 'val4_auc: 0.624', 'sum_auc: 2.072']\n",
      "Epoch3\t['loss: 0.147', 'val2_auc: 0.764', 'val3_auc: 0.684', 'val4_auc: 0.707', 'sum_auc: 2.156']\n",
      "Epoch4\t['loss: 0.145', 'val2_auc: 0.777', 'val3_auc: 0.710', 'val4_auc: 0.613', 'sum_auc: 2.101']\n",
      "Epoch5\t['loss: 0.143', 'val2_auc: 0.777', 'val3_auc: 0.712', 'val4_auc: 0.748', 'sum_auc: 2.237']\n",
      "Epoch6\t['loss: 0.143', 'val2_auc: 0.778', 'val3_auc: 0.698', 'val4_auc: 0.633', 'sum_auc: 2.110']\n",
      "Epoch7\t['loss: 0.143', 'val2_auc: 0.780', 'val3_auc: 0.714', 'val4_auc: 0.630', 'sum_auc: 2.124']\n",
      "Epoch8\t['loss: 0.142', 'val2_auc: 0.781', 'val3_auc: 0.698', 'val4_auc: 0.700', 'sum_auc: 2.179']\n",
      "Epoch9\t['loss: 0.140', 'val2_auc: 0.778', 'val3_auc: 0.694', 'val4_auc: 0.675', 'sum_auc: 2.147']\n",
      "[I 2023-07-14 14:51:24,118] Trial 50 finished with value: 2.1466 and parameters: {'feature_dim': 256, 'n_step': 3, 'n_shared': 4, 'relaxation_factor': 1.0, 'sparsity_coefficient': 0.0001603214729305239, 'bn_momentum': 0.9851664705325368}. Best is trial 49 with value: 2.3189.\n",
      "Epoch0\t['loss: 0.185', 'val2_auc: 0.730', 'val3_auc: 0.667', 'val4_auc: 0.720', 'sum_auc: 2.118']\n",
      "Epoch2\t['loss: 0.160', 'val2_auc: 0.731', 'val3_auc: 0.694', 'val4_auc: 0.699', 'sum_auc: 2.124']\n",
      "Epoch3\t['loss: 0.155', 'val2_auc: 0.744', 'val3_auc: 0.679', 'val4_auc: 0.716', 'sum_auc: 2.139']\n",
      "Epoch4\t['loss: 0.151', 'val2_auc: 0.746', 'val3_auc: 0.693', 'val4_auc: 0.633', 'sum_auc: 2.072']\n",
      "Epoch5\t['loss: 0.149', 'val2_auc: 0.741', 'val3_auc: 0.691', 'val4_auc: 0.533', 'sum_auc: 1.966']\n",
      "Epoch6\t['loss: 0.148', 'val2_auc: 0.746', 'val3_auc: 0.700', 'val4_auc: 0.680', 'sum_auc: 2.126']\n",
      "Epoch7\t['loss: 0.147', 'val2_auc: 0.750', 'val3_auc: 0.685', 'val4_auc: 0.685', 'sum_auc: 2.120']\n",
      "Epoch8\t['loss: 0.147', 'val2_auc: 0.736', 'val3_auc: 0.671', 'val4_auc: 0.557', 'sum_auc: 1.964']\n",
      "Epoch 8: early stopping Threshold\n",
      "[I 2023-07-14 15:03:44,588] Trial 51 finished with value: 2.1391 and parameters: {'feature_dim': 256, 'n_step': 8, 'n_shared': 4, 'relaxation_factor': 1.1, 'sparsity_coefficient': 9.360871725291956e-05, 'bn_momentum': 0.9958829081406799}. Best is trial 49 with value: 2.3189.\n",
      "Epoch0\t['loss: 0.179', 'val2_auc: 0.740', 'val3_auc: 0.671', 'val4_auc: 0.802', 'sum_auc: 2.213']\n",
      "Epoch1\t['loss: 0.159', 'val2_auc: 0.733', 'val3_auc: 0.661', 'val4_auc: 0.709', 'sum_auc: 2.103']\n",
      "Epoch2\t['loss: 0.152', 'val2_auc: 0.761', 'val3_auc: 0.665', 'val4_auc: 0.575', 'sum_auc: 2.002']\n",
      "Epoch3\t['loss: 0.146', 'val2_auc: 0.773', 'val3_auc: 0.696', 'val4_auc: 0.614', 'sum_auc: 2.083']\n",
      "Epoch4\t['loss: 0.144', 'val2_auc: 0.773', 'val3_auc: 0.710', 'val4_auc: 0.564', 'sum_auc: 2.048']\n",
      "Epoch5\t['loss: 0.141', 'val2_auc: 0.781', 'val3_auc: 0.713', 'val4_auc: 0.577', 'sum_auc: 2.071']\n",
      "Epoch 5: early stopping Threshold\n",
      "[I 2023-07-14 15:07:36,232] Trial 52 finished with value: 2.2132 and parameters: {'feature_dim': 256, 'n_step': 3, 'n_shared': 4, 'relaxation_factor': 1.3, 'sparsity_coefficient': 4.537432248340084e-05, 'bn_momentum': 0.9955480885964809}. Best is trial 49 with value: 2.3189.\n",
      "Epoch0\t['loss: 0.180', 'val2_auc: 0.719', 'val3_auc: 0.659', 'val4_auc: 0.664', 'sum_auc: 2.043']\n",
      "Epoch1\t['loss: 0.157', 'val2_auc: 0.743', 'val3_auc: 0.665', 'val4_auc: 0.638', 'sum_auc: 2.046']\n",
      "Epoch2\t['loss: 0.150', 'val2_auc: 0.766', 'val3_auc: 0.701', 'val4_auc: 0.694', 'sum_auc: 2.162']\n",
      "Epoch3\t['loss: 0.145', 'val2_auc: 0.774', 'val3_auc: 0.709', 'val4_auc: 0.567', 'sum_auc: 2.050']\n",
      "Epoch4\t['loss: 0.143', 'val2_auc: 0.784', 'val3_auc: 0.720', 'val4_auc: 0.609', 'sum_auc: 2.113']\n",
      "Epoch5\t['loss: 0.142', 'val2_auc: 0.779', 'val3_auc: 0.695', 'val4_auc: 0.660', 'sum_auc: 2.135']\n",
      "Epoch6\t['loss: 0.142', 'val2_auc: 0.782', 'val3_auc: 0.730', 'val4_auc: 0.657', 'sum_auc: 2.169']\n",
      "Epoch7\t['loss: 0.141', 'val2_auc: 0.787', 'val3_auc: 0.730', 'val4_auc: 0.687', 'sum_auc: 2.204']\n",
      "Epoch8\t['loss: 0.139', 'val2_auc: 0.792', 'val3_auc: 0.726', 'val4_auc: 0.599', 'sum_auc: 2.117']\n",
      "Epoch9\t['loss: 0.138', 'val2_auc: 0.791', 'val3_auc: 0.738', 'val4_auc: 0.595', 'sum_auc: 2.124']\n",
      "[I 2023-07-14 15:15:26,013] Trial 53 finished with value: 2.1239 and parameters: {'feature_dim': 256, 'n_step': 4, 'n_shared': 4, 'relaxation_factor': 1.0, 'sparsity_coefficient': 0.0002681979688375612, 'bn_momentum': 0.9877121585413458}. Best is trial 49 with value: 2.3189.\n",
      "Epoch0\t['loss: 0.194', 'val2_auc: 0.719', 'val3_auc: 0.678', 'val4_auc: 0.833', 'sum_auc: 2.229']\n",
      "Epoch1\t['loss: 0.166', 'val2_auc: 0.760', 'val3_auc: 0.675', 'val4_auc: 0.858', 'sum_auc: 2.293']\n",
      "Epoch2\t['loss: 0.160', 'val2_auc: 0.746', 'val3_auc: 0.687', 'val4_auc: 0.855', 'sum_auc: 2.288']\n",
      "Epoch3\t['loss: 0.157', 'val2_auc: 0.758', 'val3_auc: 0.684', 'val4_auc: 0.860', 'sum_auc: 2.302']\n",
      "Epoch4\t['loss: 0.155', 'val2_auc: 0.749', 'val3_auc: 0.681', 'val4_auc: 0.859', 'sum_auc: 2.290']\n",
      "Epoch5\t['loss: 0.153', 'val2_auc: 0.766', 'val3_auc: 0.685', 'val4_auc: 0.859', 'sum_auc: 2.310']\n",
      "Epoch6\t['loss: 0.152', 'val2_auc: 0.768', 'val3_auc: 0.695', 'val4_auc: 0.856', 'sum_auc: 2.319']\n",
      "Epoch7\t['loss: 0.151', 'val2_auc: 0.760', 'val3_auc: 0.684', 'val4_auc: 0.852', 'sum_auc: 2.297']\n",
      "Epoch8\t['loss: 0.150', 'val2_auc: 0.746', 'val3_auc: 0.682', 'val4_auc: 0.822', 'sum_auc: 2.251']\n",
      "Epoch9\t['loss: 0.150', 'val2_auc: 0.766', 'val3_auc: 0.682', 'val4_auc: 0.857', 'sum_auc: 2.306']\n",
      "[I 2023-07-14 15:23:45,816] Trial 54 finished with value: 2.3057 and parameters: {'feature_dim': 128, 'n_step': 6, 'n_shared': 4, 'relaxation_factor': 1.2, 'sparsity_coefficient': 1.959495692268293e-05, 'bn_momentum': 0.9997440949716035}. Best is trial 49 with value: 2.3189.\n",
      "Epoch0\t['loss: 0.213', 'val2_auc: 0.588', 'val3_auc: 0.598', 'val4_auc: 0.553', 'sum_auc: 1.739']\n",
      "Epoch1\t['loss: 0.169', 'val2_auc: 0.657', 'val3_auc: 0.635', 'val4_auc: 0.603', 'sum_auc: 1.895']\n",
      "Epoch2\t['loss: 0.164', 'val2_auc: 0.698', 'val3_auc: 0.674', 'val4_auc: 0.667', 'sum_auc: 2.038']\n",
      "Epoch3\t['loss: 0.160', 'val2_auc: 0.717', 'val3_auc: 0.668', 'val4_auc: 0.683', 'sum_auc: 2.069']\n",
      "Epoch4\t['loss: 0.158', 'val2_auc: 0.715', 'val3_auc: 0.663', 'val4_auc: 0.625', 'sum_auc: 2.004']\n",
      "Epoch5\t['loss: 0.156', 'val2_auc: 0.719', 'val3_auc: 0.666', 'val4_auc: 0.623', 'sum_auc: 2.008']\n",
      "Epoch6\t['loss: 0.154', 'val2_auc: 0.725', 'val3_auc: 0.658', 'val4_auc: 0.640', 'sum_auc: 2.024']\n",
      "Epoch7\t['loss: 0.153', 'val2_auc: 0.733', 'val3_auc: 0.663', 'val4_auc: 0.693', 'sum_auc: 2.090']\n",
      "Epoch8\t['loss: 0.152', 'val2_auc: 0.742', 'val3_auc: 0.668', 'val4_auc: 0.574', 'sum_auc: 1.984']\n",
      "Epoch9\t['loss: 0.151', 'val2_auc: 0.726', 'val3_auc: 0.664', 'val4_auc: 0.640', 'sum_auc: 2.031']\n",
      "[I 2023-07-14 15:31:48,794] Trial 55 finished with value: 2.0308 and parameters: {'feature_dim': 64, 'n_step': 6, 'n_shared': 4, 'relaxation_factor': 1.4, 'sparsity_coefficient': 8.044277009099852e-05, 'bn_momentum': 0.9896514308382856}. Best is trial 49 with value: 2.3189.\n",
      "Epoch0\t['loss: 0.197', 'val2_auc: 0.650', 'val3_auc: 0.665', 'val4_auc: 0.712', 'sum_auc: 2.028']\n",
      "Epoch1\t['loss: 0.169', 'val2_auc: 0.661', 'val3_auc: 0.637', 'val4_auc: 0.667', 'sum_auc: 1.965']\n",
      "Epoch2\t['loss: 0.163', 'val2_auc: 0.706', 'val3_auc: 0.668', 'val4_auc: 0.671', 'sum_auc: 2.045']\n",
      "Epoch3\t['loss: 0.161', 'val2_auc: 0.705', 'val3_auc: 0.656', 'val4_auc: 0.707', 'sum_auc: 2.068']\n",
      "Epoch4\t['loss: 0.157', 'val2_auc: 0.726', 'val3_auc: 0.660', 'val4_auc: 0.711', 'sum_auc: 2.097']\n",
      "Epoch5\t['loss: 0.155', 'val2_auc: 0.735', 'val3_auc: 0.662', 'val4_auc: 0.640', 'sum_auc: 2.038']\n",
      "Epoch6\t['loss: 0.152', 'val2_auc: 0.745', 'val3_auc: 0.666', 'val4_auc: 0.642', 'sum_auc: 2.052']\n",
      "Epoch7\t['loss: 0.150', 'val2_auc: 0.747', 'val3_auc: 0.666', 'val4_auc: 0.613', 'sum_auc: 2.026']\n",
      "Epoch8\t['loss: 0.150', 'val2_auc: 0.745', 'val3_auc: 0.675', 'val4_auc: 0.610', 'sum_auc: 2.030']\n",
      "Epoch9\t['loss: 0.149', 'val2_auc: 0.735', 'val3_auc: 0.671', 'val4_auc: 0.530', 'sum_auc: 1.936']\n",
      "Epoch 9: early stopping Threshold\n",
      "[I 2023-07-14 15:39:52,030] Trial 56 finished with value: 2.0968 and parameters: {'feature_dim': 32, 'n_step': 6, 'n_shared': 4, 'relaxation_factor': 1.2, 'sparsity_coefficient': 2.7302760829189872e-05, 'bn_momentum': 0.9953449465789945}. Best is trial 49 with value: 2.3189.\n",
      "Epoch0\t['loss: 0.195', 'val2_auc: 0.738', 'val3_auc: 0.688', 'val4_auc: 0.826', 'sum_auc: 2.253']\n",
      "Epoch1\t['loss: 0.165', 'val2_auc: 0.731', 'val3_auc: 0.688', 'val4_auc: 0.708', 'sum_auc: 2.126']\n",
      "Epoch2\t['loss: 0.159', 'val2_auc: 0.736', 'val3_auc: 0.696', 'val4_auc: 0.657', 'sum_auc: 2.089']\n",
      "Epoch3\t['loss: 0.156', 'val2_auc: 0.742', 'val3_auc: 0.673', 'val4_auc: 0.625', 'sum_auc: 2.041']\n",
      "Epoch4\t['loss: 0.153', 'val2_auc: 0.750', 'val3_auc: 0.687', 'val4_auc: 0.692', 'sum_auc: 2.128']\n",
      "Epoch5\t['loss: 0.151', 'val2_auc: 0.747', 'val3_auc: 0.706', 'val4_auc: 0.664', 'sum_auc: 2.117']\n",
      "Epoch 5: early stopping Threshold\n",
      "[I 2023-07-14 15:44:19,387] Trial 57 finished with value: 2.2527 and parameters: {'feature_dim': 128, 'n_step': 5, 'n_shared': 4, 'relaxation_factor': 1.1, 'sparsity_coefficient': 0.0018008992044165632, 'bn_momentum': 0.9966454387252991}. Best is trial 49 with value: 2.3189.\n",
      "Epoch0\t['loss: 0.229', 'val2_auc: 0.611', 'val3_auc: 0.599', 'val4_auc: 0.568', 'sum_auc: 1.777']\n",
      "Epoch1\t['loss: 0.167', 'val2_auc: 0.670', 'val3_auc: 0.644', 'val4_auc: 0.665', 'sum_auc: 1.980']\n",
      "Epoch2\t['loss: 0.164', 'val2_auc: 0.683', 'val3_auc: 0.653', 'val4_auc: 0.643', 'sum_auc: 1.979']\n",
      "Epoch3\t['loss: 0.162', 'val2_auc: 0.703', 'val3_auc: 0.636', 'val4_auc: 0.697', 'sum_auc: 2.037']\n",
      "Epoch4\t['loss: 0.159', 'val2_auc: 0.712', 'val3_auc: 0.639', 'val4_auc: 0.650', 'sum_auc: 2.001']\n",
      "Epoch5\t['loss: 0.157', 'val2_auc: 0.729', 'val3_auc: 0.649', 'val4_auc: 0.680', 'sum_auc: 2.058']\n",
      "Epoch6\t['loss: 0.155', 'val2_auc: 0.731', 'val3_auc: 0.657', 'val4_auc: 0.676', 'sum_auc: 2.064']\n",
      "Epoch7\t['loss: 0.154', 'val2_auc: 0.728', 'val3_auc: 0.653', 'val4_auc: 0.590', 'sum_auc: 1.971']\n",
      "Epoch8\t['loss: 0.152', 'val2_auc: 0.739', 'val3_auc: 0.662', 'val4_auc: 0.719', 'sum_auc: 2.120']\n",
      "Epoch9\t['loss: 0.151', 'val2_auc: 0.739', 'val3_auc: 0.655', 'val4_auc: 0.614', 'sum_auc: 2.009']\n",
      "[I 2023-07-14 15:53:41,091] Trial 58 finished with value: 2.0085 and parameters: {'feature_dim': 16, 'n_step': 7, 'n_shared': 4, 'relaxation_factor': 1.0, 'sparsity_coefficient': 0.00016777669229964078, 'bn_momentum': 0.9776567139060013}. Best is trial 49 with value: 2.3189.\n",
      "Epoch0\t['loss: 0.175', 'val2_auc: 0.685', 'val3_auc: 0.663', 'val4_auc: 0.655', 'sum_auc: 2.004']\n",
      "Epoch1\t['loss: 0.161', 'val2_auc: 0.714', 'val3_auc: 0.664', 'val4_auc: 0.701', 'sum_auc: 2.079']\n",
      "Epoch2\t['loss: 0.155', 'val2_auc: 0.745', 'val3_auc: 0.679', 'val4_auc: 0.749', 'sum_auc: 2.172']\n",
      "Epoch3\t['loss: 0.154', 'val2_auc: 0.742', 'val3_auc: 0.668', 'val4_auc: 0.645', 'sum_auc: 2.055']\n",
      "Epoch4\t['loss: 0.152', 'val2_auc: 0.741', 'val3_auc: 0.660', 'val4_auc: 0.660', 'sum_auc: 2.061']\n",
      "Epoch5\t['loss: 0.151', 'val2_auc: 0.749', 'val3_auc: 0.652', 'val4_auc: 0.696', 'sum_auc: 2.097']\n",
      "Epoch6\t['loss: 0.151', 'val2_auc: 0.746', 'val3_auc: 0.672', 'val4_auc: 0.708', 'sum_auc: 2.126']\n",
      "Epoch7\t['loss: 0.151', 'val2_auc: 0.749', 'val3_auc: 0.661', 'val4_auc: 0.662', 'sum_auc: 2.072']\n",
      "Epoch 7: early stopping Threshold\n",
      "[I 2023-07-14 16:02:11,572] Trial 59 finished with value: 2.1725 and parameters: {'feature_dim': 256, 'n_step': 6, 'n_shared': 1, 'relaxation_factor': 1.3, 'sparsity_coefficient': 3.3863804528666787e-06, 'bn_momentum': 0.9865603530891418}. Best is trial 49 with value: 2.3189.\n",
      "Epoch0\t['loss: 0.187', 'val2_auc: 0.754', 'val3_auc: 0.643', 'val4_auc: 0.792', 'sum_auc: 2.190']\n",
      "Epoch1\t['loss: 0.162', 'val2_auc: 0.755', 'val3_auc: 0.692', 'val4_auc: 0.771', 'sum_auc: 2.219']\n",
      "Epoch2\t['loss: 0.158', 'val2_auc: 0.755', 'val3_auc: 0.715', 'val4_auc: 0.741', 'sum_auc: 2.211']\n",
      "Epoch3\t['loss: 0.155', 'val2_auc: 0.719', 'val3_auc: 0.674', 'val4_auc: 0.564', 'sum_auc: 1.958']\n",
      "Epoch4\t['loss: 0.153', 'val2_auc: 0.721', 'val3_auc: 0.670', 'val4_auc: 0.602', 'sum_auc: 1.993']\n",
      "Epoch5\t['loss: 0.150', 'val2_auc: 0.711', 'val3_auc: 0.688', 'val4_auc: 0.569', 'sum_auc: 1.968']\n",
      "Epoch6\t['loss: 0.149', 'val2_auc: 0.718', 'val3_auc: 0.671', 'val4_auc: 0.535', 'sum_auc: 1.925']\n",
      "Epoch 6: early stopping Threshold\n",
      "[I 2023-07-14 16:06:21,349] Trial 60 finished with value: 2.2185 and parameters: {'feature_dim': 128, 'n_step': 4, 'n_shared': 4, 'relaxation_factor': 1.2, 'sparsity_coefficient': 3.9336290012986225e-05, 'bn_momentum': 0.9998557968495816}. Best is trial 49 with value: 2.3189.\n",
      "Epoch0\t['loss: 0.189', 'val2_auc: 0.546', 'val3_auc: 0.530', 'val4_auc: 0.632', 'sum_auc: 1.708']\n",
      "Epoch1\t['loss: 0.169', 'val2_auc: 0.678', 'val3_auc: 0.651', 'val4_auc: 0.704', 'sum_auc: 2.033']\n",
      "Epoch2\t['loss: 0.164', 'val2_auc: 0.704', 'val3_auc: 0.642', 'val4_auc: 0.659', 'sum_auc: 2.005']\n",
      "Epoch3\t['loss: 0.160', 'val2_auc: 0.717', 'val3_auc: 0.668', 'val4_auc: 0.714', 'sum_auc: 2.099']\n",
      "Epoch4\t['loss: 0.155', 'val2_auc: 0.734', 'val3_auc: 0.685', 'val4_auc: 0.745', 'sum_auc: 2.163']\n",
      "Epoch5\t['loss: 0.153', 'val2_auc: 0.738', 'val3_auc: 0.671', 'val4_auc: 0.678', 'sum_auc: 2.087']\n",
      "Epoch6\t['loss: 0.152', 'val2_auc: 0.747', 'val3_auc: 0.677', 'val4_auc: 0.748', 'sum_auc: 2.172']\n",
      "Epoch7\t['loss: 0.150', 'val2_auc: 0.745', 'val3_auc: 0.684', 'val4_auc: 0.725', 'sum_auc: 2.154']\n",
      "Epoch8\t['loss: 0.149', 'val2_auc: 0.753', 'val3_auc: 0.691', 'val4_auc: 0.716', 'sum_auc: 2.161']\n",
      "Epoch9\t['loss: 0.148', 'val2_auc: 0.750', 'val3_auc: 0.683', 'val4_auc: 0.685', 'sum_auc: 2.118']\n",
      "[I 2023-07-14 16:11:15,215] Trial 61 finished with value: 2.1178 and parameters: {'feature_dim': 128, 'n_step': 3, 'n_shared': 4, 'relaxation_factor': 2.4000000000000004, 'sparsity_coefficient': 1.6728040188892077e-05, 'bn_momentum': 0.9966137949818046}. Best is trial 49 with value: 2.3189.\n",
      "Epoch0\t['loss: 0.179', 'val2_auc: 0.735', 'val3_auc: 0.664', 'val4_auc: 0.745', 'sum_auc: 2.143']\n",
      "Epoch1\t['loss: 0.152', 'val2_auc: 0.772', 'val3_auc: 0.665', 'val4_auc: 0.625', 'sum_auc: 2.062']\n",
      "Epoch2\t['loss: 0.147', 'val2_auc: 0.784', 'val3_auc: 0.726', 'val4_auc: 0.711', 'sum_auc: 2.220']\n",
      "Epoch3\t['loss: 0.144', 'val2_auc: 0.791', 'val3_auc: 0.637', 'val4_auc: 0.591', 'sum_auc: 2.019']\n",
      "Epoch4\t['loss: 0.143', 'val2_auc: 0.784', 'val3_auc: 0.679', 'val4_auc: 0.624', 'sum_auc: 2.087']\n",
      "Epoch5\t['loss: 0.141', 'val2_auc: 0.792', 'val3_auc: 0.724', 'val4_auc: 0.673', 'sum_auc: 2.190']\n",
      "Epoch6\t['loss: 0.140', 'val2_auc: 0.793', 'val3_auc: 0.649', 'val4_auc: 0.635', 'sum_auc: 2.077']\n",
      "Epoch7\t['loss: 0.141', 'val2_auc: 0.799', 'val3_auc: 0.666', 'val4_auc: 0.557', 'sum_auc: 2.022']\n",
      "Epoch 7: early stopping Threshold\n",
      "[I 2023-07-14 16:14:04,975] Trial 62 finished with value: 2.22 and parameters: {'feature_dim': 128, 'n_step': 2, 'n_shared': 4, 'relaxation_factor': 2.1, 'sparsity_coefficient': 2.0469169019872964e-05, 'bn_momentum': 0.991047516893711}. Best is trial 49 with value: 2.3189.\n",
      "Epoch0\t['loss: 0.182', 'val2_auc: 0.752', 'val3_auc: 0.700', 'val4_auc: 0.813', 'sum_auc: 2.265']\n",
      "Epoch1\t['loss: 0.152', 'val2_auc: 0.764', 'val3_auc: 0.682', 'val4_auc: 0.682', 'sum_auc: 2.129']\n",
      "Epoch2\t['loss: 0.146', 'val2_auc: 0.777', 'val3_auc: 0.701', 'val4_auc: 0.710', 'sum_auc: 2.188']\n",
      "Epoch3\t['loss: 0.143', 'val2_auc: 0.785', 'val3_auc: 0.706', 'val4_auc: 0.684', 'sum_auc: 2.175']\n",
      "Epoch4\t['loss: 0.142', 'val2_auc: 0.781', 'val3_auc: 0.688', 'val4_auc: 0.670', 'sum_auc: 2.139']\n",
      "Epoch5\t['loss: 0.140', 'val2_auc: 0.788', 'val3_auc: 0.685', 'val4_auc: 0.721', 'sum_auc: 2.194']\n",
      "Epoch 5: early stopping Threshold\n",
      "[I 2023-07-14 16:17:05,149] Trial 63 finished with value: 2.2651 and parameters: {'feature_dim': 128, 'n_step': 3, 'n_shared': 4, 'relaxation_factor': 1.1, 'sparsity_coefficient': 1.0970623751411055e-05, 'bn_momentum': 0.9966196731726596}. Best is trial 49 with value: 2.3189.\n",
      "Epoch0\t['loss: 0.172', 'val2_auc: 0.745', 'val3_auc: 0.655', 'val4_auc: 0.652', 'sum_auc: 2.052']\n",
      "Epoch1\t['loss: 0.152', 'val2_auc: 0.774', 'val3_auc: 0.681', 'val4_auc: 0.664', 'sum_auc: 2.119']\n",
      "Epoch2\t['loss: 0.145', 'val2_auc: 0.781', 'val3_auc: 0.710', 'val4_auc: 0.709', 'sum_auc: 2.200']\n",
      "Epoch3\t['loss: 0.142', 'val2_auc: 0.796', 'val3_auc: 0.722', 'val4_auc: 0.706', 'sum_auc: 2.225']\n",
      "Epoch4\t['loss: 0.140', 'val2_auc: 0.804', 'val3_auc: 0.723', 'val4_auc: 0.653', 'sum_auc: 2.179']\n",
      "Epoch5\t['loss: 0.139', 'val2_auc: 0.811', 'val3_auc: 0.722', 'val4_auc: 0.630', 'sum_auc: 2.164']\n",
      "Epoch6\t['loss: 0.138', 'val2_auc: 0.811', 'val3_auc: 0.717', 'val4_auc: 0.613', 'sum_auc: 2.140']\n",
      "Epoch7\t['loss: 0.136', 'val2_auc: 0.812', 'val3_auc: 0.723', 'val4_auc: 0.578', 'sum_auc: 2.114']\n",
      "Epoch8\t['loss: 0.135', 'val2_auc: 0.811', 'val3_auc: 0.719', 'val4_auc: 0.671', 'sum_auc: 2.202']\n",
      "Epoch 8: early stopping Threshold\n",
      "[I 2023-07-14 16:20:21,427] Trial 64 finished with value: 2.2248 and parameters: {'feature_dim': 128, 'n_step': 2, 'n_shared': 3, 'relaxation_factor': 1.0, 'sparsity_coefficient': 9.76009622413215e-05, 'bn_momentum': 0.9921909467545443}. Best is trial 49 with value: 2.3189.\n",
      "Epoch0\t['loss: 0.220', 'val2_auc: 0.529', 'val3_auc: 0.505', 'val4_auc: 0.542', 'sum_auc: 1.576']\n",
      "Epoch1\t['loss: 0.171', 'val2_auc: 0.546', 'val3_auc: 0.573', 'val4_auc: 0.577', 'sum_auc: 1.697']\n",
      "Epoch2\t['loss: 0.170', 'val2_auc: 0.618', 'val3_auc: 0.582', 'val4_auc: 0.607', 'sum_auc: 1.807']\n",
      "Epoch3\t['loss: 0.164', 'val2_auc: 0.662', 'val3_auc: 0.638', 'val4_auc: 0.665', 'sum_auc: 1.965']\n",
      "Epoch4\t['loss: 0.162', 'val2_auc: 0.694', 'val3_auc: 0.658', 'val4_auc: 0.685', 'sum_auc: 2.036']\n",
      "Epoch5\t['loss: 0.161', 'val2_auc: 0.700', 'val3_auc: 0.661', 'val4_auc: 0.689', 'sum_auc: 2.050']\n",
      "Epoch6\t['loss: 0.158', 'val2_auc: 0.714', 'val3_auc: 0.662', 'val4_auc: 0.650', 'sum_auc: 2.026']\n",
      "Epoch7\t['loss: 0.156', 'val2_auc: 0.721', 'val3_auc: 0.668', 'val4_auc: 0.680', 'sum_auc: 2.069']\n",
      "Epoch8\t['loss: 0.156', 'val2_auc: 0.721', 'val3_auc: 0.672', 'val4_auc: 0.749', 'sum_auc: 2.143']\n",
      "Epoch9\t['loss: 0.155', 'val2_auc: 0.727', 'val3_auc: 0.678', 'val4_auc: 0.642', 'sum_auc: 2.046']\n",
      "[I 2023-07-14 16:27:07,412] Trial 65 finished with value: 2.0465 and parameters: {'feature_dim': 32, 'n_step': 5, 'n_shared': 4, 'relaxation_factor': 1.7000000000000002, 'sparsity_coefficient': 4.728160494274513e-05, 'bn_momentum': 0.9976622382321227}. Best is trial 49 with value: 2.3189.\n",
      "Epoch0\t['loss: 0.221', 'val2_auc: 0.579', 'val3_auc: 0.650', 'val4_auc: 0.628', 'sum_auc: 1.857']\n",
      "Epoch1\t['loss: 0.166', 'val2_auc: 0.709', 'val3_auc: 0.708', 'val4_auc: 0.752', 'sum_auc: 2.168']\n",
      "Epoch2\t['loss: 0.159', 'val2_auc: 0.742', 'val3_auc: 0.692', 'val4_auc: 0.771', 'sum_auc: 2.205']\n",
      "Epoch3\t['loss: 0.155', 'val2_auc: 0.743', 'val3_auc: 0.690', 'val4_auc: 0.763', 'sum_auc: 2.196']\n",
      "Epoch4\t['loss: 0.152', 'val2_auc: 0.749', 'val3_auc: 0.713', 'val4_auc: 0.786', 'sum_auc: 2.249']\n",
      "Epoch5\t['loss: 0.151', 'val2_auc: 0.755', 'val3_auc: 0.715', 'val4_auc: 0.771', 'sum_auc: 2.240']\n",
      "Epoch6\t['loss: 0.148', 'val2_auc: 0.760', 'val3_auc: 0.722', 'val4_auc: 0.774', 'sum_auc: 2.256']\n",
      "Epoch7\t['loss: 0.146', 'val2_auc: 0.764', 'val3_auc: 0.731', 'val4_auc: 0.766', 'sum_auc: 2.261']\n",
      "Epoch8\t['loss: 0.145', 'val2_auc: 0.756', 'val3_auc: 0.729', 'val4_auc: 0.779', 'sum_auc: 2.264']\n",
      "Epoch9\t['loss: 0.144', 'val2_auc: 0.754', 'val3_auc: 0.740', 'val4_auc: 0.779', 'sum_auc: 2.273']\n",
      "[I 2023-07-14 16:31:54,610] Trial 66 finished with value: 2.2728 and parameters: {'feature_dim': 8, 'n_step': 3, 'n_shared': 2, 'relaxation_factor': 1.2, 'sparsity_coefficient': 0.0006455917996580439, 'bn_momentum': 0.9897072236986766}. Best is trial 49 with value: 2.3189.\n",
      "Epoch0\t['loss: 0.175', 'val2_auc: 0.722', 'val3_auc: 0.634', 'val4_auc: 0.650', 'sum_auc: 2.005']\n",
      "Epoch1\t['loss: 0.155', 'val2_auc: 0.770', 'val3_auc: 0.713', 'val4_auc: 0.734', 'sum_auc: 2.217']\n",
      "Epoch2\t['loss: 0.148', 'val2_auc: 0.794', 'val3_auc: 0.694', 'val4_auc: 0.602', 'sum_auc: 2.090']\n",
      "Epoch3\t['loss: 0.144', 'val2_auc: 0.802', 'val3_auc: 0.704', 'val4_auc: 0.591', 'sum_auc: 2.097']\n",
      "Epoch4\t['loss: 0.141', 'val2_auc: 0.803', 'val3_auc: 0.712', 'val4_auc: 0.648', 'sum_auc: 2.163']\n",
      "Epoch5\t['loss: 0.140', 'val2_auc: 0.803', 'val3_auc: 0.711', 'val4_auc: 0.619', 'sum_auc: 2.133']\n",
      "Epoch6\t['loss: 0.139', 'val2_auc: 0.804', 'val3_auc: 0.705', 'val4_auc: 0.641', 'sum_auc: 2.151']\n",
      "Epoch 6: early stopping Threshold\n",
      "[I 2023-07-14 16:34:20,713] Trial 67 finished with value: 2.217 and parameters: {'feature_dim': 128, 'n_step': 2, 'n_shared': 4, 'relaxation_factor': 1.4, 'sparsity_coefficient': 0.00028873139761325626, 'bn_momentum': 0.9832221729402266}. Best is trial 49 with value: 2.3189.\n",
      "Epoch0\t['loss: 0.181', 'val2_auc: 0.751', 'val3_auc: 0.737', 'val4_auc: 0.761', 'sum_auc: 2.248']\n",
      "Epoch1\t['loss: 0.162', 'val2_auc: 0.762', 'val3_auc: 0.677', 'val4_auc: 0.849', 'sum_auc: 2.287']\n",
      "Epoch2\t['loss: 0.158', 'val2_auc: 0.761', 'val3_auc: 0.675', 'val4_auc: 0.861', 'sum_auc: 2.297']\n",
      "Epoch3\t['loss: 0.155', 'val2_auc: 0.749', 'val3_auc: 0.667', 'val4_auc: 0.858', 'sum_auc: 2.274']\n",
      "Epoch4\t['loss: 0.154', 'val2_auc: 0.751', 'val3_auc: 0.630', 'val4_auc: 0.857', 'sum_auc: 2.238']\n",
      "Epoch5\t['loss: 0.153', 'val2_auc: 0.739', 'val3_auc: 0.656', 'val4_auc: 0.789', 'sum_auc: 2.184']\n",
      "Epoch6\t['loss: 0.153', 'val2_auc: 0.758', 'val3_auc: 0.697', 'val4_auc: 0.835', 'sum_auc: 2.290']\n",
      "Epoch7\t['loss: 0.152', 'val2_auc: 0.749', 'val3_auc: 0.670', 'val4_auc: 0.768', 'sum_auc: 2.187']\n",
      "Epoch 7: early stopping Threshold\n",
      "[I 2023-07-14 16:44:01,670] Trial 68 finished with value: 2.2969 and parameters: {'feature_dim': 256, 'n_step': 7, 'n_shared': 3, 'relaxation_factor': 1.2, 'sparsity_coefficient': 3.05589666821579e-05, 'bn_momentum': 0.9998178835275052}. Best is trial 49 with value: 2.3189.\n",
      "Epoch0\t['loss: 0.178', 'val2_auc: 0.723', 'val3_auc: 0.667', 'val4_auc: 0.685', 'sum_auc: 2.075']\n",
      "Epoch1\t['loss: 0.157', 'val2_auc: 0.751', 'val3_auc: 0.681', 'val4_auc: 0.661', 'sum_auc: 2.093']\n",
      "Epoch2\t['loss: 0.150', 'val2_auc: 0.765', 'val3_auc: 0.676', 'val4_auc: 0.693', 'sum_auc: 2.133']\n",
      "Epoch3\t['loss: 0.147', 'val2_auc: 0.774', 'val3_auc: 0.687', 'val4_auc: 0.711', 'sum_auc: 2.172']\n",
      "Epoch4\t['loss: 0.144', 'val2_auc: 0.763', 'val3_auc: 0.675', 'val4_auc: 0.546', 'sum_auc: 1.983']\n",
      "Epoch5\t['loss: 0.143', 'val2_auc: 0.769', 'val3_auc: 0.689', 'val4_auc: 0.496', 'sum_auc: 1.954']\n",
      "Epoch6\t['loss: 0.142', 'val2_auc: 0.771', 'val3_auc: 0.698', 'val4_auc: 0.610', 'sum_auc: 2.079']\n",
      "Epoch7\t['loss: 0.142', 'val2_auc: 0.772', 'val3_auc: 0.671', 'val4_auc: 0.539', 'sum_auc: 1.982']\n",
      "Epoch8\t['loss: 0.141', 'val2_auc: 0.769', 'val3_auc: 0.672', 'val4_auc: 0.640', 'sum_auc: 2.082']\n",
      "Epoch 8: early stopping Threshold\n",
      "[I 2023-07-14 16:54:52,849] Trial 69 finished with value: 2.1723 and parameters: {'feature_dim': 256, 'n_step': 7, 'n_shared': 3, 'relaxation_factor': 1.0, 'sparsity_coefficient': 0.00015491684510292536, 'bn_momentum': 0.9922495190774453}. Best is trial 49 with value: 2.3189.\n",
      "Epoch0\t['loss: 0.177', 'val2_auc: 0.699', 'val3_auc: 0.665', 'val4_auc: 0.736', 'sum_auc: 2.099']\n",
      "Epoch1\t['loss: 0.160', 'val2_auc: 0.729', 'val3_auc: 0.681', 'val4_auc: 0.760', 'sum_auc: 2.169']\n",
      "Epoch2\t['loss: 0.156', 'val2_auc: 0.728', 'val3_auc: 0.682', 'val4_auc: 0.621', 'sum_auc: 2.031']\n",
      "Epoch3\t['loss: 0.154', 'val2_auc: 0.736', 'val3_auc: 0.686', 'val4_auc: 0.668', 'sum_auc: 2.089']\n",
      "Epoch4\t['loss: 0.152', 'val2_auc: 0.744', 'val3_auc: 0.670', 'val4_auc: 0.651', 'sum_auc: 2.065']\n",
      "Epoch5\t['loss: 0.151', 'val2_auc: 0.750', 'val3_auc: 0.674', 'val4_auc: 0.748', 'sum_auc: 2.171']\n",
      "Epoch6\t['loss: 0.150', 'val2_auc: 0.746', 'val3_auc: 0.675', 'val4_auc: 0.606', 'sum_auc: 2.027']\n",
      "Epoch7\t['loss: 0.150', 'val2_auc: 0.746', 'val3_auc: 0.656', 'val4_auc: 0.659', 'sum_auc: 2.061']\n",
      "Epoch8\t['loss: 0.149', 'val2_auc: 0.745', 'val3_auc: 0.678', 'val4_auc: 0.584', 'sum_auc: 2.006']\n",
      "Epoch9\t['loss: 0.149', 'val2_auc: 0.747', 'val3_auc: 0.655', 'val4_auc: 0.598', 'sum_auc: 2.001']\n",
      "[I 2023-07-14 17:08:35,958] Trial 70 finished with value: 2.0006 and parameters: {'feature_dim': 256, 'n_step': 8, 'n_shared': 2, 'relaxation_factor': 1.2, 'sparsity_coefficient': 6.845200569552851e-05, 'bn_momentum': 0.9870744166358222}. Best is trial 49 with value: 2.3189.\n",
      "Epoch0\t['loss: 0.181', 'val2_auc: 0.760', 'val3_auc: 0.669', 'val4_auc: 0.861', 'sum_auc: 2.290']\n",
      "Epoch1\t['loss: 0.161', 'val2_auc: 0.761', 'val3_auc: 0.672', 'val4_auc: 0.824', 'sum_auc: 2.256']\n",
      "Epoch2\t['loss: 0.155', 'val2_auc: 0.767', 'val3_auc: 0.681', 'val4_auc: 0.656', 'sum_auc: 2.104']\n",
      "Epoch5\t['loss: 0.148', 'val2_auc: 0.756', 'val3_auc: 0.698', 'val4_auc: 0.649', 'sum_auc: 2.103']\n",
      "Epoch 5: early stopping Threshold\n",
      "[I 2023-07-14 17:16:55,812] Trial 71 finished with value: 2.2896 and parameters: {'feature_dim': 256, 'n_step': 8, 'n_shared': 3, 'relaxation_factor': 1.1, 'sparsity_coefficient': 2.9451738548128144e-05, 'bn_momentum': 0.9992353075756529}. Best is trial 49 with value: 2.3189.\n",
      "Epoch0\t['loss: 0.185', 'val2_auc: 0.550', 'val3_auc: 0.525', 'val4_auc: 0.509', 'sum_auc: 1.584']\n",
      "Epoch1\t['loss: 0.172', 'val2_auc: 0.640', 'val3_auc: 0.605', 'val4_auc: 0.626', 'sum_auc: 1.870']\n",
      "Epoch2\t['loss: 0.168', 'val2_auc: 0.638', 'val3_auc: 0.585', 'val4_auc: 0.591', 'sum_auc: 1.814']\n",
      "Epoch3\t['loss: 0.167', 'val2_auc: 0.604', 'val3_auc: 0.595', 'val4_auc: 0.567', 'sum_auc: 1.765']\n",
      "Epoch4\t['loss: 0.166', 'val2_auc: 0.650', 'val3_auc: 0.630', 'val4_auc: 0.611', 'sum_auc: 1.892']\n",
      "Epoch5\t['loss: 0.165', 'val2_auc: 0.646', 'val3_auc: 0.644', 'val4_auc: 0.617', 'sum_auc: 1.907']\n",
      "Epoch6\t['loss: 0.165', 'val2_auc: 0.631', 'val3_auc: 0.620', 'val4_auc: 0.648', 'sum_auc: 1.899']\n",
      "Epoch7\t['loss: 0.164', 'val2_auc: 0.675', 'val3_auc: 0.653', 'val4_auc: 0.671', 'sum_auc: 1.999']\n",
      "Epoch8\t['loss: 0.163', 'val2_auc: 0.666', 'val3_auc: 0.606', 'val4_auc: 0.663', 'sum_auc: 1.935']\n",
      "Epoch9\t['loss: 0.163', 'val2_auc: 0.661', 'val3_auc: 0.624', 'val4_auc: 0.611', 'sum_auc: 1.895']\n",
      "[I 2023-07-14 17:29:05,473] Trial 72 finished with value: 1.8953 and parameters: {'feature_dim': 256, 'n_step': 7, 'n_shared': 3, 'relaxation_factor': 2.7, 'sparsity_coefficient': 6.772428580023055e-06, 'bn_momentum': 0.9942019999833633}. Best is trial 49 with value: 2.3189.\n",
      "Epoch0\t['loss: 0.201', 'val2_auc: 0.556', 'val3_auc: 0.544', 'val4_auc: 0.479', 'sum_auc: 1.580']\n",
      "Epoch1\t['loss: 0.169', 'val2_auc: 0.694', 'val3_auc: 0.669', 'val4_auc: 0.670', 'sum_auc: 2.033']\n",
      "Epoch2\t['loss: 0.163', 'val2_auc: 0.704', 'val3_auc: 0.640', 'val4_auc: 0.653', 'sum_auc: 1.997']\n",
      "Epoch3\t['loss: 0.159', 'val2_auc: 0.708', 'val3_auc: 0.680', 'val4_auc: 0.667', 'sum_auc: 2.055']\n",
      "Epoch6\t['loss: 0.154', 'val2_auc: 0.734', 'val3_auc: 0.667', 'val4_auc: 0.717', 'sum_auc: 2.118']\n",
      "Epoch7\t['loss: 0.153', 'val2_auc: 0.722', 'val3_auc: 0.661', 'val4_auc: 0.606', 'sum_auc: 1.989']\n",
      "Epoch8\t['loss: 0.153', 'val2_auc: 0.743', 'val3_auc: 0.687', 'val4_auc: 0.701', 'sum_auc: 2.131']\n",
      "Epoch9\t['loss: 0.152', 'val2_auc: 0.741', 'val3_auc: 0.670', 'val4_auc: 0.739', 'sum_auc: 2.150']\n",
      "[I 2023-07-14 17:38:23,154] Trial 73 finished with value: 2.1504 and parameters: {'feature_dim': 32, 'n_step': 7, 'n_shared': 3, 'relaxation_factor': 1.3, 'sparsity_coefficient': 1.7789836062517932e-05, 'bn_momentum': 0.9974886146849952}. Best is trial 49 with value: 2.3189.\n",
      "Epoch0\t['loss: 0.195', 'val2_auc: 0.535', 'val3_auc: 0.548', 'val4_auc: 0.521', 'sum_auc: 1.604']\n",
      "Epoch1\t['loss: 0.173', 'val2_auc: 0.542', 'val3_auc: 0.526', 'val4_auc: 0.594', 'sum_auc: 1.662']\n",
      "Epoch2\t['loss: 0.170', 'val2_auc: 0.647', 'val3_auc: 0.629', 'val4_auc: 0.611', 'sum_auc: 1.887']\n",
      "Epoch3\t['loss: 0.165', 'val2_auc: 0.683', 'val3_auc: 0.624', 'val4_auc: 0.582', 'sum_auc: 1.889']\n",
      "Epoch4\t['loss: 0.163', 'val2_auc: 0.688', 'val3_auc: 0.649', 'val4_auc: 0.628', 'sum_auc: 1.965']\n",
      "Epoch5\t['loss: 0.161', 'val2_auc: 0.695', 'val3_auc: 0.640', 'val4_auc: 0.631', 'sum_auc: 1.966']\n",
      "Epoch6\t['loss: 0.160', 'val2_auc: 0.718', 'val3_auc: 0.666', 'val4_auc: 0.710', 'sum_auc: 2.094']\n",
      "Epoch7\t['loss: 0.158', 'val2_auc: 0.720', 'val3_auc: 0.649', 'val4_auc: 0.698', 'sum_auc: 2.067']\n",
      "Epoch8\t['loss: 0.157', 'val2_auc: 0.715', 'val3_auc: 0.656', 'val4_auc: 0.676', 'sum_auc: 2.046']\n",
      "Epoch9\t['loss: 0.155', 'val2_auc: 0.736', 'val3_auc: 0.677', 'val4_auc: 0.711', 'sum_auc: 2.124']\n",
      "[I 2023-07-14 17:46:34,430] Trial 74 finished with value: 2.1242 and parameters: {'feature_dim': 128, 'n_step': 6, 'n_shared': 4, 'relaxation_factor': 2.3, 'sparsity_coefficient': 0.00011803080952084801, 'bn_momentum': 0.9930083215214524}. Best is trial 49 with value: 2.3189.\n",
      "Epoch0\t['loss: 0.170', 'val2_auc: 0.751', 'val3_auc: 0.687', 'val4_auc: 0.653', 'sum_auc: 2.091']\n",
      "Epoch1\t['loss: 0.149', 'val2_auc: 0.768', 'val3_auc: 0.700', 'val4_auc: 0.833', 'sum_auc: 2.301']\n",
      "Epoch2\t['loss: 0.145', 'val2_auc: 0.768', 'val3_auc: 0.674', 'val4_auc: 0.845', 'sum_auc: 2.286']\n",
      "Epoch3\t['loss: 0.143', 'val2_auc: 0.773', 'val3_auc: 0.692', 'val4_auc: 0.827', 'sum_auc: 2.292']\n",
      "Epoch4\t['loss: 0.142', 'val2_auc: 0.775', 'val3_auc: 0.699', 'val4_auc: 0.846', 'sum_auc: 2.319']\n",
      "Epoch5\t['loss: 0.139', 'val2_auc: 0.778', 'val3_auc: 0.691', 'val4_auc: 0.803', 'sum_auc: 2.273']\n",
      "Epoch6\t['loss: 0.138', 'val2_auc: 0.789', 'val3_auc: 0.721', 'val4_auc: 0.767', 'sum_auc: 2.277']\n",
      "Epoch7\t['loss: 0.136', 'val2_auc: 0.776', 'val3_auc: 0.715', 'val4_auc: 0.861', 'sum_auc: 2.353']\n",
      "Epoch8\t['loss: 0.135', 'val2_auc: 0.787', 'val3_auc: 0.728', 'val4_auc: 0.849', 'sum_auc: 2.364']\n",
      "Epoch9\t['loss: 0.134', 'val2_auc: 0.781', 'val3_auc: 0.726', 'val4_auc: 0.854', 'sum_auc: 2.361']\n",
      "[I 2023-07-14 17:51:16,139] Trial 75 finished with value: 2.3607 and parameters: {'feature_dim': 256, 'n_step': 2, 'n_shared': 2, 'relaxation_factor': 1.0, 'sparsity_coefficient': 0.00044768001615344994, 'bn_momentum': 0.9998302996755233}. Best is trial 75 with value: 2.3607.\n",
      "Epoch0\t['loss: 0.174', 'val2_auc: 0.759', 'val3_auc: 0.694', 'val4_auc: 0.792', 'sum_auc: 2.245']\n",
      "Epoch1\t['loss: 0.152', 'val2_auc: 0.763', 'val3_auc: 0.697', 'val4_auc: 0.651', 'sum_auc: 2.110']\n",
      "Epoch4\t['loss: 0.145', 'val2_auc: 0.767', 'val3_auc: 0.720', 'val4_auc: 0.661', 'sum_auc: 2.148']\n",
      "Epoch5\t['loss: 0.144', 'val2_auc: 0.775', 'val3_auc: 0.711', 'val4_auc: 0.670', 'sum_auc: 2.156']\n",
      "Epoch 5: early stopping Threshold\n",
      "[I 2023-07-14 17:55:07,958] Trial 76 finished with value: 2.2453 and parameters: {'feature_dim': 256, 'n_step': 3, 'n_shared': 2, 'relaxation_factor': 1.0, 'sparsity_coefficient': 0.00036367078408910226, 'bn_momentum': 0.9967010915202621}. Best is trial 75 with value: 2.3607.\n",
      "Epoch0\t['loss: 0.171', 'val2_auc: 0.732', 'val3_auc: 0.636', 'val4_auc: 0.846', 'sum_auc: 2.214']\n",
      "Epoch1\t['loss: 0.149', 'val2_auc: 0.749', 'val3_auc: 0.696', 'val4_auc: 0.860', 'sum_auc: 2.305']\n",
      "Epoch2\t['loss: 0.144', 'val2_auc: 0.769', 'val3_auc: 0.722', 'val4_auc: 0.851', 'sum_auc: 2.342']\n",
      "Epoch3\t['loss: 0.142', 'val2_auc: 0.774', 'val3_auc: 0.727', 'val4_auc: 0.815', 'sum_auc: 2.316']\n",
      "Epoch4\t['loss: 0.140', 'val2_auc: 0.766', 'val3_auc: 0.709', 'val4_auc: 0.849', 'sum_auc: 2.323']\n",
      "Epoch5\t['loss: 0.139', 'val2_auc: 0.768', 'val3_auc: 0.705', 'val4_auc: 0.777', 'sum_auc: 2.250']\n",
      "Epoch6\t['loss: 0.137', 'val2_auc: 0.779', 'val3_auc: 0.670', 'val4_auc: 0.775', 'sum_auc: 2.225']\n",
      "Epoch7\t['loss: 0.136', 'val2_auc: 0.782', 'val3_auc: 0.691', 'val4_auc: 0.778', 'sum_auc: 2.251']\n",
      "Epoch 7: early stopping Threshold\n",
      "[I 2023-07-14 17:58:57,738] Trial 77 finished with value: 2.3423 and parameters: {'feature_dim': 256, 'n_step': 2, 'n_shared': 2, 'relaxation_factor': 1.1, 'sparsity_coefficient': 0.0005102820827684426, 'bn_momentum': 0.9997942081537435}. Best is trial 75 with value: 2.3607.\n",
      "Epoch0\t['loss: 0.168', 'val2_auc: 0.763', 'val3_auc: 0.700', 'val4_auc: 0.625', 'sum_auc: 2.089']\n",
      "Epoch1\t['loss: 0.149', 'val2_auc: 0.784', 'val3_auc: 0.728', 'val4_auc: 0.681', 'sum_auc: 2.193']\n",
      "Epoch2\t['loss: 0.144', 'val2_auc: 0.789', 'val3_auc: 0.714', 'val4_auc: 0.709', 'sum_auc: 2.213']\n",
      "Epoch3\t['loss: 0.142', 'val2_auc: 0.789', 'val3_auc: 0.724', 'val4_auc: 0.595', 'sum_auc: 2.107']\n",
      "Epoch4\t['loss: 0.141', 'val2_auc: 0.792', 'val3_auc: 0.732', 'val4_auc: 0.620', 'sum_auc: 2.145']\n",
      "Epoch5\t['loss: 0.139', 'val2_auc: 0.807', 'val3_auc: 0.719', 'val4_auc: 0.595', 'sum_auc: 2.121']\n",
      "Epoch6\t['loss: 0.138', 'val2_auc: 0.811', 'val3_auc: 0.716', 'val4_auc: 0.628', 'sum_auc: 2.156']\n",
      "Epoch7\t['loss: 0.137', 'val2_auc: 0.815', 'val3_auc: 0.727', 'val4_auc: 0.659', 'sum_auc: 2.200']\n",
      "Epoch 7: early stopping Threshold\n",
      "[I 2023-07-14 18:02:45,326] Trial 78 finished with value: 2.2126 and parameters: {'feature_dim': 256, 'n_step': 2, 'n_shared': 2, 'relaxation_factor': 1.1, 'sparsity_coefficient': 0.0008997470463120219, 'bn_momentum': 0.9904237869716954}. Best is trial 75 with value: 2.3607.\n",
      "Epoch0\t['loss: 0.165', 'val2_auc: 0.775', 'val3_auc: 0.713', 'val4_auc: 0.662', 'sum_auc: 2.150']\n",
      "Epoch1\t['loss: 0.148', 'val2_auc: 0.786', 'val3_auc: 0.721', 'val4_auc: 0.630', 'sum_auc: 2.136']\n",
      "Epoch2\t['loss: 0.144', 'val2_auc: 0.791', 'val3_auc: 0.731', 'val4_auc: 0.628', 'sum_auc: 2.151']\n",
      "Epoch3\t['loss: 0.141', 'val2_auc: 0.800', 'val3_auc: 0.718', 'val4_auc: 0.628', 'sum_auc: 2.146']\n",
      "Epoch4\t['loss: 0.141', 'val2_auc: 0.801', 'val3_auc: 0.740', 'val4_auc: 0.651', 'sum_auc: 2.193']\n",
      "Epoch5\t['loss: 0.139', 'val2_auc: 0.806', 'val3_auc: 0.716', 'val4_auc: 0.655', 'sum_auc: 2.176']\n",
      "Epoch6\t['loss: 0.138', 'val2_auc: 0.810', 'val3_auc: 0.698', 'val4_auc: 0.613', 'sum_auc: 2.121']\n",
      "Epoch7\t['loss: 0.137', 'val2_auc: 0.813', 'val3_auc: 0.711', 'val4_auc: 0.684', 'sum_auc: 2.208']\n",
      "Epoch8\t['loss: 0.135', 'val2_auc: 0.820', 'val3_auc: 0.725', 'val4_auc: 0.677', 'sum_auc: 2.221']\n",
      "Epoch9\t['loss: 0.134', 'val2_auc: 0.821', 'val3_auc: 0.737', 'val4_auc: 0.698', 'sum_auc: 2.256']\n",
      "[I 2023-07-14 18:07:27,860] Trial 79 finished with value: 2.2562 and parameters: {'feature_dim': 256, 'n_step': 2, 'n_shared': 2, 'relaxation_factor': 1.0, 'sparsity_coefficient': 0.00047138808584308155, 'bn_momentum': 0.9943875668988038}. Best is trial 75 with value: 2.3607.\n",
      "Epoch0\t['loss: 0.251', 'val2_auc: 0.663', 'val3_auc: 0.663', 'val4_auc: 0.685', 'sum_auc: 2.010']\n",
      "Epoch1\t['loss: 0.163', 'val2_auc: 0.706', 'val3_auc: 0.671', 'val4_auc: 0.728', 'sum_auc: 2.105']\n",
      "Epoch2\t['loss: 0.159', 'val2_auc: 0.733', 'val3_auc: 0.682', 'val4_auc: 0.786', 'sum_auc: 2.202']\n",
      "Epoch3\t['loss: 0.156', 'val2_auc: 0.738', 'val3_auc: 0.702', 'val4_auc: 0.784', 'sum_auc: 2.224']\n",
      "Epoch4\t['loss: 0.153', 'val2_auc: 0.752', 'val3_auc: 0.725', 'val4_auc: 0.760', 'sum_auc: 2.238']\n",
      "Epoch5\t['loss: 0.151', 'val2_auc: 0.764', 'val3_auc: 0.732', 'val4_auc: 0.720', 'sum_auc: 2.216']\n",
      "Epoch6\t['loss: 0.149', 'val2_auc: 0.774', 'val3_auc: 0.734', 'val4_auc: 0.644', 'sum_auc: 2.152']\n",
      "Epoch7\t['loss: 0.146', 'val2_auc: 0.779', 'val3_auc: 0.722', 'val4_auc: 0.719', 'sum_auc: 2.220']\n",
      "Epoch8\t['loss: 0.145', 'val2_auc: 0.788', 'val3_auc: 0.726', 'val4_auc: 0.714', 'sum_auc: 2.228']\n",
      "Epoch9\t['loss: 0.144', 'val2_auc: 0.789', 'val3_auc: 0.722', 'val4_auc: 0.769', 'sum_auc: 2.281']\n",
      "[I 2023-07-14 18:10:54,314] Trial 80 finished with value: 2.2807 and parameters: {'feature_dim': 8, 'n_step': 2, 'n_shared': 2, 'relaxation_factor': 1.5, 'sparsity_coefficient': 0.00021452091637857315, 'bn_momentum': 0.992418891661106}. Best is trial 75 with value: 2.3607.\n",
      "Epoch0\t['loss: 0.168', 'val2_auc: 0.752', 'val3_auc: 0.671', 'val4_auc: 0.770', 'sum_auc: 2.194']\n",
      "Epoch1\t['loss: 0.149', 'val2_auc: 0.775', 'val3_auc: 0.681', 'val4_auc: 0.759', 'sum_auc: 2.215']\n",
      "Epoch2\t['loss: 0.144', 'val2_auc: 0.793', 'val3_auc: 0.729', 'val4_auc: 0.718', 'sum_auc: 2.240']\n",
      "Epoch3\t['loss: 0.143', 'val2_auc: 0.807', 'val3_auc: 0.733', 'val4_auc: 0.660', 'sum_auc: 2.200']\n",
      "Epoch4\t['loss: 0.140', 'val2_auc: 0.813', 'val3_auc: 0.739', 'val4_auc: 0.673', 'sum_auc: 2.225']\n",
      "Epoch5\t['loss: 0.139', 'val2_auc: 0.804', 'val3_auc: 0.717', 'val4_auc: 0.647', 'sum_auc: 2.168']\n",
      "Epoch6\t['loss: 0.139', 'val2_auc: 0.811', 'val3_auc: 0.750', 'val4_auc: 0.647', 'sum_auc: 2.208']\n",
      "Epoch7\t['loss: 0.138', 'val2_auc: 0.815', 'val3_auc: 0.755', 'val4_auc: 0.650', 'sum_auc: 2.221']\n",
      "Epoch 7: early stopping Threshold\n",
      "[I 2023-07-14 18:14:40,396] Trial 81 finished with value: 2.24 and parameters: {'feature_dim': 256, 'n_step': 2, 'n_shared': 2, 'relaxation_factor': 1.2, 'sparsity_coefficient': 0.0006315509316055307, 'bn_momentum': 0.9973207497783388}. Best is trial 75 with value: 2.3607.\n",
      "Epoch0\t['loss: 0.169', 'val2_auc: 0.765', 'val3_auc: 0.688', 'val4_auc: 0.790', 'sum_auc: 2.243']\n",
      "Epoch1\t['loss: 0.150', 'val2_auc: 0.763', 'val3_auc: 0.697', 'val4_auc: 0.779', 'sum_auc: 2.239']\n",
      "Epoch2\t['loss: 0.147', 'val2_auc: 0.757', 'val3_auc: 0.696', 'val4_auc: 0.697', 'sum_auc: 2.150']\n",
      "Epoch3\t['loss: 0.144', 'val2_auc: 0.778', 'val3_auc: 0.710', 'val4_auc: 0.749', 'sum_auc: 2.237']\n",
      "Epoch4\t['loss: 0.140', 'val2_auc: 0.770', 'val3_auc: 0.701', 'val4_auc: 0.642', 'sum_auc: 2.113']\n",
      "Epoch5\t['loss: 0.139', 'val2_auc: 0.771', 'val3_auc: 0.677', 'val4_auc: 0.592', 'sum_auc: 2.039']\n",
      "Epoch 5: early stopping Threshold\n",
      "[I 2023-07-14 18:18:29,464] Trial 82 finished with value: 2.2431 and parameters: {'feature_dim': 256, 'n_step': 3, 'n_shared': 2, 'relaxation_factor': 1.2, 'sparsity_coefficient': 0.00025771982195155863, 'bn_momentum': 0.9997458570779307}. Best is trial 75 with value: 2.3607.\n",
      "Epoch0\t['loss: 0.170', 'val2_auc: 0.656', 'val3_auc: 0.592', 'val4_auc: 0.610', 'sum_auc: 1.857']\n",
      "Epoch1\t['loss: 0.148', 'val2_auc: 0.762', 'val3_auc: 0.677', 'val4_auc: 0.843', 'sum_auc: 2.282']\n",
      "Epoch2\t['loss: 0.142', 'val2_auc: 0.757', 'val3_auc: 0.696', 'val4_auc: 0.825', 'sum_auc: 2.278']\n",
      "Epoch3\t['loss: 0.139', 'val2_auc: 0.771', 'val3_auc: 0.706', 'val4_auc: 0.748', 'sum_auc: 2.225']\n",
      "Epoch4\t['loss: 0.138', 'val2_auc: 0.777', 'val3_auc: 0.695', 'val4_auc: 0.798', 'sum_auc: 2.270']\n",
      "Epoch5\t['loss: 0.139', 'val2_auc: 0.777', 'val3_auc: 0.698', 'val4_auc: 0.800', 'sum_auc: 2.275']\n",
      "Epoch6\t['loss: 0.137', 'val2_auc: 0.787', 'val3_auc: 0.694', 'val4_auc: 0.757', 'sum_auc: 2.237']\n",
      "Epoch 6: early stopping Threshold\n",
      "[I 2023-07-14 18:21:51,702] Trial 83 finished with value: 2.2821 and parameters: {'feature_dim': 256, 'n_step': 2, 'n_shared': 1, 'relaxation_factor': 1.1, 'sparsity_coefficient': 0.0004229873784852526, 'bn_momentum': 0.99983121971374}. Best is trial 75 with value: 2.3607.\n",
      "Epoch0\t['loss: 0.183', 'val2_auc: 0.746', 'val3_auc: 0.670', 'val4_auc: 0.766', 'sum_auc: 2.182']\n",
      "Epoch1\t['loss: 0.160', 'val2_auc: 0.742', 'val3_auc: 0.666', 'val4_auc: 0.685', 'sum_auc: 2.093']\n",
      "Epoch2\t['loss: 0.152', 'val2_auc: 0.749', 'val3_auc: 0.672', 'val4_auc: 0.675', 'sum_auc: 2.096']\n",
      "Epoch3\t['loss: 0.149', 'val2_auc: 0.755', 'val3_auc: 0.657', 'val4_auc: 0.680', 'sum_auc: 2.092']\n",
      "Epoch4\t['loss: 0.146', 'val2_auc: 0.754', 'val3_auc: 0.668', 'val4_auc: 0.706', 'sum_auc: 2.128']\n",
      "Epoch5\t['loss: 0.145', 'val2_auc: 0.758', 'val3_auc: 0.671', 'val4_auc: 0.749', 'sum_auc: 2.178']\n",
      "Epoch 5: early stopping Threshold\n",
      "[I 2023-07-14 18:26:40,426] Trial 84 finished with value: 2.182 and parameters: {'feature_dim': 256, 'n_step': 4, 'n_shared': 2, 'relaxation_factor': 1.3, 'sparsity_coefficient': 7.016133038937755e-05, 'bn_momentum': 0.9949521931858448}. Best is trial 75 with value: 2.3607.\n",
      "Epoch0\t['loss: 0.179', 'val2_auc: 0.729', 'val3_auc: 0.666', 'val4_auc: 0.769', 'sum_auc: 2.164']\n",
      "Epoch1\t['loss: 0.155', 'val2_auc: 0.762', 'val3_auc: 0.676', 'val4_auc: 0.710', 'sum_auc: 2.148']\n",
      "Epoch2\t['loss: 0.149', 'val2_auc: 0.763', 'val3_auc: 0.670', 'val4_auc: 0.689', 'sum_auc: 2.121']\n",
      "Epoch3\t['loss: 0.146', 'val2_auc: 0.785', 'val3_auc: 0.697', 'val4_auc: 0.720', 'sum_auc: 2.202']\n",
      "Epoch4\t['loss: 0.143', 'val2_auc: 0.792', 'val3_auc: 0.694', 'val4_auc: 0.621', 'sum_auc: 2.107']\n",
      "Epoch5\t['loss: 0.143', 'val2_auc: 0.769', 'val3_auc: 0.695', 'val4_auc: 0.613', 'sum_auc: 2.077']\n",
      "Epoch6\t['loss: 0.142', 'val2_auc: 0.790', 'val3_auc: 0.691', 'val4_auc: 0.600', 'sum_auc: 2.081']\n",
      "Epoch7\t['loss: 0.141', 'val2_auc: 0.791', 'val3_auc: 0.683', 'val4_auc: 0.708', 'sum_auc: 2.182']\n",
      "Epoch8\t['loss: 0.141', 'val2_auc: 0.795', 'val3_auc: 0.707', 'val4_auc: 0.635', 'sum_auc: 2.138']\n",
      "Epoch 8: early stopping Threshold\n",
      "[I 2023-07-14 18:32:19,281] Trial 85 finished with value: 2.2018 and parameters: {'feature_dim': 256, 'n_step': 3, 'n_shared': 3, 'relaxation_factor': 1.1, 'sparsity_coefficient': 0.0016227597672671306, 'bn_momentum': 0.9881692688593857}. Best is trial 75 with value: 2.3607.\n",
      "Epoch0\t['loss: 0.186', 'val2_auc: 0.760', 'val3_auc: 0.710', 'val4_auc: 0.834', 'sum_auc: 2.304']\n",
      "Epoch1\t['loss: 0.161', 'val2_auc: 0.735', 'val3_auc: 0.678', 'val4_auc: 0.696', 'sum_auc: 2.109']\n",
      "Epoch2\t['loss: 0.155', 'val2_auc: 0.750', 'val3_auc: 0.675', 'val4_auc: 0.702', 'sum_auc: 2.128']\n",
      "Epoch3\t['loss: 0.150', 'val2_auc: 0.766', 'val3_auc: 0.695', 'val4_auc: 0.724', 'sum_auc: 2.185']\n",
      "Epoch4\t['loss: 0.147', 'val2_auc: 0.774', 'val3_auc: 0.688', 'val4_auc: 0.673', 'sum_auc: 2.135']\n",
      "Epoch5\t['loss: 0.144', 'val2_auc: 0.780', 'val3_auc: 0.703', 'val4_auc: 0.682', 'sum_auc: 2.164']\n",
      "Epoch 5: early stopping Threshold\n",
      "[I 2023-07-14 18:37:25,261] Trial 86 finished with value: 2.3042 and parameters: {'feature_dim': 64, 'n_step': 6, 'n_shared': 2, 'relaxation_factor': 1.0, 'sparsity_coefficient': 0.0002120760333962052, 'bn_momentum': 0.9963993214320468}. Best is trial 75 with value: 2.3607.\n",
      "Epoch2\t['loss: 0.154', 'val2_auc: 0.762', 'val3_auc: 0.694', 'val4_auc: 0.681', 'sum_auc: 2.137']\n",
      "Epoch3\t['loss: 0.149', 'val2_auc: 0.771', 'val3_auc: 0.691', 'val4_auc: 0.611', 'sum_auc: 2.073']\n",
      "Epoch4\t['loss: 0.145', 'val2_auc: 0.784', 'val3_auc: 0.693', 'val4_auc: 0.590', 'sum_auc: 2.067']\n",
      "Epoch5\t['loss: 0.143', 'val2_auc: 0.791', 'val3_auc: 0.702', 'val4_auc: 0.676', 'sum_auc: 2.170']\n",
      "Epoch6\t['loss: 0.141', 'val2_auc: 0.791', 'val3_auc: 0.697', 'val4_auc: 0.674', 'sum_auc: 2.161']\n",
      "Epoch7\t['loss: 0.141', 'val2_auc: 0.795', 'val3_auc: 0.705', 'val4_auc: 0.652', 'sum_auc: 2.152']\n",
      "Epoch8\t['loss: 0.140', 'val2_auc: 0.801', 'val3_auc: 0.700', 'val4_auc: 0.686', 'sum_auc: 2.187']\n",
      "Epoch9\t['loss: 0.138', 'val2_auc: 0.800', 'val3_auc: 0.697', 'val4_auc: 0.663', 'sum_auc: 2.160']\n",
      "[I 2023-07-14 18:45:41,040] Trial 87 finished with value: 2.1601 and parameters: {'feature_dim': 64, 'n_step': 6, 'n_shared': 2, 'relaxation_factor': 1.0, 'sparsity_coefficient': 0.0009694012228379899, 'bn_momentum': 0.9904114148574527}. Best is trial 75 with value: 2.3607.\n",
      "Epoch0\t['loss: 0.184', 'val2_auc: 0.726', 'val3_auc: 0.670', 'val4_auc: 0.723', 'sum_auc: 2.119']\n",
      "Epoch1\t['loss: 0.160', 'val2_auc: 0.735', 'val3_auc: 0.683', 'val4_auc: 0.688', 'sum_auc: 2.106']\n",
      "Epoch2\t['loss: 0.154', 'val2_auc: 0.750', 'val3_auc: 0.701', 'val4_auc: 0.727', 'sum_auc: 2.178']\n",
      "Epoch3\t['loss: 0.150', 'val2_auc: 0.758', 'val3_auc: 0.692', 'val4_auc: 0.739', 'sum_auc: 2.189']\n",
      "Epoch4\t['loss: 0.148', 'val2_auc: 0.769', 'val3_auc: 0.682', 'val4_auc: 0.714', 'sum_auc: 2.165']\n",
      "Epoch5\t['loss: 0.145', 'val2_auc: 0.772', 'val3_auc: 0.684', 'val4_auc: 0.727', 'sum_auc: 2.183']\n",
      "Epoch6\t['loss: 0.144', 'val2_auc: 0.775', 'val3_auc: 0.685', 'val4_auc: 0.709', 'sum_auc: 2.169']\n",
      "Epoch7\t['loss: 0.142', 'val2_auc: 0.779', 'val3_auc: 0.688', 'val4_auc: 0.687', 'sum_auc: 2.153']\n",
      "Epoch8\t['loss: 0.141', 'val2_auc: 0.780', 'val3_auc: 0.693', 'val4_auc: 0.692', 'sum_auc: 2.165']\n",
      "Epoch 8: early stopping Threshold\n",
      "[I 2023-07-14 18:53:11,833] Trial 88 finished with value: 2.1891 and parameters: {'feature_dim': 64, 'n_step': 6, 'n_shared': 2, 'relaxation_factor': 1.0, 'sparsity_coefficient': 0.0001442139844906696, 'bn_momentum': 0.9936643967947719}. Best is trial 75 with value: 2.3607.\n",
      "Epoch0\t['loss: 0.179', 'val2_auc: 0.726', 'val3_auc: 0.678', 'val4_auc: 0.738', 'sum_auc: 2.142']\n",
      "Epoch1\t['loss: 0.153', 'val2_auc: 0.773', 'val3_auc: 0.685', 'val4_auc: 0.720', 'sum_auc: 2.178']\n",
      "Epoch2\t['loss: 0.146', 'val2_auc: 0.789', 'val3_auc: 0.698', 'val4_auc: 0.685', 'sum_auc: 2.173']\n",
      "Epoch3\t['loss: 0.141', 'val2_auc: 0.796', 'val3_auc: 0.713', 'val4_auc: 0.631', 'sum_auc: 2.139']\n",
      "Epoch4\t['loss: 0.139', 'val2_auc: 0.801', 'val3_auc: 0.705', 'val4_auc: 0.608', 'sum_auc: 2.114']\n",
      "Epoch5\t['loss: 0.137', 'val2_auc: 0.806', 'val3_auc: 0.728', 'val4_auc: 0.676', 'sum_auc: 2.210']\n",
      "Epoch6\t['loss: 0.136', 'val2_auc: 0.807', 'val3_auc: 0.729', 'val4_auc: 0.736', 'sum_auc: 2.272']\n",
      "Epoch7\t['loss: 0.135', 'val2_auc: 0.809', 'val3_auc: 0.731', 'val4_auc: 0.674', 'sum_auc: 2.214']\n",
      "Epoch8\t['loss: 0.134', 'val2_auc: 0.814', 'val3_auc: 0.744', 'val4_auc: 0.659', 'sum_auc: 2.217']\n",
      "Epoch9\t['loss: 0.133', 'val2_auc: 0.812', 'val3_auc: 0.725', 'val4_auc: 0.680', 'sum_auc: 2.217']\n",
      "[I 2023-07-14 18:56:38,605] Trial 89 finished with value: 2.2166 and parameters: {'feature_dim': 64, 'n_step': 2, 'n_shared': 2, 'relaxation_factor': 1.1, 'sparsity_coefficient': 0.00018319494771933977, 'bn_momentum': 0.9853866165847156}. Best is trial 75 with value: 2.3607.\n",
      "Epoch2\t['loss: 0.153', 'val2_auc: 0.750', 'val3_auc: 0.697', 'val4_auc: 0.706', 'sum_auc: 2.154']\n",
      "Epoch3\t['loss: 0.148', 'val2_auc: 0.764', 'val3_auc: 0.716', 'val4_auc: 0.734', 'sum_auc: 2.214']\n",
      "Epoch4\t['loss: 0.146', 'val2_auc: 0.772', 'val3_auc: 0.723', 'val4_auc: 0.725', 'sum_auc: 2.220']\n",
      "Epoch5\t['loss: 0.144', 'val2_auc: 0.774', 'val3_auc: 0.701', 'val4_auc: 0.761', 'sum_auc: 2.236']\n",
      "Epoch 5: early stopping Threshold\n",
      "[I 2023-07-14 19:01:03,336] Trial 90 finished with value: 2.2419 and parameters: {'feature_dim': 64, 'n_step': 5, 'n_shared': 1, 'relaxation_factor': 1.0, 'sparsity_coefficient': 0.0003805120552356859, 'bn_momentum': 0.9967111541697032}. Best is trial 75 with value: 2.3607.\n",
      "Epoch0\t['loss: 0.191', 'val2_auc: 0.717', 'val3_auc: 0.666', 'val4_auc: 0.836', 'sum_auc: 2.220']\n",
      "Epoch1\t['loss: 0.165', 'val2_auc: 0.733', 'val3_auc: 0.676', 'val4_auc: 0.803', 'sum_auc: 2.212']\n",
      "Epoch2\t['loss: 0.159', 'val2_auc: 0.725', 'val3_auc: 0.683', 'val4_auc: 0.740', 'sum_auc: 2.148']\n",
      "Epoch3\t['loss: 0.156', 'val2_auc: 0.738', 'val3_auc: 0.668', 'val4_auc: 0.724', 'sum_auc: 2.130']\n",
      "Epoch4\t['loss: 0.154', 'val2_auc: 0.740', 'val3_auc: 0.669', 'val4_auc: 0.735', 'sum_auc: 2.144']\n",
      "Epoch5\t['loss: 0.152', 'val2_auc: 0.738', 'val3_auc: 0.677', 'val4_auc: 0.685', 'sum_auc: 2.099']\n",
      "Epoch 5: early stopping Threshold\n",
      "[I 2023-07-14 19:06:50,847] Trial 91 finished with value: 2.2194 and parameters: {'feature_dim': 32, 'n_step': 7, 'n_shared': 2, 'relaxation_factor': 1.2, 'sparsity_coefficient': 3.889995099610577e-05, 'bn_momentum': 0.9981869788531498}. Best is trial 75 with value: 2.3607.\n",
      "Epoch0\t['loss: 0.225', 'val2_auc: 0.655', 'val3_auc: 0.649', 'val4_auc: 0.687', 'sum_auc: 1.992']\n",
      "Epoch1\t['loss: 0.166', 'val2_auc: 0.689', 'val3_auc: 0.662', 'val4_auc: 0.664', 'sum_auc: 2.015']\n",
      "Epoch2\t['loss: 0.161', 'val2_auc: 0.704', 'val3_auc: 0.669', 'val4_auc: 0.637', 'sum_auc: 2.010']\n",
      "Epoch3\t['loss: 0.158', 'val2_auc: 0.717', 'val3_auc: 0.706', 'val4_auc: 0.695', 'sum_auc: 2.118']\n",
      "Epoch4\t['loss: 0.157', 'val2_auc: 0.734', 'val3_auc: 0.689', 'val4_auc: 0.734', 'sum_auc: 2.157']\n",
      "Epoch5\t['loss: 0.155', 'val2_auc: 0.731', 'val3_auc: 0.688', 'val4_auc: 0.663', 'sum_auc: 2.082']\n",
      "Epoch6\t['loss: 0.154', 'val2_auc: 0.732', 'val3_auc: 0.673', 'val4_auc: 0.677', 'sum_auc: 2.082']\n",
      "Epoch7\t['loss: 0.153', 'val2_auc: 0.739', 'val3_auc: 0.680', 'val4_auc: 0.681', 'sum_auc: 2.101']\n",
      "Epoch8\t['loss: 0.152', 'val2_auc: 0.754', 'val3_auc: 0.675', 'val4_auc: 0.728', 'sum_auc: 2.157']\n",
      "Epoch9\t['loss: 0.151', 'val2_auc: 0.730', 'val3_auc: 0.671', 'val4_auc: 0.589', 'sum_auc: 1.990']\n",
      "[I 2023-07-14 19:15:05,115] Trial 92 finished with value: 1.99 and parameters: {'feature_dim': 16, 'n_step': 6, 'n_shared': 3, 'relaxation_factor': 1.1, 'sparsity_coefficient': 0.00011441915453862153, 'bn_momentum': 0.9958119007995833}. Best is trial 75 with value: 2.3607.\n",
      "Epoch0\t['loss: 0.174', 'val2_auc: 0.747', 'val3_auc: 0.684', 'val4_auc: 0.647', 'sum_auc: 2.079']\n",
      "Epoch1\t['loss: 0.151', 'val2_auc: 0.753', 'val3_auc: 0.674', 'val4_auc: 0.641', 'sum_auc: 2.068']\n",
      "Epoch2\t['loss: 0.147', 'val2_auc: 0.770', 'val3_auc: 0.670', 'val4_auc: 0.641', 'sum_auc: 2.081']\n",
      "Epoch3\t['loss: 0.146', 'val2_auc: 0.763', 'val3_auc: 0.682', 'val4_auc: 0.678', 'sum_auc: 2.124']\n",
      "Epoch4\t['loss: 0.144', 'val2_auc: 0.767', 'val3_auc: 0.692', 'val4_auc: 0.649', 'sum_auc: 2.108']\n",
      "Epoch5\t['loss: 0.143', 'val2_auc: 0.770', 'val3_auc: 0.676', 'val4_auc: 0.576', 'sum_auc: 2.022']\n",
      "Epoch6\t['loss: 0.141', 'val2_auc: 0.775', 'val3_auc: 0.680', 'val4_auc: 0.660', 'sum_auc: 2.116']\n",
      "Epoch7\t['loss: 0.141', 'val2_auc: 0.783', 'val3_auc: 0.690', 'val4_auc: 0.694', 'sum_auc: 2.168']\n",
      "Epoch8\t['loss: 0.140', 'val2_auc: 0.776', 'val3_auc: 0.695', 'val4_auc: 0.625', 'sum_auc: 2.096']\n",
      "Epoch9\t['loss: 0.140', 'val2_auc: 0.786', 'val3_auc: 0.696', 'val4_auc: 0.613', 'sum_auc: 2.095']\n",
      "[I 2023-07-14 19:21:22,654] Trial 93 finished with value: 2.0952 and parameters: {'feature_dim': 256, 'n_step': 3, 'n_shared': 2, 'relaxation_factor': 1.3, 'sparsity_coefficient': 0.00021827966947781855, 'bn_momentum': 0.9933788924983785}. Best is trial 75 with value: 2.3607.\n",
      "Epoch0\t['loss: 0.166', 'val2_auc: 0.763', 'val3_auc: 0.697', 'val4_auc: 0.784', 'sum_auc: 2.244']\n",
      "Epoch1\t['loss: 0.147', 'val2_auc: 0.781', 'val3_auc: 0.695', 'val4_auc: 0.632', 'sum_auc: 2.108']\n",
      "Epoch2\t['loss: 0.144', 'val2_auc: 0.786', 'val3_auc: 0.705', 'val4_auc: 0.706', 'sum_auc: 2.198']\n",
      "Epoch3\t['loss: 0.142', 'val2_auc: 0.766', 'val3_auc: 0.739', 'val4_auc: 0.672', 'sum_auc: 2.177']\n",
      "Epoch4\t['loss: 0.142', 'val2_auc: 0.796', 'val3_auc: 0.739', 'val4_auc: 0.687', 'sum_auc: 2.222']\n",
      "Epoch5\t['loss: 0.140', 'val2_auc: 0.799', 'val3_auc: 0.708', 'val4_auc: 0.756', 'sum_auc: 2.263']\n",
      "Epoch6\t['loss: 0.138', 'val2_auc: 0.802', 'val3_auc: 0.740', 'val4_auc: 0.736', 'sum_auc: 2.279']\n",
      "Epoch7\t['loss: 0.137', 'val2_auc: 0.804', 'val3_auc: 0.719', 'val4_auc: 0.755', 'sum_auc: 2.278']\n",
      "Epoch8\t['loss: 0.136', 'val2_auc: 0.806', 'val3_auc: 0.721', 'val4_auc: 0.757', 'sum_auc: 2.284']\n",
      "Epoch9\t['loss: 0.135', 'val2_auc: 0.809', 'val3_auc: 0.752', 'val4_auc: 0.732', 'sum_auc: 2.293']\n",
      "[I 2023-07-14 19:26:03,127] Trial 94 finished with value: 2.2935 and parameters: {'feature_dim': 256, 'n_step': 2, 'n_shared': 2, 'relaxation_factor': 1.2, 'sparsity_coefficient': 8.363144151094225e-05, 'bn_momentum': 0.9973218744954349}. Best is trial 75 with value: 2.3607.\n",
      "Epoch0\t['loss: 0.178', 'val2_auc: 0.766', 'val3_auc: 0.685', 'val4_auc: 0.797', 'sum_auc: 2.247']\n",
      "Epoch1\t['loss: 0.158', 'val2_auc: 0.756', 'val3_auc: 0.684', 'val4_auc: 0.761', 'sum_auc: 2.200']\n",
      "Epoch2\t['loss: 0.151', 'val2_auc: 0.763', 'val3_auc: 0.687', 'val4_auc: 0.777', 'sum_auc: 2.227']\n",
      "Epoch3\t['loss: 0.147', 'val2_auc: 0.769', 'val3_auc: 0.707', 'val4_auc: 0.838', 'sum_auc: 2.314']\n",
      "Epoch4\t['loss: 0.145', 'val2_auc: 0.772', 'val3_auc: 0.694', 'val4_auc: 0.795', 'sum_auc: 2.261']\n",
      "Epoch5\t['loss: 0.144', 'val2_auc: 0.769', 'val3_auc: 0.694', 'val4_auc: 0.835', 'sum_auc: 2.298']\n",
      "Epoch6\t['loss: 0.143', 'val2_auc: 0.764', 'val3_auc: 0.699', 'val4_auc: 0.838', 'sum_auc: 2.302']\n",
      "Epoch7\t['loss: 0.141', 'val2_auc: 0.769', 'val3_auc: 0.705', 'val4_auc: 0.751', 'sum_auc: 2.224']\n",
      "Epoch8\t['loss: 0.140', 'val2_auc: 0.769', 'val3_auc: 0.704', 'val4_auc: 0.786', 'sum_auc: 2.258']\n",
      "Epoch 8: early stopping Threshold\n",
      "[I 2023-07-14 19:35:43,165] Trial 95 finished with value: 2.3139 and parameters: {'feature_dim': 256, 'n_step': 6, 'n_shared': 3, 'relaxation_factor': 1.0, 'sparsity_coefficient': 5.678098990179924e-05, 'bn_momentum': 0.9998255140851426}. Best is trial 75 with value: 2.3607.\n",
      "Epoch0\t['loss: 0.195', 'val2_auc: 0.689', 'val3_auc: 0.669', 'val4_auc: 0.731', 'sum_auc: 2.089']\n",
      "Epoch1\t['loss: 0.164', 'val2_auc: 0.725', 'val3_auc: 0.683', 'val4_auc: 0.675', 'sum_auc: 2.083']\n",
      "Epoch2\t['loss: 0.158', 'val2_auc: 0.729', 'val3_auc: 0.678', 'val4_auc: 0.666', 'sum_auc: 2.073']\n",
      "Epoch3\t['loss: 0.155', 'val2_auc: 0.745', 'val3_auc: 0.694', 'val4_auc: 0.651', 'sum_auc: 2.090']\n",
      "Epoch4\t['loss: 0.152', 'val2_auc: 0.753', 'val3_auc: 0.685', 'val4_auc: 0.621', 'sum_auc: 2.060']\n",
      "Epoch5\t['loss: 0.151', 'val2_auc: 0.753', 'val3_auc: 0.680', 'val4_auc: 0.623', 'sum_auc: 2.056']\n",
      "Epoch6\t['loss: 0.149', 'val2_auc: 0.765', 'val3_auc: 0.676', 'val4_auc: 0.662', 'sum_auc: 2.103']\n",
      "Epoch9\t['loss: 0.144', 'val2_auc: 0.767', 'val3_auc: 0.665', 'val4_auc: 0.576', 'sum_auc: 2.008']\n",
      "[I 2023-07-14 19:43:57,548] Trial 96 finished with value: 2.0082 and parameters: {'feature_dim': 64, 'n_step': 6, 'n_shared': 3, 'relaxation_factor': 1.0, 'sparsity_coefficient': 0.0005612943998910708, 'bn_momentum': 0.9945284931462776}. Best is trial 75 with value: 2.3607.\n",
      "Epoch0\t['loss: 0.179', 'val2_auc: 0.729', 'val3_auc: 0.680', 'val4_auc: 0.734', 'sum_auc: 2.143']\n",
      "Epoch1\t['loss: 0.154', 'val2_auc: 0.750', 'val3_auc: 0.679', 'val4_auc: 0.731', 'sum_auc: 2.161']\n",
      "Epoch2\t['loss: 0.149', 'val2_auc: 0.762', 'val3_auc: 0.684', 'val4_auc: 0.740', 'sum_auc: 2.186']\n",
      "Epoch3\t['loss: 0.146', 'val2_auc: 0.774', 'val3_auc: 0.678', 'val4_auc: 0.676', 'sum_auc: 2.129']\n",
      "Epoch4\t['loss: 0.144', 'val2_auc: 0.782', 'val3_auc: 0.676', 'val4_auc: 0.651', 'sum_auc: 2.109']\n",
      "Epoch5\t['loss: 0.142', 'val2_auc: 0.780', 'val3_auc: 0.676', 'val4_auc: 0.661', 'sum_auc: 2.117']\n",
      "Epoch6\t['loss: 0.141', 'val2_auc: 0.789', 'val3_auc: 0.678', 'val4_auc: 0.627', 'sum_auc: 2.093']\n",
      "Epoch7\t['loss: 0.139', 'val2_auc: 0.790', 'val3_auc: 0.685', 'val4_auc: 0.672', 'sum_auc: 2.147']\n",
      "Epoch 7: early stopping Threshold\n",
      "[I 2023-07-14 19:50:44,543] Trial 97 finished with value: 2.1858 and parameters: {'feature_dim': 32, 'n_step': 6, 'n_shared': 0, 'relaxation_factor': 1.1, 'sparsity_coefficient': 5.955696381402883e-05, 'bn_momentum': 0.9908961238772228}. Best is trial 75 with value: 2.3607.\n",
      "Epoch0\t['loss: 0.175', 'val2_auc: 0.762', 'val3_auc: 0.682', 'val4_auc: 0.814', 'sum_auc: 2.257']\n",
      "Epoch1\t['loss: 0.156', 'val2_auc: 0.760', 'val3_auc: 0.712', 'val4_auc: 0.730', 'sum_auc: 2.202']\n",
      "Epoch2\t['loss: 0.149', 'val2_auc: 0.765', 'val3_auc: 0.696', 'val4_auc: 0.620', 'sum_auc: 2.081']\n",
      "Epoch3\t['loss: 0.145', 'val2_auc: 0.770', 'val3_auc: 0.705', 'val4_auc: 0.623', 'sum_auc: 2.098']\n",
      "Epoch4\t['loss: 0.142', 'val2_auc: 0.776', 'val3_auc: 0.706', 'val4_auc: 0.637', 'sum_auc: 2.119']\n",
      "Epoch5\t['loss: 0.141', 'val2_auc: 0.775', 'val3_auc: 0.696', 'val4_auc: 0.591', 'sum_auc: 2.062']\n",
      "Epoch 5: early stopping Threshold\n",
      "[I 2023-07-14 19:56:29,827] Trial 98 finished with value: 2.2575 and parameters: {'feature_dim': 256, 'n_step': 5, 'n_shared': 2, 'relaxation_factor': 1.0, 'sparsity_coefficient': 0.0002774976235016847, 'bn_momentum': 0.9976715881606901}. Best is trial 75 with value: 2.3607.\n",
      "Epoch0\t['loss: 0.179', 'val2_auc: 0.667', 'val3_auc: 0.648', 'val4_auc: 0.638', 'sum_auc: 1.953']\n",
      "Epoch1\t['loss: 0.162', 'val2_auc: 0.728', 'val3_auc: 0.656', 'val4_auc: 0.656', 'sum_auc: 2.040']\n",
      "Epoch2\t['loss: 0.155', 'val2_auc: 0.738', 'val3_auc: 0.663', 'val4_auc: 0.683', 'sum_auc: 2.084']\n",
      "Epoch3\t['loss: 0.152', 'val2_auc: 0.755', 'val3_auc: 0.682', 'val4_auc: 0.695', 'sum_auc: 2.132']\n",
      "Epoch5\t['loss: 0.148', 'val2_auc: 0.757', 'val3_auc: 0.671', 'val4_auc: 0.682', 'sum_auc: 2.110']\n",
      "Epoch6\t['loss: 0.146', 'val2_auc: 0.756', 'val3_auc: 0.667', 'val4_auc: 0.714', 'sum_auc: 2.138']\n",
      "Epoch7\t['loss: 0.145', 'val2_auc: 0.758', 'val3_auc: 0.656', 'val4_auc: 0.639', 'sum_auc: 2.054']\n",
      "Epoch8\t['loss: 0.144', 'val2_auc: 0.765', 'val3_auc: 0.656', 'val4_auc: 0.617', 'sum_auc: 2.038']\n",
      "Epoch9\t['loss: 0.143', 'val2_auc: 0.762', 'val3_auc: 0.668', 'val4_auc: 0.575', 'sum_auc: 2.005']\n",
      "[I 2023-07-14 20:07:19,471] Trial 99 finished with value: 2.0047 and parameters: {'feature_dim': 256, 'n_step': 6, 'n_shared': 2, 'relaxation_factor': 1.1, 'sparsity_coefficient': 0.0007651948881843217, 'bn_momentum': 0.9881640366790869}. Best is trial 75 with value: 2.3607.\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna import Trial, visualization\n",
    "\n",
    "def Objective(trial):\n",
    "    feature_dim = trial.suggest_categorical(\"feature_dim\", [8,16,32, 64, 128,256])\n",
    "    n_step = trial.suggest_int(\"n_step\", 2, 9, step=1)\n",
    "    n_shared = trial.suggest_int(\"n_shared\", 0, 4, step=1)\n",
    "    relaxation_factor = trial.suggest_float(\"relaxation_factor\", 1., 3., step=0.1)\n",
    "    sparsity_coefficient = trial.suggest_float(\"sparsity_coefficient\", 0.00000001, 0.1, log=True)\n",
    "    bn_momentum = trial.suggest_float('bn_momentum', 0.9, 0.9999)\n",
    "    tabnet_params = dict(num_features=flat_x[0].shape[1],\n",
    "                         output_dim=feature_dim,\n",
    "                         feature_dim=feature_dim,\n",
    "                         n_step=n_step, \n",
    "                         relaxation_factor=relaxation_factor,\n",
    "                         sparsity_coefficient=sparsity_coefficient,\n",
    "                         n_shared = n_shared,\n",
    "                         bn_momentum = bn_momentum\n",
    "                     )\n",
    "    \n",
    "    cbs = [\n",
    "    # tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=30, restore_best_weights=False)\n",
    "        EarlyStopByAUCSUM(dataset= [datasets[1],datasets[2], datasets[3]], patience=5)\n",
    "        # ,  MultiValidationCallback([datasets[1],datasets[2], datasets[3]])\n",
    "        ]\n",
    "    \n",
    "    tn = TabNet(**tabnet_params)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001,clipnorm=10)\n",
    "    loss = [tf.keras.losses.BinaryCrossentropy()]\n",
    "    \n",
    "    tn.compile(\n",
    "            optimizer,\n",
    "            loss=loss)\n",
    "            #    metrics = metrics.AUC(name='auc', curve='ROC')\n",
    "\n",
    "    tn.fit(datasets[0], \n",
    "          epochs=10, \n",
    "          validation_data=datasets[1],\n",
    "          callbacks=cbs,\n",
    "          verbose=0)\n",
    "    \n",
    "    \n",
    "    auc_scores = []\n",
    "    for i in range(3):\n",
    "        idx = i+1\n",
    "        val_preds, _ =  tn.predict(datasets[idx])\n",
    "        auc_scores.append(roc_auc_score(y[idx], val_preds))\n",
    "    score = np.round(sum(auc_scores),4)\n",
    "    \n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", study_name='TabNet optimization')\n",
    "study.optimize(Objective, n_jobs=1, n_trials=100, gc_after_trial=True, show_progress_bar=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa70d0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: score 2.3607,\n",
      "params {'feature_dim': 256, 'n_step': 2, 'n_shared': 2, 'relaxation_factor': 1.0, 'sparsity_coefficient': 0.00044768001615344994, 'bn_momentum': 0.9998302996755233}\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "cliponaxis": false,
         "hovertemplate": [
          "sparsity_coefficient (FloatDistribution): 0.012651115255380334<extra></extra>",
          "n_shared (IntDistribution): 0.019043681289581376<extra></extra>",
          "feature_dim (CategoricalDistribution): 0.05198031409673394<extra></extra>",
          "n_step (IntDistribution): 0.14416550423495308<extra></extra>",
          "relaxation_factor (FloatDistribution): 0.30318175047124607<extra></extra>",
          "bn_momentum (FloatDistribution): 0.46897763465210524<extra></extra>"
         ],
         "marker": {
          "color": "rgb(66,146,198)"
         },
         "orientation": "h",
         "text": [
          "0.01",
          "0.02",
          "0.05",
          "0.14",
          "0.30",
          "0.47"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          0.012651115255380334,
          0.019043681289581376,
          0.05198031409673394,
          0.14416550423495308,
          0.30318175047124607,
          0.46897763465210524
         ],
         "y": [
          "sparsity_coefficient",
          "n_shared",
          "feature_dim",
          "n_step",
          "relaxation_factor",
          "bn_momentum"
         ]
        }
       ],
       "layout": {
        "autosize": true,
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Hyperparameter Importances"
        },
        "xaxis": {
         "autorange": true,
         "range": [
          0,
          0.4936606680548476
         ],
         "title": {
          "text": "Importance for Objective Value"
         },
         "type": "linear"
        },
        "yaxis": {
         "autorange": true,
         "range": [
          -0.5,
          5.5
         ],
         "title": {
          "text": "Hyperparameter"
         },
         "type": "category"
        }
       }
      },
      "image/png": "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",
      "text/html": [
       "<div>                            <div id=\"1e720933-52a9-4012-976d-1c076df362e6\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1e720933-52a9-4012-976d-1c076df362e6\")) {                    Plotly.newPlot(                        \"1e720933-52a9-4012-976d-1c076df362e6\",                        [{\"cliponaxis\":false,\"hovertemplate\":[\"sparsity_coefficient (FloatDistribution): 0.012651115255380334\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"n_shared (IntDistribution): 0.019043681289581376\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"feature_dim (CategoricalDistribution): 0.05198031409673394\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"n_step (IntDistribution): 0.14416550423495308\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"relaxation_factor (FloatDistribution): 0.30318175047124607\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"bn_momentum (FloatDistribution): 0.46897763465210524\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"],\"marker\":{\"color\":\"rgb(66,146,198)\"},\"orientation\":\"h\",\"text\":[\"0.01\",\"0.02\",\"0.05\",\"0.14\",\"0.30\",\"0.47\"],\"textposition\":\"outside\",\"x\":[0.012651115255380334,0.019043681289581376,0.05198031409673394,0.14416550423495308,0.30318175047124607,0.46897763465210524],\"y\":[\"sparsity_coefficient\",\"n_shared\",\"feature_dim\",\"n_step\",\"relaxation_factor\",\"bn_momentum\"],\"type\":\"bar\"}],                        {\"showlegend\":false,\"title\":{\"text\":\"Hyperparameter Importances\"},\"xaxis\":{\"title\":{\"text\":\"Importance for Objective Value\"}},\"yaxis\":{\"title\":{\"text\":\"Hyperparameter\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('1e720933-52a9-4012-976d-1c076df362e6');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Best trial: score {},\\nparams {}'.format(study.best_trial.value,study.best_trial.params))\n",
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e63c8724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "Objective Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99
         ],
         "y": [
          2.1157,
          2.2173,
          2.1988,
          2.1813,
          2.1619,
          1.7912,
          2.0218,
          2.0906,
          2.0514,
          2.0996,
          1.9967,
          2.309,
          2.279,
          2.2484,
          2.1474,
          2.1054,
          2.2524,
          2.2099,
          2.1856,
          2.1358,
          2.0535,
          2.2428,
          2.2915,
          2.1353,
          2.1433,
          2.1641,
          2.2903,
          2.0562,
          2.2074,
          2.1351,
          2.1369,
          2.3143,
          2.179,
          2.2974,
          2.2643,
          2.1892,
          2.2156,
          2.1043,
          2.1329,
          2.161,
          2.1404,
          2.2863,
          2.2055,
          2.0631,
          2.2022,
          2.2809,
          2.0862,
          2.1041,
          2.2969,
          2.3189,
          2.1466,
          2.1391,
          2.2132,
          2.1239,
          2.3057,
          2.0308,
          2.0968,
          2.2527,
          2.0085,
          2.1725,
          2.2185,
          2.1178,
          2.22,
          2.2651,
          2.2248,
          2.0465,
          2.2728,
          2.217,
          2.2969,
          2.1723,
          2.0006,
          2.2896,
          1.8953,
          2.1504,
          2.1242,
          2.3607,
          2.2453,
          2.3423,
          2.2126,
          2.2562,
          2.2807,
          2.24,
          2.2431,
          2.2821,
          2.182,
          2.2018,
          2.3042,
          2.1601,
          2.1891,
          2.2166,
          2.2419,
          2.2194,
          1.99,
          2.0952,
          2.2935,
          2.3139,
          2.0082,
          2.1858,
          2.2575,
          2.0047
         ]
        },
        {
         "name": "Best Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99
         ],
         "y": [
          2.1157,
          2.2173,
          2.2173,
          2.2173,
          2.2173,
          2.2173,
          2.2173,
          2.2173,
          2.2173,
          2.2173,
          2.2173,
          2.309,
          2.309,
          2.309,
          2.309,
          2.309,
          2.309,
          2.309,
          2.309,
          2.309,
          2.309,
          2.309,
          2.309,
          2.309,
          2.309,
          2.309,
          2.309,
          2.309,
          2.309,
          2.309,
          2.309,
          2.3143,
          2.3143,
          2.3143,
          2.3143,
          2.3143,
          2.3143,
          2.3143,
          2.3143,
          2.3143,
          2.3143,
          2.3143,
          2.3143,
          2.3143,
          2.3143,
          2.3143,
          2.3143,
          2.3143,
          2.3143,
          2.3189,
          2.3189,
          2.3189,
          2.3189,
          2.3189,
          2.3189,
          2.3189,
          2.3189,
          2.3189,
          2.3189,
          2.3189,
          2.3189,
          2.3189,
          2.3189,
          2.3189,
          2.3189,
          2.3189,
          2.3189,
          2.3189,
          2.3189,
          2.3189,
          2.3189,
          2.3189,
          2.3189,
          2.3189,
          2.3189,
          2.3607,
          2.3607,
          2.3607,
          2.3607,
          2.3607,
          2.3607,
          2.3607,
          2.3607,
          2.3607,
          2.3607,
          2.3607,
          2.3607,
          2.3607,
          2.3607,
          2.3607,
          2.3607,
          2.3607,
          2.3607,
          2.3607,
          2.3607,
          2.3607,
          2.3607,
          2.3607,
          2.3607,
          2.3607
         ]
        }
       ],
       "layout": {
        "autosize": true,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "autorange": true,
         "range": [
          -6.3524488530688155,
          105.35244885306882
         ],
         "title": {
          "text": "Trial"
         },
         "type": "linear"
        },
        "yaxis": {
         "autorange": true,
         "range": [
          1.7442024271844658,
          2.407697572815534
         ],
         "title": {
          "text": "Objective Value"
         },
         "type": "linear"
        }
       }
      },
      "image/png": "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",
      "text/html": [
       "<div>                            <div id=\"6c969bfb-4c32-4e77-9c82-808cebfcfcf9\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6c969bfb-4c32-4e77-9c82-808cebfcfcf9\")) {                    Plotly.newPlot(                        \"6c969bfb-4c32-4e77-9c82-808cebfcfcf9\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"y\":[2.1157,2.2173,2.1988,2.1813,2.1619,1.7912,2.0218,2.0906,2.0514,2.0996,1.9967,2.309,2.279,2.2484,2.1474,2.1054,2.2524,2.2099,2.1856,2.1358,2.0535,2.2428,2.2915,2.1353,2.1433,2.1641,2.2903,2.0562,2.2074,2.1351,2.1369,2.3143,2.179,2.2974,2.2643,2.1892,2.2156,2.1043,2.1329,2.161,2.1404,2.2863,2.2055,2.0631,2.2022,2.2809,2.0862,2.1041,2.2969,2.3189,2.1466,2.1391,2.2132,2.1239,2.3057,2.0308,2.0968,2.2527,2.0085,2.1725,2.2185,2.1178,2.22,2.2651,2.2248,2.0465,2.2728,2.217,2.2969,2.1723,2.0006,2.2896,1.8953,2.1504,2.1242,2.3607,2.2453,2.3423,2.2126,2.2562,2.2807,2.24,2.2431,2.2821,2.182,2.2018,2.3042,2.1601,2.1891,2.2166,2.2419,2.2194,1.99,2.0952,2.2935,2.3139,2.0082,2.1858,2.2575,2.0047],\"type\":\"scatter\"},{\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"y\":[2.1157,2.2173,2.2173,2.2173,2.2173,2.2173,2.2173,2.2173,2.2173,2.2173,2.2173,2.309,2.309,2.309,2.309,2.309,2.309,2.309,2.309,2.309,2.309,2.309,2.309,2.309,2.309,2.309,2.309,2.309,2.309,2.309,2.309,2.3143,2.3143,2.3143,2.3143,2.3143,2.3143,2.3143,2.3143,2.3143,2.3143,2.3143,2.3143,2.3143,2.3143,2.3143,2.3143,2.3143,2.3143,2.3189,2.3189,2.3189,2.3189,2.3189,2.3189,2.3189,2.3189,2.3189,2.3189,2.3189,2.3189,2.3189,2.3189,2.3189,2.3189,2.3189,2.3189,2.3189,2.3189,2.3189,2.3189,2.3189,2.3189,2.3189,2.3189,2.3607,2.3607,2.3607,2.3607,2.3607,2.3607,2.3607,2.3607,2.3607,2.3607,2.3607,2.3607,2.3607,2.3607,2.3607,2.3607,2.3607,2.3607,2.3607,2.3607,2.3607,2.3607,2.3607,2.3607,2.3607],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('6c969bfb-4c32-4e77-9c82-808cebfcfcf9');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba87f8e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f708f79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d13ee10",
   "metadata": {},
   "outputs": [],
   "source": [
    "asdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787677c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(model):\n",
    "    hist = model.history\n",
    "    for label, values in hist.history.items():\n",
    "        if label.endswith('_auc'):\n",
    "            plt.plot(values, label=label)\n",
    "\n",
    "    plt.axhline(y=0.819, color='r', linestyle='--')\n",
    "    plt.axhline(y=0.792, color='orange', linestyle='--')\n",
    "    plt.axhline(y=0.835, color='g', linestyle='--')\n",
    "    plt.legend(loc='lower right')  # Display the legend (labels)\n",
    "    plt.show()  # Display the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9c33ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minkoo/.conda/envs/tf/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.16667 | train_auc: 0.76083 | test_icu_auc: 0.68754 | test_covid_auc: 0.80347 | valid_auc: 0.76045 |  0:00:49s\n",
      "epoch 1  | loss: 0.14986 | train_auc: 0.76783 | test_icu_auc: 0.68598 | test_covid_auc: 0.73723 | valid_auc: 0.76438 |  0:01:37s\n",
      "epoch 2  | loss: 0.14728 | train_auc: 0.78156 | test_icu_auc: 0.71073 | test_covid_auc: 0.82782 | valid_auc: 0.77565 |  0:02:25s\n",
      "epoch 3  | loss: 0.14523 | train_auc: 0.79038 | test_icu_auc: 0.7155  | test_covid_auc: 0.78204 | valid_auc: 0.78092 |  0:03:14s\n",
      "epoch 4  | loss: 0.14296 | train_auc: 0.80248 | test_icu_auc: 0.71279 | test_covid_auc: 0.7658  | valid_auc: 0.8018  |  0:04:03s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bbuild-38.201/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb#Y145sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_tabnet\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtab_model\u001b[39;00m \u001b[39mimport\u001b[39;00m TabNetClassifier\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bbuild-38.201/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb#Y145sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m classifier \u001b[39m=\u001b[39m TabNetClassifier(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bbuild-38.201/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb#Y145sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     n_d\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m, \u001b[39m# 8~64\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bbuild-38.201/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb#Y145sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     n_a\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m, \u001b[39m#  ==n_d\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbuild-38.201/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb#Y145sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39m#model_name\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbuild-38.201/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb#Y145sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m     )\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bbuild-38.201/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb#Y145sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m classifier\u001b[39m.\u001b[39;49mfit(X_train\u001b[39m=\u001b[39;49mflat_x[\u001b[39m0\u001b[39;49m], y_train\u001b[39m=\u001b[39;49my[\u001b[39m0\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbuild-38.201/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb#Y145sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m                eval_set\u001b[39m=\u001b[39;49m[(flat_x[\u001b[39m0\u001b[39;49m], y[\u001b[39m0\u001b[39;49m]), (flat_x[\u001b[39m2\u001b[39;49m], y[\u001b[39m2\u001b[39;49m]), (flat_x[\u001b[39m3\u001b[39;49m], y[\u001b[39m3\u001b[39;49m]), (flat_x[\u001b[39m1\u001b[39;49m], y[\u001b[39m1\u001b[39;49m])],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbuild-38.201/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb#Y145sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m                eval_name\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mtest_icu\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mtest_covid\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mvalid\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbuild-38.201/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb#Y145sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m                eval_metric\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mauc\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbuild-38.201/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb#Y145sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m                max_epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbuild-38.201/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb#Y145sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m                patience\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbuild-38.201/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb#Y145sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m                weights\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, \u001b[39m# 0 no sample / 1 --> sampling considering class weight\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbuild-38.201/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb#Y145sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m                \u001b[39m# loss = CE\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbuild-38.201/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb#Y145sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m                batch_size\u001b[39m=\u001b[39;49m\u001b[39m1024\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbuild-38.201/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb#Y145sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m                virtual_batch_size\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbuild-38.201/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb#Y145sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m                num_workers \u001b[39m=\u001b[39;49m \u001b[39m8\u001b[39;49m, \u001b[39m# number of workers used in torch dataloader\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbuild-38.201/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb#Y145sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m                drop_last\u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbuild-38.201/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb#Y145sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m                callbacks\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbuild-38.201/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb#Y145sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m                \u001b[39m#pretraining_ratio  for pretrainer only\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbuild-38.201/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb#Y145sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m                )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbuild-38.201/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb#Y145sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m plot_history(classifier)\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:241\u001b[0m, in \u001b[0;36mTabModel.fit\u001b[0;34m(self, X_train, y_train, eval_set, eval_name, eval_metric, loss_fn, weights, max_epochs, patience, batch_size, virtual_batch_size, num_workers, drop_last, callbacks, pin_memory, from_unsupervised, warm_start, augmentations)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[39mfor\u001b[39;00m epoch_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_epochs):\n\u001b[1;32m    237\u001b[0m \n\u001b[1;32m    238\u001b[0m     \u001b[39m# Call method on_epoch_begin for all callbacks\u001b[39;00m\n\u001b[1;32m    239\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callback_container\u001b[39m.\u001b[39mon_epoch_begin(epoch_idx)\n\u001b[0;32m--> 241\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_epoch(train_dataloader)\n\u001b[1;32m    243\u001b[0m     \u001b[39m# Apply predict epoch to all eval sets\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     \u001b[39mfor\u001b[39;00m eval_name, valid_dataloader \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(eval_names, valid_dataloaders):\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:454\u001b[0m, in \u001b[0;36mTabModel._train_epoch\u001b[0;34m(self, train_loader)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[39mTrains one epoch of the network in self.network\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[39m    DataLoader with train set\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnetwork\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m--> 454\u001b[0m \u001b[39mfor\u001b[39;00m batch_idx, (X, y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m    455\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callback_container\u001b[39m.\u001b[39mon_batch_begin(batch_idx)\n\u001b[1;32m    457\u001b[0m     batch_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch(X, y)\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1316\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1315\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1316\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1317\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1318\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1319\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1282\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1279\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1281\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1282\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1283\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1284\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1120\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1107\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1108\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1117\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1118\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1119\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1120\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1121\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   1122\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1123\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[1;32m    114\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/multiprocessing/connection.py:262\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[1;32m    261\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 262\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/multiprocessing/connection.py:429\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_poll\u001b[39m(\u001b[39mself\u001b[39m, timeout):\n\u001b[0;32m--> 429\u001b[0m     r \u001b[39m=\u001b[39m wait([\u001b[39mself\u001b[39;49m], timeout)\n\u001b[1;32m    430\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/multiprocessing/connection.py:930\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[39mwith\u001b[39;00m _WaitSelector() \u001b[39mas\u001b[39;00m selector:\n\u001b[1;32m    929\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m object_list:\n\u001b[0;32m--> 930\u001b[0m         selector\u001b[39m.\u001b[39;49mregister(obj, selectors\u001b[39m.\u001b[39mEVENT_READ)\n\u001b[1;32m    932\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    933\u001b[0m         deadline \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m+\u001b[39m timeout\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# do plane tabnet training\n",
    "# here we use default value\n",
    "\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "classifier = TabNetClassifier(\n",
    "    n_d=8, # 8~64\n",
    "    n_a=8, #  ==n_d\n",
    "    n_steps=3, # 3~10\n",
    "    n_independent=2, # 1~5\n",
    "    n_shared = 2, #1~5\n",
    "    optimizer_fn=torch.optim.Adam, # default\n",
    "    optimizer_params=dict(lr=1e-2),\n",
    "    scheduler_fn = None,\n",
    "    lambda_sparse = 1e-3,\n",
    "    device_name = 'auto',\n",
    "    mask_type='sparsemax'# \"sparsemax\", entmax\n",
    "    #model_name\n",
    "    )\n",
    "\n",
    "classifier.fit(X_train=flat_x[0], y_train=y[0],\n",
    "               eval_set=[(flat_x[0], y[0]), (flat_x[2], y[2]), (flat_x[3], y[3]), (flat_x[1], y[1])],\n",
    "               eval_name=['train', 'test_icu', 'test_covid', 'valid'],\n",
    "               eval_metric=['auc'],\n",
    "               max_epochs=50,\n",
    "               patience=10,\n",
    "               weights=0, # 0 no sample / 1 --> sampling considering class weight\n",
    "               # loss = CE\n",
    "               batch_size=1024,\n",
    "               virtual_batch_size=128,\n",
    "               num_workers = 8, # number of workers used in torch dataloader\n",
    "               drop_last= False,\n",
    "               callbacks=None,\n",
    "               #pretraining_ratio  for pretrainer only\n",
    "               )\n",
    "plot_history(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fc0ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eca76f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minkoo/.conda/envs/tf/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.56299 | train_auc: 0.8055  | test_icu_auc: 0.72492 | test_covid_auc: 0.79415 | valid_auc: 0.79996 |  0:00:49s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bbuild-38.201/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb#Y150sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# change weight\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bbuild-38.201/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb#Y150sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m classifier2 \u001b[39m=\u001b[39m TabNetClassifier(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bbuild-38.201/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb#Y150sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     n_d\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m, \u001b[39m# 8~64\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bbuild-38.201/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb#Y150sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     n_a\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m, \u001b[39m#  ==n_d\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbuild-38.201/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb#Y150sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m#model_name\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbuild-38.201/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb#Y150sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     )\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bbuild-38.201/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb#Y150sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m classifier2\u001b[39m.\u001b[39;49mfit(X_train\u001b[39m=\u001b[39;49mflat_x[\u001b[39m0\u001b[39;49m], y_train\u001b[39m=\u001b[39;49my[\u001b[39m0\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbuild-38.201/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb#Y150sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m                eval_set\u001b[39m=\u001b[39;49m[(flat_x[\u001b[39m0\u001b[39;49m], y[\u001b[39m0\u001b[39;49m]), (flat_x[\u001b[39m2\u001b[39;49m], y[\u001b[39m2\u001b[39;49m]), (flat_x[\u001b[39m3\u001b[39;49m], y[\u001b[39m3\u001b[39;49m]), (flat_x[\u001b[39m1\u001b[39;49m], y[\u001b[39m1\u001b[39;49m])],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbuild-38.201/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb#Y150sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m                eval_name\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mtest_icu\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mtest_covid\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mvalid\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbuild-38.201/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb#Y150sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m                eval_metric\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mauc\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbuild-38.201/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb#Y150sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m                max_epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbuild-38.201/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb#Y150sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m                patience\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbuild-38.201/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb#Y150sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m                weights\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m# 0 no sample / 1 --> sampling considering class weight\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbuild-38.201/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb#Y150sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m                \u001b[39m# loss = CE\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbuild-38.201/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb#Y150sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m                batch_size\u001b[39m=\u001b[39;49m\u001b[39m1024\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbuild-38.201/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb#Y150sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m                virtual_batch_size\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbuild-38.201/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb#Y150sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m                num_workers \u001b[39m=\u001b[39;49m \u001b[39m8\u001b[39;49m, \u001b[39m# number of workers used in torch dataloader\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbuild-38.201/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb#Y150sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m                drop_last\u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbuild-38.201/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb#Y150sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m                callbacks\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbuild-38.201/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb#Y150sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m                \u001b[39m#pretraining_ratio  for pretrainer only\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbuild-38.201/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb#Y150sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m                )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbuild-38.201/home/minkoo/serverity_prediction/notebook/severity_tabnet.ipynb#Y150sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m plot_history(classifier2)\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:245\u001b[0m, in \u001b[0;36mTabModel.fit\u001b[0;34m(self, X_train, y_train, eval_set, eval_name, eval_metric, loss_fn, weights, max_epochs, patience, batch_size, virtual_batch_size, num_workers, drop_last, callbacks, pin_memory, from_unsupervised, warm_start, augmentations)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[39m# Apply predict epoch to all eval sets\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[39mfor\u001b[39;00m eval_name, valid_dataloader \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(eval_names, valid_dataloaders):\n\u001b[0;32m--> 245\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict_epoch(eval_name, valid_dataloader)\n\u001b[1;32m    247\u001b[0m \u001b[39m# Call method on_epoch_end for all callbacks\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callback_container\u001b[39m.\u001b[39mon_epoch_end(\n\u001b[1;32m    249\u001b[0m     epoch_idx, logs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhistory\u001b[39m.\u001b[39mepoch_metrics\n\u001b[1;32m    250\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:530\u001b[0m, in \u001b[0;36mTabModel._predict_epoch\u001b[0;34m(self, name, loader)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[39m# Main loop\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \u001b[39mfor\u001b[39;00m batch_idx, (X, y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(loader):\n\u001b[0;32m--> 530\u001b[0m     scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict_batch(X)\n\u001b[1;32m    531\u001b[0m     list_y_true\u001b[39m.\u001b[39mappend(y)\n\u001b[1;32m    532\u001b[0m     list_y_score\u001b[39m.\u001b[39mappend(scores)\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/pytorch_tabnet/abstract_model.py:558\u001b[0m, in \u001b[0;36mTabModel._predict_batch\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    555\u001b[0m X \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m    557\u001b[0m \u001b[39m# compute model output\u001b[39;00m\n\u001b[0;32m--> 558\u001b[0m scores, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnetwork(X)\n\u001b[1;32m    560\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(scores, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    561\u001b[0m     scores \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy() \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m scores]\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/pytorch_tabnet/tab_network.py:586\u001b[0m, in \u001b[0;36mTabNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m    585\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedder(x)\n\u001b[0;32m--> 586\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtabnet(x)\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/pytorch_tabnet/tab_network.py:471\u001b[0m, in \u001b[0;36mTabNetNoEmbeddings.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m    470\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 471\u001b[0m     steps_output, M_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(x)\n\u001b[1;32m    472\u001b[0m     res \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msum(torch\u001b[39m.\u001b[39mstack(steps_output, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m), dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m    474\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_multi_task:\n\u001b[1;32m    475\u001b[0m         \u001b[39m# Result will be in list format\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/pytorch_tabnet/tab_network.py:156\u001b[0m, in \u001b[0;36mTabNetEncoder.forward\u001b[0;34m(self, x, prior)\u001b[0m\n\u001b[1;32m    153\u001b[0m     prior \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones(x\u001b[39m.\u001b[39mshape)\u001b[39m.\u001b[39mto(x\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    155\u001b[0m M_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 156\u001b[0m att \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minitial_splitter(x)[:, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_d :]\n\u001b[1;32m    158\u001b[0m steps_output \u001b[39m=\u001b[39m []\n\u001b[1;32m    159\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_steps):\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/pytorch_tabnet/tab_network.py:706\u001b[0m, in \u001b[0;36mFeatTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 706\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshared(x)\n\u001b[1;32m    707\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspecifics(x)\n\u001b[1;32m    708\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/tf/lib/python3.9/site-packages/pytorch_tabnet/tab_network.py:750\u001b[0m, in \u001b[0;36mGLU_Block.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[39mfor\u001b[39;00m glu_id \u001b[39min\u001b[39;00m layers_left:\n\u001b[1;32m    749\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39madd(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mglu_layers[glu_id](x))\n\u001b[0;32m--> 750\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m*\u001b[39;49m scale\n\u001b[1;32m    751\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# change weight\n",
    "\n",
    "classifier2 = TabNetClassifier(\n",
    "    n_d=8, # 8~64\n",
    "    n_a=8, #  ==n_d\n",
    "    n_steps=3, # 3~10\n",
    "    n_independent=2, # 1~5\n",
    "    n_shared = 2, #1~5\n",
    "    optimizer_fn=torch.optim.Adam, # default\n",
    "    optimizer_params=dict(lr=1e-2),\n",
    "    scheduler_fn = None,\n",
    "    mask_type='sparsemax'# \"sparsemax\", entmax\n",
    "    #model_name\n",
    "    )\n",
    "\n",
    "classifier2.fit(X_train=flat_x[0], y_train=y[0],\n",
    "               eval_set=[(flat_x[0], y[0]), (flat_x[2], y[2]), (flat_x[3], y[3]), (flat_x[1], y[1])],\n",
    "               eval_name=['train', 'test_icu', 'test_covid', 'valid'],\n",
    "               eval_metric=['auc'],\n",
    "               max_epochs=50,\n",
    "               patience=10,\n",
    "               weights=1, # 0 no sample / 1 --> sampling considering class weight\n",
    "               # loss = CE\n",
    "               batch_size=1024,\n",
    "               virtual_batch_size=128,\n",
    "               num_workers = 8, # number of workers used in torch dataloader\n",
    "               drop_last= False,\n",
    "               callbacks=None,\n",
    "               #pretraining_ratio  for pretrainer only\n",
    "               )\n",
    "plot_history(classifier2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544ee319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x1440 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "explain_matrix, masks = classifier.explain(flat_x[1])\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20,20))\n",
    "for i in range(3):\n",
    "    axs[i].imshow(masks[i][:50])\n",
    "    axs[i].set_title(f\"mask {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0f6563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58064b12",
   "metadata": {},
   "source": [
    "Hyperparameter search using optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e75020",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1084955490.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [72]\u001b[0;36m\u001b[0m\n\u001b[0;31m    def __init__(\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna import Trial, visualization\n",
    "\n",
    "    # def __init__(\n",
    "    #     self,\n",
    "    #     num_features,\n",
    "    #     feature_dim,\n",
    "    #     output_dim,\n",
    "    #     n_step = 2,\n",
    "    #     n_total = 4,\n",
    "    #     n_shared = 2,\n",
    "    #     relaxation_factor = 1.5,\n",
    "    #     bn_epsilon = 1e-5,\n",
    "    #     bn_momentum = 0.7,\n",
    "    #     sparsity_coefficient = 1e-5\n",
    "    # ):\n",
    "# classifier2 = TabNetClassifier(\n",
    "#     n_d=8, # 8~64    == feature_dim\n",
    "#     n_a=8, #  ==n_d   == num_features\n",
    "#     gamma=1.3\n",
    "#     n_steps=3, # 3~10\n",
    "#     n_independent=2, # 1~5\n",
    "#     n_shared = 2, #1~5\n",
    "#     optimizer_fn=torch.optim.Adam, # default\n",
    "#     optimizer_params=dict(lr=1e-2),\n",
    "#     scheduler_fn = None,\n",
    "#     lambda_sparse = 1e-3,\n",
    "#     momentum = 0.02,\n",
    "#     mask_type='sparsemax'# \"sparsemax\", entmax\n",
    "#     #model_name\n",
    "#     )\n",
    "\n",
    "def Objective(trial):\n",
    "    feature_dim = trial.suggest_categorical(\"n_d\", [8,16,32, 64, 128])\n",
    "    n_step = trial.suggest_int(\"n_step\", 2, 9, step=1)\n",
    "    n_shared = trial.suggest_int(\"n_shared\", 0, 4, step=1)\n",
    "    relaxation_factor = trial.suggest_float(\"gamma\", 1., 3., step=0.1)\n",
    "    sparsity_coefficient = trial.suggest_float(\"lambda_sparse\", 0.00000001, 0.1, log=True)\n",
    "    bn_momentum = trial.suggest_float('momentum', 0.9, 0.9999)\n",
    "    tabnet_params = dict(num_features=flat_x[0].shape[1],\n",
    "                         output_dim=feature_dim,\n",
    "                         feature_dim=feature_dim,\n",
    "                         n_step=n_step, \n",
    "                         relaxation_factor=relaxation_factor,\n",
    "                         sparsity_coefficient=sparsity_coefficient,\n",
    "                         n_shared = n_shared,\n",
    "                         bn_momentum = bn_momentum\n",
    "                     )\n",
    "    class_weight =  trial.suggest_int(\"class_weight\", 1, 10.5, step=0.5)\n",
    "    \n",
    "    cbs = [tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\", patience=5, restore_best_weights=True\n",
    "        )]\n",
    "    \n",
    "    tn = TabNetClassifier(**tabnet_params)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001,clipnorm=10)\n",
    "    loss = [tf.keras.losses.CategoricalCrossentropy(from_logits=False),None]\n",
    "    \n",
    "    tn.compile(\n",
    "            optimizer,\n",
    "            loss=loss)\n",
    "\n",
    "    tn.fit(train_ds, \n",
    "          epochs=100, \n",
    "          validation_data=val_ds,\n",
    "          callbacks=cbs,\n",
    "          verbose=1)\n",
    "    \n",
    "    \n",
    "    val_preds, _ =  tn.predict(val_ds)\n",
    "    pr_auc = average_precision_score(val_y, val_preds[:,1])\n",
    "    \n",
    "    return pr_auc\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", study_name='TabNet optimization')\n",
    "study.optimize(Objective, n_jobs=1, n_trials=100, gc_after_trial=True, show_progress_bar=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd618649",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
